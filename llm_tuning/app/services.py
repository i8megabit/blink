"""
–°–µ—Ä–≤–∏—Å–Ω—ã–π —Å–ª–æ–π –¥–ª—è LLM Tuning –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏ —Ç—é–Ω–∏–Ω–≥–∞
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

import httpx
import numpy as np
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete, and_, or_, func
from sqlalchemy.orm import selectinload

from .models import (
    LLMModel, ModelRoute, TuningSession, PerformanceMetrics,
    RAGDocument, APILog, ModelStatus, RouteStrategy, TuningStrategy,
    ABTest, ABTestStatus, ModelOptimization, QualityAssessment, SystemHealth,
    OptimizationType
)
from .config import settings

logger = logging.getLogger(__name__)


class ModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è LLM –º–æ–¥–µ–ª—è–º–∏"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    async def list_models(self) -> List[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ Ollama
            response = await self.ollama_client.get("/api/tags")
            ollama_models = response.json().get("models", [])
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –ë–î
            stmt = select(LLMModel).options(selectinload(LLMModel.routes))
            result = await self.db.execute(stmt)
            db_models = result.scalars().all()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å—ã –º–æ–¥–µ–ª–µ–π
            for model in db_models:
                model.is_available = any(
                    m["name"] == model.name for m in ollama_models
                )
            
            await self.db.commit()
            return db_models
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            raise
    
    async def get_model(self, model_id: int) -> Optional[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ ID"""
        stmt = select(LLMModel).options(
            selectinload(LLMModel.routes),
            selectinload(LLMModel.metrics)
        ).where(LLMModel.id == model_id)
        
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def create_model(self, model_data: Dict[str, Any]) -> LLMModel:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        model = LLMModel(**model_data)
        self.db.add(model)
        await self.db.commit()
        await self.db.refresh(model)
        return model
    
    async def update_model(self, model_id: int, model_data: Dict[str, Any]) -> Optional[LLMModel]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        stmt = update(LLMModel).where(LLMModel.id == model_id).values(**model_data)
        await self.db.execute(stmt)
        await self.db.commit()
        
        return await self.get_model(model_id)
    
    async def delete_model(self, model_id: int) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        stmt = delete(LLMModel).where(LLMModel.id == model_id)
        result = await self.db.execute(stmt)
        await self.db.commit()
        return result.rowcount > 0
    
    async def get_model_info(self, model_name: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –∏–∑ Ollama"""
        try:
            response = await self.ollama_client.get(f"/api/show", params={"name": model_name})
            return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            return {}


class RouteManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self._route_cache: Dict[str, ModelRoute] = {}
        self._cache_updated = datetime.now()
    
    async def get_route(self, request_type: str, content: str = "") -> Optional[ModelRoute]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
        if datetime.now() - self._cache_updated > timedelta(minutes=5):
            await self._update_cache()
        
        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–∞—Ä—à—Ä—É—Ç
        for route in self._route_cache.values():
            if route.is_active and self._matches_route(route, request_type, content):
                return route
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Ä—à—Ä—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return self._get_default_route()
    
    def _matches_route(self, route: ModelRoute, request_type: str, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞–ø—Ä–æ—Å–∞ –º–∞—Ä—à—Ä—É—Ç—É"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        if route.request_types and request_type not in route.request_types:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if route.keywords and not any(
            keyword.lower() in content.lower() for keyword in route.keywords
        ):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        if route.complexity_threshold:
            complexity = self._calculate_complexity(content)
            if complexity < route.complexity_threshold:
                return False
        
        return True
    
    def _calculate_complexity(self, content: str) -> float:
        """–†–∞—Å—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if not content:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        words = content.split()
        sentences = content.split('.')
        avg_sentence_length = len(words) / len(sentences) if sentences else 0
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ —á–∏—Å–ª–∞
        special_chars = sum(1 for c in content if not c.isalnum() and not c.isspace())
        numbers = sum(1 for c in content if c.isdigit())
        
        complexity = (
            avg_sentence_length * 0.4 +
            (special_chars / len(content)) * 0.3 +
            (numbers / len(content)) * 0.3
        )
        
        return min(complexity, 1.0)
    
    def _get_default_route(self) -> Optional[ModelRoute]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        for route in self._route_cache.values():
            if route.is_default:
                return route
        return None
    
    async def _update_cache(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤"""
        stmt = select(ModelRoute).options(selectinload(ModelRoute.model))
        result = await self.db.execute(stmt)
        routes = result.scalars().all()
        
        self._route_cache = {route.name: route for route in routes}
        self._cache_updated = datetime.now()
    
    async def create_route(self, route_data: Dict[str, Any]) -> ModelRoute:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞"""
        route = ModelRoute(**route_data)
        self.db.add(route)
        await self.db.commit()
        await self.db.refresh(route)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
        await self._update_cache()
        return route
    
    async def update_route(self, route_id: int, route_data: Dict[str, Any]) -> Optional[ModelRoute]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞"""
        stmt = update(ModelRoute).where(ModelRoute.id == route_id).values(**route_data)
        await self.db.execute(stmt)
        await self.db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
        await self._update_cache()
        
        stmt = select(ModelRoute).where(ModelRoute.id == route_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()


class RAGService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG (Retrieval-Augmented Generation)"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
        self._vector_cache: Dict[str, List[float]] = {}
    
    async def add_document(self, document_data: Dict[str, Any]) -> RAGDocument:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ RAG —Å–∏—Å—Ç–µ–º—É"""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º metadata -> doc_metadata, –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'metadata' in document_data:
                document_data['doc_metadata'] = document_data.pop('metadata')
            # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            document = RAGDocument(**document_data)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            embeddings = await self._generate_embeddings(document.content)
            document.embeddings = json.dumps(embeddings)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            document.keywords = await self._extract_keywords(document.content)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            self.db.add(document)
            await self.db.commit()
            await self.db.refresh(document)
            
            # –ö—ç—à–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            self._vector_cache[f"doc_{document.id}"] = embeddings
            
            logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç {document.title} –¥–æ–±–∞–≤–ª–µ–Ω –≤ RAG —Å–∏—Å—Ç–µ–º—É")
            return document
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            raise
    
    async def search_documents(self, query: str, limit: int = 5) -> List[RAGDocument]:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embeddings = await self._generate_embeddings(query)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            stmt = select(RAGDocument).where(RAGDocument.is_active == True)
            result = await self.db.execute(stmt)
            documents = result.scalars().all()
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarities = []
            for doc in documents:
                if doc.embeddings:
                    doc_embeddings = json.loads(doc.embeddings)
                    similarity = self._cosine_similarity(query_embeddings, doc_embeddings)
                    similarities.append((similarity, doc))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            similarities.sort(key=lambda x: x[0], reverse=True)
            top_documents = [doc for _, doc in similarities[:limit]]
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(top_documents)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
            return top_documents
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return []
    
    async def generate_with_rag(
        self, 
        model_name: str, 
        query: str, 
        context_documents: List[RAGDocument] = None
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG"""
        try:
            # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏—â–µ–º –∏—Ö
            if not context_documents:
                context_documents = await self.search_documents(query, limit=3)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            context = self._build_context(context_documents)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            system_prompt = """–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 
            –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º —á–µ—Å—Ç–Ω–æ."""
            
            user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç:"""
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = await self._generate_response(model_name, user_prompt, system_prompt)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            response["context_documents"] = [
                {
                    "title": doc.title,
                    "source": doc.source,
                    "relevance_score": doc.relevance_score
                }
                for doc in context_documents
            ]
            
            return response
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å RAG: {e}")
            return {
                "error": str(e),
                "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."
            }
    
    async def _generate_embeddings(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            response = await self.ollama_client.post(
                "/api/embeddings",
                json={
                    "model": "nomic-embed-text",
                    "prompt": text
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("embedding", [])
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                return self._simple_embeddings(text)
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}")
            return self._simple_embeddings(text)
    
    def _simple_embeddings(self, text: str) -> List[float]:
        """–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è fallback"""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã —Å–∏–º–≤–æ–ª–æ–≤
        import string
        from collections import Counter
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
        text = text.lower()
        text = ''.join(c for c in text if c.isalnum() or c.isspace())
        
        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Å–∏–º–≤–æ–ª–æ–≤
        char_freq = Counter(text)
        
        # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
        embedding = [0.0] * 128
        for i, (char, freq) in enumerate(char_freq.most_common(128)):
            if i < 128:
                embedding[i] = freq / len(text)
        
        return embedding
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        try:
            import numpy as np
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω–µ
            min_len = min(len(vec1), len(vec2))
            vec1 = vec1[:min_len]
            vec2 = vec2[:min_len]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return dot_product / (norm1 * norm2)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}")
            return 0.0
    
    async def _extract_keywords(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            import re
            from collections import Counter
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            stop_words = {
                '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞',
                '—Ç–∞–∫', '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞', '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ',
                '–º–Ω–µ', '–±—ã–ª–æ', '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç', '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞',
                '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥', '–ª–∏', '–µ—Å–ª–∏', '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ',
                '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å', '—É–∂', '–≤–∞–º', '–≤–µ–¥—å', '—Ç–∞–º', '–ø–æ—Ç–æ–º', '—Å–µ–±—è', '–Ω–∏—á–µ–≥–æ', '–µ–π',
                '–º–æ–∂–µ—Ç', '–æ–Ω–∏', '—Ç—É—Ç', '–≥–¥–µ', '–µ—Å—Ç—å', '–Ω–∞–¥–æ', '–Ω–µ–π', '–¥–ª—è', '–º—ã', '—Ç–µ–±—è', '–∏—Ö', '—á–µ–º',
                '–±—ã–ª–∞', '—Å–∞–º', '—á—Ç–æ–±', '–±–µ–∑', '–±—É–¥—Ç–æ', '—á–µ–≥–æ', '—Ä–∞–∑', '—Ç–æ–∂–µ', '—Å–µ–±–µ', '–ø–æ–¥', '–±—É–¥–µ—Ç',
                '–∂', '—Ç–æ–≥–¥–∞', '–∫—Ç–æ', '—ç—Ç–æ—Ç', '—Ç–æ–≥–æ', '–ø–æ—Ç–æ–º—É', '—ç—Ç–æ–≥–æ', '–∫–∞–∫–æ–π', '—Å–æ–≤—Å–µ–º', '–Ω–∏–º', '–∑–¥–µ—Å—å',
                '—ç—Ç–æ–º', '–æ–¥–∏–Ω', '–ø–æ—á—Ç–∏', '–º–æ–π', '—Ç–µ–º', '—á—Ç–æ–±—ã', '–Ω–µ–µ', '—Å–µ–π—á–∞—Å', '–±—ã–ª–∏', '–∫—É–¥–∞', '–∑–∞—á–µ–º',
                '–≤—Å–µ—Ö', '–Ω–∏–∫–æ–≥–¥–∞', '–º–æ–∂–Ω–æ', '–ø—Ä–∏', '–Ω–∞–∫–æ–Ω–µ—Ü', '–¥–≤–∞', '–æ–±', '–¥—Ä—É–≥–æ–π', '—Ö–æ—Ç—å', '–ø–æ—Å–ª–µ',
                '–Ω–∞–¥', '–±–æ–ª—å—à–µ', '—Ç–æ—Ç', '—á–µ—Ä–µ–∑', '—ç—Ç–∏', '–Ω–∞—Å', '–ø—Ä–æ', '–≤—Å–µ–≥–æ', '–Ω–∏—Ö', '–∫–∞–∫–∞—è', '–º–Ω–æ–≥–æ',
                '—Ä–∞–∑–≤–µ', '—Ç—Ä–∏', '—ç—Ç—É', '–º–æ—è', '–≤–ø—Ä–æ—á–µ–º', '—Ö–æ—Ä–æ—à–æ', '—Å–≤–æ—é', '—ç—Ç–æ–π', '–ø–µ—Ä–µ–¥', '–∏–Ω–æ–≥–¥–∞',
                '–ª—É—á—à–µ', '—á—É—Ç—å', '—Ç–æ–º', '–Ω–µ–ª—å–∑—è', '—Ç–∞–∫–æ–π', '–∏–º', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–ø—Ä–∏—Ç–æ–º', '–±—É–¥–µ—Ç',
                '–æ—á–µ–Ω—å', '–Ω–∞—Å', '–≤–¥–≤–æ–µ–º', '–ø–æ–¥', '–æ–±–æ—Ä–æ—Ç', '—Ç–µ–ø–µ—Ä—å', '–¥–æ–ª–≥–æ', '–ª–∏', '–æ—á–µ–Ω—å', '–ª–∏–±–æ',
                '–≤–ø—Ä–æ—á–µ–º', '–≤—Å–µ', '—Ç–∞–∫–∏', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–º–µ–∂–¥—É'
            }
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
            text = text.lower()
            text = re.sub(r'[^\w\s]', '', text)
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
            words = text.split()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
            keywords = [
                word for word in words 
                if word not in stop_words and len(word) > 2
            ]
            
            # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-10
            word_freq = Counter(keywords)
            return [word for word, _ in word_freq.most_common(10)]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
            return []
    
    def _build_context(self, documents: List[RAGDocument]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if not documents:
            return ""
        
        context_parts = []
        for i, doc in enumerate(documents, 1):
            context_parts.append(f"–î–æ–∫—É–º–µ–Ω—Ç {i}: {doc.title}")
            context_parts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {doc.source}")
            context_parts.append(f"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {doc.content[:500]}...")
            context_parts.append("")
        
        return "\n".join(context_parts)
    
    async def _generate_response(
        self, 
        model_name: str, 
        prompt: str, 
        system_prompt: str = None
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏"""
        try:
            payload = {
                "model": model_name,
                "prompt": prompt,
                "stream": False
            }
            
            if system_prompt:
                payload["system"] = system_prompt
            
            response = await self.ollama_client.post(
                "/api/generate",
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "response": data.get("response", ""),
                    "model": model_name,
                    "tokens_used": data.get("eval_count", 0),
                    "prompt_eval_count": data.get("prompt_eval_count", 0),
                    "eval_count": data.get("eval_count", 0)
                }
            else:
                return {
                    "error": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {response.text}",
                    "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."
                }
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                "error": str(e),
                "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."
            }
    
    async def update_document(self, doc_id: int, updates: Dict[str, Any]) -> Optional[RAGDocument]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            stmt = select(RAGDocument).where(RAGDocument.id == doc_id)
            result = await self.db.execute(stmt)
            document = result.scalar_one_or_none()
            
            if not document:
                return None
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
            for key, value in updates.items():
                if hasattr(document, key):
                    setattr(document, key, value)
            
            # –ï—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç, –æ–±–Ω–æ–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            if "content" in updates:
                embeddings = await self._generate_embeddings(document.content)
                document.embeddings = json.dumps(embeddings)
                document.keywords = await self._extract_keywords(document.content)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                self._vector_cache[f"doc_{document.id}"] = embeddings
            
            await self.db.commit()
            await self.db.refresh(document)
            
            return document
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return None
    
    async def delete_document(self, doc_id: int) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            stmt = select(RAGDocument).where(RAGDocument.id == doc_id)
            result = await self.db.execute(stmt)
            document = result.scalar_one_or_none()
            
            if not document:
                return False
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞
            cache_key = f"doc_{document.id}"
            if cache_key in self._vector_cache:
                del self._vector_cache[cache_key]
            
            # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–π
            document.is_active = False
            await self.db.commit()
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
    
    async def get_documents_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            total_stmt = select(func.count(RAGDocument.id))
            total_result = await self.db.execute(total_stmt)
            total_docs = total_result.scalar()
            
            # –ê–∫—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            active_stmt = select(func.count(RAGDocument.id)).where(RAGDocument.is_active == True)
            active_result = await self.db.execute(active_stmt)
            active_docs = active_result.scalar()
            
            # –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ç–∏–ø–∞–º
            type_stmt = select(
                RAGDocument.document_type,
                func.count(RAGDocument.id)
            ).group_by(RAGDocument.document_type)
            type_result = await self.db.execute(type_stmt)
            docs_by_type = dict(type_result.all())
            
            return {
                "total_documents": total_docs,
                "active_documents": active_docs,
                "documents_by_type": docs_by_type,
                "vector_cache_size": len(self._vector_cache)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return {}


class TuningService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    async def create_tuning_session(self, session_data: Dict[str, Any]) -> TuningSession:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
        session = TuningSession(**session_data)
        self.db.add(session)
        await self.db.commit()
        await self.db.refresh(session)
        return session
    
    async def get_tuning_session(self, session_id: int) -> Optional[TuningSession]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
        stmt = select(TuningSession).where(TuningSession.id == session_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def update_tuning_session(self, session_id: int, updates: Dict[str, Any]) -> Optional[TuningSession]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
        stmt = update(TuningSession).where(TuningSession.id == session_id).values(**updates)
        await self.db.execute(stmt)
        await self.db.commit()
        
        return await self.get_tuning_session(session_id)
    
    async def start_tuning(self, session_id: int) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ç—é–Ω–∏–Ω–≥–∞"""
        session = await self.get_tuning_session(session_id)
        if not session:
            return False
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.TUNING,
                "started_at": datetime.now()
            })
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—é–Ω–∏–Ω–≥ –≤ —Ñ–æ–Ω–µ
            asyncio.create_task(self._run_tuning(session_id))
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Ç—é–Ω–∏–Ω–≥–∞: {e}")
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.FAILED,
                "error_message": str(e)
            })
            return False
    
    async def _run_tuning(self, session_id: int):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–∏"""
        session = await self.get_tuning_session(session_id)
        if not session:
            logger.error(f"–°–µ—Å—Å–∏—è —Ç—é–Ω–∏–Ω–≥–∞ {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        try:
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            model = await self._get_model_by_session(session_id)
            if not model:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                })
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.TUNING,
                "started_at": datetime.now()
            })
            
            # –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (10%)
            logger.info("üìä –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞")
            await self.update_tuning_session(session_id, {"progress": 10})
            
            training_data = await self._prepare_training_data(session)
            if not training_data:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"
                })
                return
            
            # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ Modelfile (20%)
            logger.info("üìù –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ Modelfile")
            await self.update_tuning_session(session_id, {"progress": 20})
            
            modelfile = await self._create_modelfile(model, training_data, session)
            if not modelfile:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Modelfile"
                })
                return
            
            # –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (40%)
            logger.info("‚¨áÔ∏è –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
            await self.update_tuning_session(session_id, {"progress": 40})
            
            base_model_loaded = await self._ensure_base_model(model.base_model)
            if not base_model_loaded:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å"
                })
                return
            
            # –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (70%)
            logger.info("üîß –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            await self.update_tuning_session(session_id, {"progress": 70})
            
            tuned_model_name = f"{model.name}-tuned-{session_id}"
            model_created = await self._create_tuned_model(tuned_model_name, modelfile)
            if not model_created:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"
                })
                return
            
            # –≠—Ç–∞–ø 5: –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (90%)
            logger.info("‚úÖ –≠—Ç–∞–ø 5: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            await self.update_tuning_session(session_id, {"progress": 90})
            
            validation_result = await self._validate_tuned_model(tuned_model_name, session)
            if not validation_result["success"]:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": f"–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞: {validation_result['error']}"
                })
                return
            
            # –≠—Ç–∞–ø 6: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ (100%)
            logger.info("üéâ –≠—Ç–∞–ø 6: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ç—é–Ω–∏–Ω–≥–∞")
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.READY,
                "progress": 100,
                "completed_at": datetime.now(),
                "tuned_model_name": tuned_model_name,
                "validation_metrics": validation_result["metrics"]
            })
            
            logger.info(f"‚úÖ –¢—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ: {tuned_model_name}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ç—é–Ω–∏–Ω–≥–∞ —Å–µ—Å—Å–∏–∏ {session_id}: {e}")
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.FAILED,
                "error_message": str(e)
            })
    
    async def _get_model_by_session(self, session_id: int) -> Optional[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ ID —Å–µ—Å—Å–∏–∏"""
        stmt = select(TuningSession).where(TuningSession.id == session_id)
        result = await self.db.execute(stmt)
        session = result.scalar_one_or_none()
        
        if not session:
            return None
        
        stmt = select(LLMModel).where(LLMModel.id == session.model_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def _prepare_training_data(self, session: TuningSession) -> Optional[List[Dict[str, str]]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ –∏–∑ —Å–µ—Å—Å–∏–∏
            training_data = []
            
            # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞
            if session.training_data:
                training_data = json.loads(session.training_data)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
                training_data = [
                    {
                        "instruction": "–û–±—ä—è—Å–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è",
                        "input": "",
                        "output": "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º —É—á–∏—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."
                    },
                    {
                        "instruction": "–ù–∞–ø–∏—à–∏ –∫–æ–¥ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞",
                        "input": "–º–∞—Å—Å–∏–≤ [3, 1, 4, 1, 5]",
                        "output": "def sort_array(arr):\n    return sorted(arr)\n\n# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\narr = [3, 1, 4, 1, 5]\nsorted_arr = sort_array(arr)\nprint(sorted_arr)  # [1, 1, 3, 4, 5]"
                    }
                ]
            
            return training_data
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞: {e}")
            return None
    
    async def _create_modelfile(
        self, 
        model: LLMModel, 
        training_data: List[Dict[str, str]], 
        session: TuningSession
    ) -> Optional[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ Modelfile –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"""
        try:
            modelfile_lines = [
                f"FROM {model.base_model}",
                "",
                "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏",
                f"PARAMETER temperature {session.parameters.get('temperature', 0.7)}",
                f"PARAMETER top_p {session.parameters.get('top_p', 0.9)}",
                f"PARAMETER top_k {session.parameters.get('top_k', 40)}",
                f"PARAMETER repeat_penalty {session.parameters.get('repeat_penalty', 1.1)}",
                "",
                "# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç",
                f'SYSTEM """{session.system_prompt or "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."}"""',
                "",
                "# –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞
            for i, example in enumerate(training_data):
                instruction = example.get("instruction", "")
                input_text = example.get("input", "")
                output = example.get("output", "")
                
                if input_text:
                    prompt = f"{instruction}\n\n–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {input_text}"
                else:
                    prompt = instruction
                
                modelfile_lines.extend([
                    f"# –ü—Ä–∏–º–µ—Ä {i+1}",
                    f'PROMPT """{prompt}"""',
                    f'RESPONSE """{output}"""',
                    ""
                ])
            
            modelfile = "\n".join(modelfile_lines)
            logger.info(f"–°–æ–∑–¥–∞–Ω Modelfile –¥–ª—è –º–æ–¥–µ–ª–∏ {model.name}")
            return modelfile
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Modelfile: {e}")
            return None
    
    async def _ensure_base_model(self, base_model: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –º–æ–¥–µ–ª—å –≤ Ollama
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{settings.OLLAMA_BASE_URL}/api/tags")
                if response.status_code == 200:
                    models = response.json().get("models", [])
                    model_names = [model["name"] for model in models]
                    
                    if base_model in model_names:
                        logger.info(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å {base_model} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                        return True
            
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å
            logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å {base_model}")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{settings.OLLAMA_BASE_URL}/api/pull",
                    json={"name": base_model}
                )
                
                if response.status_code == 200:
                    logger.info(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å {base_model} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    return True
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ {base_model}")
                    return False
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    async def _create_tuned_model(self, model_name: str, modelfile: str) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{settings.OLLAMA_BASE_URL}/api/create",
                    json={
                        "name": model_name,
                        "modelfile": modelfile
                    }
                )
                
                if response.status_code == 200:
                    logger.info(f"–¢—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å {model_name} —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    return True
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {response.text}")
                    return False
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    async def _validate_tuned_model(self, model_name: str, session: TuningSession) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            test_queries = [
                "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
                "–û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, —á—Ç–æ —Ç–∞–∫–æ–µ API",
                "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏"
            ]
            
            results = []
            total_tokens = 0
            total_time = 0
            
            async with httpx.AsyncClient() as client:
                for query in test_queries:
                    start_time = time.time()
                    
                    response = await client.post(
                        f"{settings.OLLAMA_BASE_URL}/api/generate",
                        json={
                            "model": model_name,
                            "prompt": query,
                            "stream": False
                        }
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        end_time = time.time()
                        
                        results.append({
                            "query": query,
                            "response": result.get("response", ""),
                            "tokens": result.get("eval_count", 0),
                            "time": end_time - start_time
                        })
                        
                        total_tokens += result.get("eval_count", 0)
                        total_time += end_time - start_time
                    else:
                        return {
                            "success": False,
                            "error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {response.text}"
                        }
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            avg_response_time = total_time / len(results) if results else 0
            avg_tokens = total_tokens / len(results) if results else 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–ª–∏–Ω—É)
            quality_score = sum(1 for r in results if len(r["response"]) > 10) / len(results)
            
            metrics = {
                "avg_response_time": avg_response_time,
                "avg_tokens": avg_tokens,
                "quality_score": quality_score,
                "test_queries_count": len(test_queries),
                "successful_responses": len(results)
            }
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—à–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            success = (
                avg_response_time < 5.0 and  # –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –º–µ–Ω–µ–µ 5 —Å–µ–∫—É–Ω–¥
                quality_score > 0.8 and      # –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –±–æ–ª–µ–µ 80%
                len(results) == len(test_queries)  # –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            )
            
            return {
                "success": success,
                "metrics": metrics,
                "error": None if success else "–ú–æ–¥–µ–ª—å –Ω–µ –ø—Ä–æ—à–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é"
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {
                "success": False,
                "error": str(e)
            }


class PerformanceMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
    
    async def record_metrics(self, metrics_data: Dict[str, Any]) -> PerformanceMetrics:
        """–ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        metrics = PerformanceMetrics(**metrics_data)
        self.db.add(metrics)
        await self.db.commit()
        await self.db.refresh(metrics)
        return metrics
    
    async def get_model_metrics(
        self, 
        model_id: int, 
        start_time: datetime = None, 
        end_time: datetime = None
    ) -> List[PerformanceMetrics]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        stmt = select(PerformanceMetrics).where(PerformanceMetrics.model_id == model_id)
        
        if start_time:
            stmt = stmt.where(PerformanceMetrics.timestamp >= start_time)
        if end_time:
            stmt = stmt.where(PerformanceMetrics.timestamp <= end_time)
        
        stmt = stmt.order_by(PerformanceMetrics.timestamp.desc())
        
        result = await self.db.execute(stmt)
        return result.scalars().all()
    
    async def get_performance_summary(self, model_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        metrics = await self.get_model_metrics(model_id, start_time, end_time)
        
        if not metrics:
            return {}
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        response_times = [m.response_time for m in metrics if m.response_time]
        token_counts = [m.tokens_generated for m in metrics if m.tokens_generated]
        success_rates = [m.success_rate for m in metrics if m.success_rate]
        
        return {
            "total_requests": len(metrics),
            "avg_response_time": np.mean(response_times) if response_times else 0,
            "avg_tokens_generated": np.mean(token_counts) if token_counts else 0,
            "avg_success_rate": np.mean(success_rates) if success_rates else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0,
        }
    
    async def log_api_call(self, log_data: Dict[str, Any]) -> APILog:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ API –≤—ã–∑–æ–≤–∞"""
        log = APILog(**log_data)
        self.db.add(log)
        await self.db.commit()
        await self.db.refresh(log)
        return log


class OptimizationService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    async def optimize_model(self, model_id: int, optimization_params: Dict[str, Any]) -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        model = await self._get_model(model_id)
        if not model:
            return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            performance = await self._analyze_performance(model_id)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            optimal_params = await self._calculate_optimal_params(performance, optimization_params)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            result = await self._apply_optimization(model.name, optimal_params)
            
            return {
                "model_id": model_id,
                "optimization_applied": True,
                "new_params": optimal_params,
                "performance_improvement": result.get("improvement", 0)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {"error": str(e)}
    
    async def _get_model(self, model_id: int) -> Optional[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        stmt = select(LLMModel).where(LLMModel.id == model_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def _analyze_performance(self, model_id: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)
        
        stmt = select(PerformanceMetrics).where(
            and_(
                PerformanceMetrics.model_id == model_id,
                PerformanceMetrics.timestamp >= start_time,
                PerformanceMetrics.timestamp <= end_time
            )
        )
        
        result = await self.db.execute(stmt)
        metrics = result.scalars().all()
        
        if not metrics:
            return {}
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        response_times = [m.response_time for m in metrics if m.response_time]
        token_counts = [m.tokens_generated for m in metrics if m.tokens_generated]
        
        return {
            "avg_response_time": np.mean(response_times) if response_times else 0,
            "avg_tokens": np.mean(token_counts) if token_counts else 0,
            "total_requests": len(metrics),
            "success_rate": sum(1 for m in metrics if m.success_rate > 0.8) / len(metrics)
        }
    
    async def _calculate_optimal_params(
        self, 
        performance: Dict[str, Any], 
        optimization_params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        target_response_time = optimization_params.get("target_response_time", 1.0)
        target_quality = optimization_params.get("target_quality", 0.8)
        
        current_response_time = performance.get("avg_response_time", 0)
        current_quality = performance.get("success_rate", 0)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        temperature_adjustment = 0.1 if current_quality < target_quality else -0.05
        top_p_adjustment = 0.05 if current_quality < target_quality else -0.02
        
        return {
            "temperature": max(0.1, min(1.0, 0.7 + temperature_adjustment)),
            "top_p": max(0.1, min(1.0, 0.9 + top_p_adjustment)),
            "num_predict": optimization_params.get("num_predict", 1000),
            "repeat_penalty": optimization_params.get("repeat_penalty", 1.1)
        }
    
    async def _apply_optimization(self, model_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫ –º–æ–¥–µ–ª–∏"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫ –º–æ–¥–µ–ª–∏
        # –ü–æ–∫–∞ —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∏–º—É–ª—è—Ü–∏—é
        
        return {
            "improvement": 0.15,  # 15% —É–ª—É—á—à–µ–Ω–∏–µ
            "applied_params": params
        }


class LLMTuningService:
    """–ì–ª–∞–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π LLM Tuning"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.model_manager = ModelManager(db_session)
        self.route_manager = RouteManager(db_session)
        self.rag_service = RAGService(db_session)
        self.tuning_service = TuningService(db_session)
        self.performance_monitor = PerformanceMonitor(db_session)
        self.optimization_service = OptimizationService(db_session)
    
    async def process_request(
        self, 
        request_type: str, 
        content: str, 
        use_rag: bool = False,
        optimization_level: str = "balanced"
    ) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π"""
        start_time = time.time()
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç
            route = await self.route_manager.get_route(request_type, content)
            if not route:
                return {"error": "–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–∞—Ä—à—Ä—É—Ç"}
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model = await self.model_manager.get_model(route.model_id)
            if not model:
                return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
            if use_rag:
                result = await self.rag_service.generate_with_rag(model.name, content)
            else:
                result = await self._generate_response(model.name, content, route.parameters)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            response_time = time.time() - start_time
            await self.performance_monitor.record_metrics({
                "model_id": model.id,
                "route_id": route.id,
                "request_type": request_type,
                "response_time": response_time,
                "tokens_generated": result.get("tokens_generated", 0),
                "success_rate": 1.0 if "response" in result else 0.0,
                "timestamp": datetime.now()
            })
            
            # –õ–æ–≥–∏—Ä—É–µ–º API –≤—ã–∑–æ–≤
            await self.performance_monitor.log_api_call({
                "model_id": model.id,
                "route_id": route.id,
                "request_type": request_type,
                "request_content": content[:1000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                "response_time": response_time,
                "status_code": 200,
                "timestamp": datetime.now()
            })
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return {"error": str(e)}
    
    async def _generate_response(
        self, 
        model_name: str, 
        content: str, 
        parameters: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏"""
        if not parameters:
            parameters = {
                "temperature": 0.7,
                "top_p": 0.9,
                "num_predict": 1000
            }
        
        response = await self.rag_service.ollama_client.post(
            f"/api/generate",
            json={
                "model": model_name,
                "prompt": content,
                "stream": False,
                "options": parameters
            }
        )
        
        return response.json()
    
    async def get_system_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            models = await self.model_manager.list_models()
            active_routes = len([r for r in self.route_manager._route_cache.values() if r.is_active])
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            total_requests = 0
            avg_response_time = 0
            
            if models:
                for model in models:
                    summary = await self.performance_monitor.get_performance_summary(model.id)
                    total_requests += summary.get("total_requests", 0)
                    avg_response_time += summary.get("avg_response_time", 0)
                
                avg_response_time /= len(models)
            
            return {
                "status": "healthy",
                "models_count": len(models),
                "active_routes": active_routes,
                "total_requests_24h": total_requests,
                "avg_response_time": avg_response_time,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }


class ABTestingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.ollama.url,
            timeout=settings.ollama.timeout
        )
    
    async def create_ab_test(self, test_data: Dict[str, Any]) -> ABTest:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ A/B —Ç–µ—Å—Ç–∞"""
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
            await self._validate_models(test_data['control_model'], test_data['variant_model'])
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞
            ab_test = ABTest(**test_data)
            self.db.add(ab_test)
            await self.db.commit()
            await self.db.refresh(ab_test)
            
            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω A/B —Ç–µ—Å—Ç: {ab_test.name}")
            return ab_test
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è A/B —Ç–µ—Å—Ç–∞: {e}")
            raise
    
    async def get_ab_test(self, test_id: int) -> Optional[ABTest]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ A/B —Ç–µ—Å—Ç–∞ –ø–æ ID"""
        stmt = select(ABTest).where(ABTest.id == test_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def list_ab_tests(
        self, 
        skip: int = 0, 
        limit: int = 100,
        status: Optional[ABTestStatus] = None,
        model_id: Optional[int] = None
    ) -> List[ABTest]:
        """–°–ø–∏—Å–æ–∫ A/B —Ç–µ—Å—Ç–æ–≤"""
        stmt = select(ABTest)
        
        if status:
            stmt = stmt.where(ABTest.status == status)
        if model_id:
            stmt = stmt.where(ABTest.model_id == model_id)
        
        stmt = stmt.offset(skip).limit(limit).order_by(ABTest.created_at.desc())
        result = await self.db.execute(stmt)
        return result.scalars().all()
    
    async def select_model_for_request(
        self, 
        test_id: int, 
        request_type: str,
        user_id: Optional[str] = None
    ) -> Tuple[str, str]:
        """–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ä–∞–º–∫–∞—Ö A/B —Ç–µ—Å—Ç–∞"""
        test = await self.get_ab_test(test_id)
        if not test or not test.is_active:
            raise ValueError("A/B —Ç–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if not self._matches_test_conditions(test, request_type, user_id):
            return test.control_model, "control"
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ traffic split
        import random
        if random.random() < test.traffic_split:
            return test.variant_model, "variant"
        else:
            return test.control_model, "control"
    
    async def record_ab_test_result(
        self, 
        test_id: int, 
        model_variant: str,
        metrics: Dict[str, Any]
    ):
        """–ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ A/B —Ç–µ—Å—Ç–∞"""
        test = await self.get_ab_test(test_id)
        if not test:
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        if model_variant == "control":
            test.control_metrics.update(metrics)
        else:
            test.variant_metrics.update(metrics)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
        if len(test.control_metrics) > 10 and len(test.variant_metrics) > 10:
            significance = await self._calculate_statistical_significance(test)
            test.statistical_significance = significance
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
            if significance > 0.95:
                test.winner = await self._determine_winner(test)
        
        await self.db.commit()
    
    async def _validate_models(self, control_model: str, variant_model: str):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è A/B —Ç–µ—Å—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –≤ Ollama
            control_response = await self.ollama_client.get("/api/tags")
            available_models = [m["name"] for m in control_response.json().get("models", [])]
            
            if control_model not in available_models:
                raise ValueError(f"–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å {control_model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            if variant_model not in available_models:
                raise ValueError(f"–¢–µ—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å {variant_model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            raise
    
    def _matches_test_conditions(
        self, 
        test: ABTest, 
        request_type: str, 
        user_id: Optional[str]
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —É—Å–ª–æ–≤–∏—è–º —Ç–µ—Å—Ç–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        if test.request_types and request_type not in test.request_types:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–≥–º–µ–Ω—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if test.user_segments and user_id:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            pass
        
        return True
    
    async def _calculate_statistical_significance(self, test: ABTest) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏"""
        try:
            # –ü—Ä–æ—Å—Ç–æ–π t-test –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
            control_scores = test.control_metrics.get('quality_scores', [])
            variant_scores = test.variant_metrics.get('quality_scores', [])
            
            if len(control_scores) < 10 or len(variant_scores) < 10:
                return 0.0
            
            import numpy as np
            from scipy import stats
            
            t_stat, p_value = stats.ttest_ind(control_scores, variant_scores)
            return 1 - p_value
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏: {e}")
            return 0.0
    
    async def _determine_winner(self, test: ABTest) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è A/B —Ç–µ—Å—Ç–∞"""
        control_avg = np.mean(test.control_metrics.get('quality_scores', [0]))
        variant_avg = np.mean(test.variant_metrics.get('quality_scores', [0]))
        
        if variant_avg > control_avg * 1.05:  # 5% —É–ª—É—á—à–µ–Ω–∏–µ
            return "variant"
        elif control_avg > variant_avg * 1.05:
            return "control"
        else:
            return "none"


class AutoOptimizationService:
    """–°–µ—Ä–≤–∏—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.ollama.url,
            timeout=settings.ollama.timeout
        )
    
    async def optimize_model(
        self, 
        model_id: int, 
        optimization_type: OptimizationType,
        target_metrics: Dict[str, Any]
    ) -> ModelOptimization:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model = await self._get_model(model_id)
            if not model:
                raise ValueError(f"–ú–æ–¥–µ–ª—å {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            optimization = ModelOptimization(
                model_id=model_id,
                optimization_type=optimization_type,
                target_metrics=target_metrics,
                status="running"
            )
            self.db.add(optimization)
            await self.db.commit()
            await self.db.refresh(optimization)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ
            asyncio.create_task(self._run_optimization(optimization.id))
            
            return optimization
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    async def _run_optimization(self, optimization_id: int):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            optimization = await self._get_optimization(optimization_id)
            if not optimization:
                return
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            before_metrics = await self._get_model_metrics(optimization.model_id)
            optimization.before_metrics = before_metrics
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            new_params = await self._apply_optimization(
                optimization.optimization_type,
                optimization.target_metrics
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            after_metrics = await self._test_optimized_model(
                optimization.model_id,
                new_params
            )
            optimization.after_metrics = after_metrics
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–∏—è
            improvement = self._calculate_improvement(before_metrics, after_metrics)
            optimization.improvement = improvement
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            optimization.status = "completed"
            optimization.completed_at = datetime.utcnow()
            
            await self.db.commit()
            logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è {optimization_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ {optimization_id}: {e}")
            optimization = await self._get_optimization(optimization_id)
            if optimization:
                optimization.status = "failed"
                optimization.error_message = str(e)
                await self.db.commit()
    
    async def _apply_optimization(
        self, 
        optimization_type: OptimizationType,
        target_metrics: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        if optimization_type == OptimizationType.PERFORMANCE:
            return await self._optimize_performance(target_metrics)
        elif optimization_type == OptimizationType.QUALITY:
            return await self._optimize_quality(target_metrics)
        elif optimization_type == OptimizationType.MEMORY:
            return await self._optimize_memory(target_metrics)
        elif optimization_type == OptimizationType.LATENCY:
            return await self._optimize_latency(target_metrics)
        else:  # HYBRID
            return await self._optimize_hybrid(target_metrics)
    
    async def _optimize_performance(self, target_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            "num_parallel": 4,
            "batch_size": 1024,
            "num_ctx": 4096,
            "num_gpu": 1,
            "num_thread": 8
        }
    
    async def _optimize_quality(self, target_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞"""
        return {
            "temperature": 0.3,
            "top_p": 0.9,
            "top_k": 40,
            "repeat_penalty": 1.1,
            "num_ctx": 8192
        }
    
    async def _optimize_memory(self, target_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏"""
        return {
            "num_ctx": 2048,
            "batch_size": 512,
            "num_parallel": 1,
            "num_gpu": 0
        }
    
    async def _optimize_latency(self, target_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏"""
        return {
            "num_ctx": 1024,
            "batch_size": 256,
            "num_parallel": 2,
            "num_thread": 4
        }
    
    async def _optimize_hybrid(self, target_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–∏–±—Ä–∏–¥–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"""
        return {
            "num_ctx": 4096,
            "batch_size": 768,
            "num_parallel": 2,
            "temperature": 0.5,
            "top_p": 0.9
        }
    
    async def _get_model_metrics(self, model_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
        stmt = select(PerformanceMetrics).where(
            PerformanceMetrics.model_id == model_id
        ).order_by(PerformanceMetrics.timestamp.desc()).limit(100)
        
        result = await self.db.execute(stmt)
        metrics = result.scalars().all()
        
        if not metrics:
            return {}
        
        return {
            "avg_response_time": np.mean([m.response_time for m in metrics]),
            "avg_quality_score": np.mean([m.user_feedback or 0 for m in metrics]),
            "success_rate": np.mean([1 if m.success else 0 for m in metrics]),
            "avg_memory_usage": np.mean([m.memory_usage or 0 for m in metrics]),
            "avg_cpu_usage": np.mean([m.cpu_usage or 0 for m in metrics])
        }
    
    async def _test_optimized_model(
        self, 
        model_id: int, 
        new_params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∏–º—É–ª—è—Ü–∏—é
        return {
            "avg_response_time": 1.5,
            "avg_quality_score": 4.2,
            "success_rate": 0.98,
            "avg_memory_usage": 2048,
            "avg_cpu_usage": 45.0
        }
    
    def _calculate_improvement(
        self, 
        before: Dict[str, Any], 
        after: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π"""
        improvement = {}
        for key in before:
            if key in after and before[key] != 0:
                if key in ['avg_response_time', 'avg_memory_usage', 'avg_cpu_usage']:
                    # –ú–µ–Ω—å—à–µ - –ª—É—á—à–µ
                    improvement[key] = (before[key] - after[key]) / before[key] * 100
                else:
                    # –ë–æ–ª—å—à–µ - –ª—É—á—à–µ
                    improvement[key] = (after[key] - before[key]) / before[key] * 100
        
        return improvement


class QualityAssessmentService:
    """–°–µ—Ä–≤–∏—Å –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
    
    async def assess_quality(
        self, 
        model_id: int,
        request_text: str,
        response_text: str,
        context_documents: List[Dict[str, Any]] = None
    ) -> QualityAssessment:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞"""
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Ü–µ–Ω–∫—É –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
            relevance_score = await self._assess_relevance(request_text, response_text, context_documents)
            accuracy_score = await self._assess_accuracy(response_text, context_documents)
            coherence_score = await self._assess_coherence(response_text)
            fluency_score = await self._assess_fluency(response_text)
            completeness_score = await self._assess_completeness(request_text, response_text)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
            overall_score = (relevance_score + accuracy_score + coherence_score + 
                           fluency_score + completeness_score) / 5
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ–± –æ—Ü–µ–Ω–∫–µ
            assessment = QualityAssessment(
                model_id=model_id,
                request_text=request_text,
                response_text=response_text,
                context_documents=context_documents or [],
                relevance_score=relevance_score,
                accuracy_score=accuracy_score,
                coherence_score=coherence_score,
                fluency_score=fluency_score,
                completeness_score=completeness_score,
                overall_score=overall_score,
                assessed_by="system",
                assessment_method="automatic"
            )
            
            self.db.add(assessment)
            await self.db.commit()
            await self.db.refresh(assessment)
            
            return assessment
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
            raise
    
    async def _assess_relevance(
        self, 
        request: str, 
        response: str, 
        context: List[Dict[str, Any]]
    ) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        request_words = set(request.lower().split())
        response_words = set(response.lower().split())
        
        if not request_words:
            return 0.0
        
        overlap = len(request_words.intersection(response_words))
        return min(overlap / len(request_words), 1.0)
    
    async def _assess_accuracy(self, response: str, context: List[Dict[str, Any]]) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ª–∏—á–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if not context:
            return 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏ –æ—Ç–≤–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_text = " ".join([doc.get('content', '') for doc in context])
        context_words = set(context_text.lower().split())
        response_words = set(response.lower().split())
        
        if not context_words:
            return 0.5
        
        overlap = len(context_words.intersection(response_words))
        return min(overlap / len(response_words), 1.0)
    
    async def _assess_coherence(self, response: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        sentences = response.split('.')
        if len(sentences) < 2:
            return 0.8  # –ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–Ω—ã–º
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        avg_length = sum(len(s.split()) for s in sentences) / len(sentences)
        
        if 5 <= avg_length <= 20:
            return 0.9
        elif 3 <= avg_length <= 25:
            return 0.7
        else:
            return 0.5
    
    async def _assess_fluency(self, response: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ –±–µ–≥–ª–æ—Å—Ç–∏ —è–∑—ã–∫–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ª–∏—á–∏—è –æ—à–∏–±–æ–∫
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        has_capitalization = response[0].isupper() if response else False
        has_punctuation = response.endswith(('.', '!', '?')) if response else False
        reasonable_length = 10 <= len(response.split()) <= 500
        
        score = 0.0
        if has_capitalization:
            score += 0.3
        if has_punctuation:
            score += 0.3
        if reasonable_length:
            score += 0.4
        
        return score
    
    async def _assess_completeness(self, request: str, response: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –æ—Ç–≤–µ—Ç–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –∑–∞–ø—Ä–æ—Å–∞
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ —Å –æ–∂–∏–¥–∞–µ–º–æ–π
        request_words = len(request.split())
        response_words = len(response.split())
        
        if request_words == 0:
            return 0.5
        
        ratio = response_words / request_words
        
        if ratio >= 2.0:
            return 0.9  # –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç
        elif ratio >= 1.0:
            return 0.7  # –ê–¥–µ–∫–≤–∞—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç
        elif ratio >= 0.5:
            return 0.5  # –ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
        else:
            return 0.3  # –û—á–µ–Ω—å –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
    
    async def get_quality_stats(
        self, 
        model_id: int, 
        days: int = 30
    ) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏"""
        from datetime import datetime, timedelta
        
        start_date = datetime.utcnow() - timedelta(days=days)
        
        stmt = select(QualityAssessment).where(
            and_(
                QualityAssessment.model_id == model_id,
                QualityAssessment.created_at >= start_date
            )
        )
        
        result = await self.db.execute(stmt)
        assessments = result.scalars().all()
        
        if not assessments:
            return {}
        
        return {
            "total_assessments": len(assessments),
            "avg_overall_score": np.mean([a.overall_score for a in assessments]),
            "avg_relevance": np.mean([a.relevance_score for a in assessments]),
            "avg_accuracy": np.mean([a.accuracy_score for a in assessments]),
            "avg_coherence": np.mean([a.coherence_score for a in assessments]),
            "avg_fluency": np.mean([a.fluency_score for a in assessments]),
            "avg_completeness": np.mean([a.completeness_score for a in assessments]),
            "score_distribution": {
                "excellent": len([a for a in assessments if a.overall_score >= 0.8]),
                "good": len([a for a in assessments if 0.6 <= a.overall_score < 0.8]),
                "fair": len([a for a in assessments if 0.4 <= a.overall_score < 0.6]),
                "poor": len([a for a in assessments if a.overall_score < 0.4])
            }
        }


class SystemHealthService:
    """–°–µ—Ä–≤–∏—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.ollama.url,
            timeout=settings.ollama.timeout
        )
    
    async def collect_system_health(self) -> SystemHealth:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            cpu_usage = await self._get_cpu_usage()
            memory_usage = await self._get_memory_usage()
            disk_usage = await self._get_disk_usage()
            network_io = await self._get_network_io()
            
            # Ollama –º–µ—Ç—Ä–∏–∫–∏
            ollama_status = await self._get_ollama_status()
            active_models = await self._get_active_models_count()
            total_requests = await self._get_total_requests()
            error_rate = await self._get_error_rate()
            
            # RAG –º–µ—Ç—Ä–∏–∫–∏
            rag_status = await self._get_rag_status()
            documents_count = await self._get_documents_count()
            vector_db_status = await self._get_vector_db_status()
            
            # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            response_time_avg = await self._get_avg_response_time()
            requests_per_minute = await self._get_requests_per_minute()
            active_connections = await self._get_active_connections()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
            alerts = await self._check_alerts(
                cpu_usage, memory_usage, error_rate, response_time_avg
            )
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ –∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã
            health = SystemHealth(
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                disk_usage=disk_usage,
                network_io=network_io,
                ollama_status=ollama_status,
                active_models=active_models,
                total_requests=total_requests,
                error_rate=error_rate,
                rag_status=rag_status,
                documents_count=documents_count,
                vector_db_status=vector_db_status,
                response_time_avg=response_time_avg,
                requests_per_minute=requests_per_minute,
                active_connections=active_connections,
                alerts=alerts
            )
            
            self.db.add(health)
            await self.db.commit()
            await self.db.refresh(health)
            
            return health
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –∑–¥–æ—Ä–æ–≤—å—è: {e}")
            raise
    
    async def _get_cpu_usage(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è CPU"""
        try:
            import psutil
            return psutil.cpu_percent(interval=1)
        except:
            return 0.0
    
    async def _get_memory_usage(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        try:
            import psutil
            memory = psutil.virtual_memory()
            return memory.percent
        except:
            return 0.0
    
    async def _get_disk_usage(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∏—Å–∫–∞"""
        try:
            import psutil
            disk = psutil.disk_usage('/')
            return (disk.used / disk.total) * 100
        except:
            return 0.0
    
    async def _get_network_io(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Ç–µ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        try:
            import psutil
            network = psutil.net_io_counters()
            return {
                "bytes_sent": network.bytes_sent,
                "bytes_recv": network.bytes_recv,
                "packets_sent": network.packets_sent,
                "packets_recv": network.packets_recv
            }
        except:
            return {}
    
    async def _get_ollama_status(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ Ollama"""
        try:
            response = await self.ollama_client.get("/api/tags")
            if response.status_code == 200:
                return "running"
            else:
                return "error"
        except:
            return "stopped"
    
    async def _get_active_models_count(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            response = await self.ollama_client.get("/api/tags")
            if response.status_code == 200:
                return len(response.json().get("models", []))
            return 0
        except:
            return 0
    
    async def _get_total_requests(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å"""
        from datetime import datetime, timedelta
        
        start_time = datetime.utcnow() - timedelta(hours=1)
        
        stmt = select(func.count(PerformanceMetrics.id)).where(
            PerformanceMetrics.timestamp >= start_time
        )
        
        result = await self.db.execute(stmt)
        return result.scalar() or 0
    
    async def _get_error_rate(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –æ—à–∏–±–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å"""
        from datetime import datetime, timedelta
        
        start_time = datetime.utcnow() - timedelta(hours=1)
        
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
        total_stmt = select(func.count(PerformanceMetrics.id)).where(
            PerformanceMetrics.timestamp >= start_time
        )
        total_result = await self.db.execute(total_stmt)
        total = total_result.scalar() or 0
        
        if total == 0:
            return 0.0
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫
        error_stmt = select(func.count(PerformanceMetrics.id)).where(
            and_(
                PerformanceMetrics.timestamp >= start_time,
                PerformanceMetrics.success == False
            )
        )
        error_result = await self.db.execute(error_stmt)
        errors = error_result.scalar() or 0
        
        return errors / total
    
    async def _get_rag_status(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ RAG —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
            if settings.vector_db.type == VectorDBType.CHROMA:
                import httpx
                client = httpx.AsyncClient()
                response = await client.get(f"http://{settings.vector_db.chroma_host}:{settings.vector_db.chroma_port}/api/v1/heartbeat")
                await client.aclose()
                
                if response.status_code == 200:
                    return "active"
                else:
                    return "error"
            else:
                return "active"  # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –ë–î
        except:
            return "inactive"
    
    async def _get_documents_count(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ RAG"""
        stmt = select(func.count(RAGDocument.id))
        result = await self.db.execute(stmt)
        return result.scalar() or 0
    
    async def _get_vector_db_status(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î"""
        return await self._get_rag_status()
    
    async def _get_avg_response_time(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å"""
        from datetime import datetime, timedelta
        
        start_time = datetime.utcnow() - timedelta(hours=1)
        
        stmt = select(func.avg(PerformanceMetrics.response_time)).where(
            PerformanceMetrics.timestamp >= start_time
        )
        
        result = await self.db.execute(stmt)
        avg_time = result.scalar()
        return float(avg_time) if avg_time else 0.0
    
    async def _get_requests_per_minute(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É"""
        from datetime import datetime, timedelta
        
        start_time = datetime.utcnow() - timedelta(minutes=1)
        
        stmt = select(func.count(PerformanceMetrics.id)).where(
            PerformanceMetrics.timestamp >= start_time
        )
        
        result = await self.db.execute(stmt)
        return float(result.scalar() or 0)
    
    async def _get_active_connections(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        # –ü—Ä–æ—Å—Ç–∞—è —Å–∏–º—É–ª—è—Ü–∏—è
        return 5
    
    async def _check_alerts(
        self, 
        cpu_usage: float, 
        memory_usage: float, 
        error_rate: float, 
        response_time: float
    ) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤"""
        alerts = []
        
        if cpu_usage > 90:
            alerts.append({
                "type": "warning",
                "message": f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU: {cpu_usage:.1f}%",
                "timestamp": datetime.utcnow().isoformat()
            })
        
        if memory_usage > 90:
            alerts.append({
                "type": "warning",
                "message": f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_usage:.1f}%",
                "timestamp": datetime.utcnow().isoformat()
            })
        
        if error_rate > 0.05:
            alerts.append({
                "type": "error",
                "message": f"–í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫: {error_rate:.2%}",
                "timestamp": datetime.utcnow().isoformat()
            })
        
        if response_time > 5.0:
            alerts.append({
                "type": "warning",
                "message": f"–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f}s",
                "timestamp": datetime.utcnow().isoformat()
            })
        
        return alerts 