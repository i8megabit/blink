"""FastAPI-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº reLink."""

from __future__ import annotations

import asyncio
import json
import os
import re
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Tuple

import chromadb
import httpx
import nltk
import numpy as np
import ollama
from bs4 import BeautifulSoup
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Request, Response, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from pydantic import BaseModel, ValidationError
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import (
    DateTime, Float, ForeignKey, Index, Integer, JSON, String, Text,
    func, select
)
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÑƒÐ»Ð¸
from .config import settings, get_settings
from .exceptions import (
    RelinkBaseException, ErrorHandler, ErrorResponse,
    ValidationException, AuthenticationException, AuthorizationException,
    NotFoundException, DatabaseException, OllamaException,
    raise_not_found, raise_validation_error, raise_authentication_error,
    raise_authorization_error, raise_database_error, raise_ollama_error
)
from .monitoring import (
    logger, metrics_collector, performance_monitor, 
    get_metrics, get_health_status, monitor_operation,
    MonitoringMiddleware
)
from .cache import (
    cache_manager, cache_result, invalidate_cache,
    SEOCache, UserCache
)
from .validation import (
    UserRegistrationModel, UserLoginModel, DomainAnalysisModel,
    SEORecommendationModel, ExportModel, PaginationModel,
    validate_request, validate_response, validate_and_clean_data
)
from .auth import (
    get_current_user, create_access_token, get_password_hash, verify_password,
    User, UserCreate, UserResponse, Token, TokenData,
    UserRegistrationRequest, UserLoginRequest
)
from .database import get_db, engine
from .models import Base, User, Domain, WordPressPost, AnalysisHistory, Diagram, DiagramEmbedding
from .llm_router import system_analyzer, llm_router
from .diagram_service import DiagramService, DiagramGenerationRequest

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° NLTK Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Ð ÑƒÑÑÐºÐ¸Ðµ ÑÑ‚Ð¾Ð¿-ÑÐ»Ð¾Ð²Ð°
RUSSIAN_STOP_WORDS = set(stopwords.words('russian'))

# ðŸ”’ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ Ð¡Ð•ÐœÐÐ¤ÐžÐ  Ð”Ð›Ð¯ ÐžÐ“Ð ÐÐÐ˜Ð§Ð•ÐÐ˜Ð¯ ÐÐÐ“Ð Ð£Ð—ÐšÐ˜ ÐÐ OLLAMA
OLLAMA_SEMAPHORE = asyncio.Semaphore(1)

@dataclass
class SemanticEntity:
    """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° LLM."""
    entity_type: str
    value: str
    confidence: float
    context: str

@dataclass
class ThematicCluster:
    """Ð¢ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€ ÑÑ‚Ð°Ñ‚ÐµÐ¹."""
    cluster_id: str
    theme: str
    keywords: List[str]
    articles_count: int
    semantic_density: float

@dataclass
class AIThought:
    """Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¼Ñ‹ÑÐ»ÑŒ Ð˜Ð˜ Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¾Ð¹."""
    thought_id: str
    stage: str  # analyzing, connecting, evaluating, optimizing
    content: str
    confidence: float
    semantic_weight: float
    related_concepts: List[str]
    reasoning_chain: List[str]
    timestamp: datetime
    
@dataclass
class SemanticConnection:
    """Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸ÑÐ¼Ð¸."""
    source_concept: str
    target_concept: str
    connection_type: str  # semantic, causal, hierarchical, temporal
    strength: float
    evidence: List[str]
    context_keywords: Set[str]

class WebSocketManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ WebSocket ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°."""

    def __init__(self) -> None:
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str) -> None:
        """ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°."""
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½: {client_id}")

    def disconnect(self, client_id: str) -> None:
        """ÐžÑ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°."""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"WebSocket Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½: {client_id}")

    async def send_progress(self, client_id: str, message: dict) -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð¼Ñƒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json(message)
                logger.debug(f"ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ {client_id}: {message}")
            except Exception as e:
                logger.error(f"Error sending progress to {client_id}: {e}")

    async def send_error(self, client_id: str, error: str, details: str = "") -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾ÑˆÐ¸Ð±ÐºÐ¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ."""
        await self.send_progress(client_id, {
            "type": "error",
            "message": error,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })

    async def send_step(self, client_id: str, step: str, current: int, total: int, details: str = "") -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ ÑˆÐ°Ð³Ðµ."""
        await self.send_progress(client_id, {
            "type": "progress",
            "step": step,
            "current": current,
            "total": total,
            "percentage": round((current / total) * 100) if total > 0 else 0,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })

    async def send_ollama_info(self, client_id: str, info: dict) -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ollama."""
        await self.send_progress(client_id, {
            "type": "ollama",
            "info": info,
            "timestamp": datetime.now().isoformat()
        })

    async def send_ai_thinking(self, client_id: str, thought: str, thinking_stage: str = "analyzing", emoji: str = "ðŸ¤”") -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° 'Ð¼Ñ‹ÑÐ»ÐµÐ¹' Ð˜Ð˜ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json({
                    "type": "ai_thinking",
                    "thought": thought,
                    "thinking_stage": thinking_stage,
                    "emoji": emoji,
                    "timestamp": datetime.now().isoformat()
                })
                logger.debug(f"ÐœÑ‹ÑÐ»ÑŒ Ð˜Ð˜ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð° {client_id}: {thought[:50]}...")
            except Exception as e:
                logger.error(f"Error sending AI thinking to {client_id}: {e}")
    
    async def send_enhanced_ai_thinking(self, client_id: str, ai_thought: AIThought) -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ñ‹ÑÐ»ÐµÐ¹ Ð˜Ð˜ Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¾Ð¹."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json({
                    "type": "enhanced_ai_thinking",
                    "thought_id": ai_thought.thought_id,
                    "stage": ai_thought.stage,
                    "content": ai_thought.content,
                    "confidence": ai_thought.confidence,
                    "semantic_weight": ai_thought.semantic_weight,
                    "related_concepts": ai_thought.related_concepts,
                    "reasoning_chain": ai_thought.reasoning_chain,
                    "timestamp": ai_thought.timestamp.isoformat()
                })
                logger.debug(f"Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ Ð¼Ñ‹ÑÐ»ÑŒ Ð˜Ð˜ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð° {client_id}: {ai_thought.content[:50]}...")
            except Exception as e:
                logger.error(f"Error sending enhanced AI thinking to {client_id}: {e}")

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ WebSocket
websocket_manager = WebSocketManager()

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ FastAPI Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
app = FastAPI(
    title=settings.api.title,
    description=settings.api.description,
    version=settings.api.version,
    debug=settings.api.debug,
    docs_url=settings.api.docs_url,
    redoc_url=settings.api.redoc_url
)

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.api.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ middleware Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
app.add_middleware(MonitoringMiddleware)

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
def initialize_rag_system() -> None:
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ñ ChromaDB."""
    try:
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° ChromaDB
        chroma_client = chromadb.Client()
        
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
        collection = chroma_client.create_collection(
            name="relink_documents",
            metadata={"description": "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ reLink"}
        )
        
        logger.info("RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ñ ChromaDB")
        return collection
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: {e}")
        return None

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ RAG ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸
rag_collection = initialize_rag_system()

class AdvancedRAGManager:
    """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹."""
    
    def __init__(self) -> None:
        self.collection = rag_collection
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=RUSSIAN_STOP_WORDS,
            ngram_range=(1, 2)
        )
    
    async def create_semantic_knowledge_base(self, domain, posts, client_id=None):
        # ÐŸÑ€Ð¾ÐºÑÐ¸Ñ€ÑƒÐµÐ¼ Ð²Ñ‹Ð·Ð¾Ð² Ðº Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñƒ Ð¼Ñ‹ÑÐ»ÐµÐ¹
        return await generate_ai_thoughts_for_domain(domain, posts, client_id)

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ RAG
rag_manager = AdvancedRAGManager()

# Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
class RecommendRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÑÑÑ‹Ð»Ð¾Ðº."""
    text: str

class WPRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° WordPress-ÑÐ°Ð¹Ñ‚Ð°."""
    domain: str
    client_id: Optional[str] = None
    comprehensive: Optional[bool] = False

class BenchmarkRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°."""
    name: str
    description: Optional[str] = None
    benchmark_type: str = "seo_advanced"
    models: List[str] = []
    iterations: int = 3
    client_id: Optional[str] = None

class ModelConfigRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸."""
    model_name: str
    display_name: Optional[str] = None
    description: Optional[str] = None
    default_parameters: Optional[dict] = None
    seo_optimized_params: Optional[dict] = None
    benchmark_params: Optional[dict] = None

class SEOAnalysisResult(BaseModel):
    """Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ SEO Ð°Ð½Ð°Ð»Ð¸Ð·Ð°."""
    domain: str
    analysis_date: datetime
    score: float
    recommendations: List[dict]
    metrics: dict
    status: str

class DomainAnalysisRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°."""
    domain: str
    comprehensive: Optional[bool] = False

class CompetitorAnalysisRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²."""
    domain: str
    competitors: List[str]

class AnalysisHistoryRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²."""
    limit: int = 10
    offset: int = 0

class ExportRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…."""
    format: str  # json, csv, pdf
    analysis_ids: List[int]

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ollama
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5:7b-instruct-turbo")

# ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²
OPTIMAL_CONTEXT_SIZE = 3072
OPTIMAL_PREDICTION_SIZE = 800
OPTIMAL_TEMPERATURE = 0.3
OPTIMAL_TOP_P = 0.85
OPTIMAL_TOP_K = 50
OPTIMAL_REPEAT_PENALTY = 1.08

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ñ‹ÑÐ»ÐµÐ¹ Ð˜Ð˜
async def generate_ai_thoughts_for_domain(domain: str, posts: List[dict], client_id: str = None) -> List[AIThought]:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¼Ñ‹ÑÐ»ÐµÐ¹ Ð˜Ð˜ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°."""
    thoughts = []
    
    if client_id:
        await websocket_manager.send_ai_thinking(
            client_id, 
            f"ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð¾Ð¼ÐµÐ½Ð° {domain}...", 
            "analyzing", 
            "ðŸ”"
        )
    
    # ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
    content_thought = AIThought(
        thought_id=f"content_analysis_{domain}",
        stage="analyzing",
        content=f"ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ {len(posts)} ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð½Ð° Ð´Ð¾Ð¼ÐµÐ½Ðµ {domain}",
        confidence=0.8,
        semantic_weight=0.7,
        related_concepts=["ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚", "Ð°Ð½Ð°Ð»Ð¸Ð·", "ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ°"],
        reasoning_chain=["Ð¿Ð¾Ð´ÑÑ‡ÐµÑ‚ ÑÑ‚Ð°Ñ‚ÐµÐ¹", "Ð¾Ñ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°"],
        timestamp=datetime.utcnow()
    )
    thoughts.append(content_thought)
    
    if client_id:
        await websocket_manager.send_enhanced_ai_thinking(client_id, content_thought)
    
    # ÐŸÐ¾Ð¸ÑÐº ÑÐ²ÑÐ·ÐµÐ¹
    connection_thought = AIThought(
        thought_id=f"connection_search_{domain}",
        stage="connecting",
        content="Ð˜Ñ‰Ñƒ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ ÑÑ‚Ð°Ñ‚ÑŒÑÐ¼Ð¸",
        confidence=0.9,
        semantic_weight=0.8,
        related_concepts=["ÑÐ²ÑÐ·Ð¸", "ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ°", "Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸"],
        reasoning_chain=["Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼", "Ð¿Ð¾Ð¸ÑÐº Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ð¹"],
        timestamp=datetime.utcnow()
    )
    thoughts.append(connection_thought)
    
    if client_id:
        await websocket_manager.send_enhanced_ai_thinking(client_id, connection_thought)
    
    return thoughts

# API endpoints
@app.get("/")
async def root():
    """ÐšÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ endpoint."""
    return {"message": "reLink SEO Platform v4.1.1.022 Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½!"}

@app.get("/health")
async def health_check():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    return {"status": "healthy", "version": settings.api.version}

@app.get("/api/v1/health")
async def api_health():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ API."""
    return {"status": "healthy", "version": settings.api.version}

@app.get("/api/v1/version")
async def get_version():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÑ€ÑÐ¸Ð¸ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    try:
        version_file = Path("VERSION")
        if version_file.exists():
            with open(version_file, 'r', encoding='utf-8') as f:
                version = f.read().strip()
        else:
            version = settings.api.version
        
        return {
            "version": version,
            "buildDate": datetime.now().strftime('%Y-%m-%d'),
            "commitHash": os.getenv("GIT_COMMIT_HASH", ""),
            "environment": os.getenv("ENVIRONMENT", "development")
        }
    except Exception as e:
        return {
            "version": settings.api.version,
            "buildDate": datetime.now().strftime('%Y-%m-%d'),
            "error": str(e)
        }

@app.get("/api/v1/settings")
async def get_settings():
    """Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº Ð´Ð»Ñ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ð°."""
    return {
        "theme": "light",
        "language": "ru",
        "features": {
            "ai_recommendations": True,
            "advanced_benchmark": True,
            "notifications": True,
            "export": True
        },
        "version": settings.api.version
    }

@app.get("/api/v1/ollama_status")
async def get_ollama_status():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ollama."""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get("http://ollama:11434/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [model.get("name", "") for model in models]
                
                return {
                    "ready_for_work": len(model_names) > 0,
                    "server_available": True,
                    "model_loaded": len(model_names) > 0,
                    "message": f"Ð“Ð¾Ñ‚Ð¾Ð² Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ðµ ({len(model_names)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹)" if model_names else "ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹",
                    "status": "available",
                    "connection": "connected",
                    "models_count": len(model_names),
                    "available_models": model_names,
                    "timestamp": datetime.now().isoformat(),
                    "last_check": datetime.now().isoformat()
                }
            else:
                return {
                    "ready_for_work": False,
                    "server_available": False,
                    "model_loaded": False,
                    "message": f"Ollama Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» ÑÐ¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐ¾Ð¼ {response.status_code}",
                    "status": "error",
                    "connection": "disconnected",
                    "models_count": 0,
                    "available_models": [],
                    "timestamp": datetime.now().isoformat(),
                    "last_check": datetime.now().isoformat()
                }
    except Exception as e:
        return {
            "ready_for_work": False,
            "server_available": False,
            "model_loaded": False,
            "message": f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ: {str(e)}",
            "status": "unavailable",
            "connection": "disconnected",
            "models_count": 0,
            "available_models": [],
            "timestamp": datetime.now().isoformat(),
            "last_check": datetime.now().isoformat()
        }

@app.get("/api/v1/domains")
async def get_domains():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²."""
    try:
        async with engine.begin() as conn:
            result = await conn.execute(select(Domain))
            domains = result.scalars().all()
            return [
                {
                    "id": domain.id,
                    "name": domain.name,
                    "display_name": domain.display_name,
                    "description": domain.description,
                    "total_posts": domain.total_posts,
                    "total_analyses": domain.total_analyses,
                    "last_analysis_at": domain.last_analysis_at.isoformat() if domain.last_analysis_at else None
                }
                for domain in domains
            ]
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/v1/analysis_history")
async def get_analysis_history():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²."""
    try:
        async with engine.begin() as conn:
            result = await conn.execute(select(AnalysisHistory).order_by(AnalysisHistory.created_at.desc()))
            histories = result.scalars().all()
            return [
                {
                    "id": history.id,
                    "domain_id": history.domain_id,
                    "posts_analyzed": history.posts_analyzed,
                    "connections_found": history.connections_found,
                    "recommendations_generated": history.recommendations_generated,
                    "created_at": history.created_at.isoformat(),
                    "completed_at": history.completed_at.isoformat() if history.completed_at else None
                }
                for history in histories
            ]
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/v1/benchmarks")
async def get_benchmarks():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð²."""
    try:
        # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð´Ð»Ñ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð²
        return [
            {
                "id": 1,
                "name": "SEO Basic Benchmark",
                "description": "Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ SEO Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº",
                "benchmark_type": "seo_basic",
                "status": "completed",
                "overall_score": 85.5,
                "created_at": datetime.now().isoformat()
            }
        ]
    except Exception as e:
        return {"error": str(e)}

@app.get("/metrics")
async def get_metrics():
    """Endpoint Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Prometheus"""
    return await get_metrics()

@app.get("/api/v1/monitoring/health")
async def get_monitoring_health():
    """Endpoint Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼"""
    return await get_health_status()

@app.get("/api/v1/monitoring/stats")
async def get_monitoring_stats():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
    try:
        return {
            "uptime": "99.9%",
            "response_time": "150ms",
            "error_rate": "0.1%",
            "active_connections": 10,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸")

@app.get("/api/v1/optimization/report")
async def get_optimization_report():
    """
    ðŸ§  ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾Ð± Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ñ… Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº
    - ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
    - Ð˜ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    - Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ LLM
    """
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾Ñ‚ SystemAnalyzer
        report = await system_analyzer.get_optimization_report()
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
        enhanced_report = {
            **report,
            "optimization_status": {
                "llm_recommendations_applied": True,
                "adaptive_optimization_active": True,
                "performance_monitoring": True,
                "knowledge_base_entries": len(system_analyzer.knowledge_base),
                "last_optimization": datetime.utcnow().isoformat()
            },
            "system_insights": {
                "apple_silicon_detected": report["system_specs"]["apple_silicon"],
                "gpu_acceleration_available": report["system_specs"]["gpu_available"],
                "memory_optimization": "high" if report["system_specs"]["memory_gb"] >= 16 else "medium",
                "cpu_utilization_optimal": report["system_specs"]["cpu_count"] >= 6
            },
            "performance_metrics": {
                "avg_response_time": report["performance_history"]["recent_avg_response_time"],
                "success_rate": report["performance_history"]["recent_success_rate"],
                "total_requests_processed": report["performance_history"]["total_records"],
                "optimization_effectiveness": "excellent" if report["performance_history"]["recent_avg_response_time"] < 2.0 else "good"
            },
            "llm_insights": {
                "model_used": report["optimized_config"]["model"],
                "temperature_optimized": report["optimized_config"]["temperature"],
                "context_length_optimized": report["optimized_config"]["context_length"],
                "batch_size_optimized": report["optimized_config"]["batch_size"]
            }
        }
        
        return enhanced_report
        
    except Exception as e:
        logger.error(f"Error getting optimization report: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾Ð± Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸: {str(e)}"
        )

@app.get("/api/v1/optimization/environment")
async def get_optimization_environment():
    """
    ðŸ”§ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ollama
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
    Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ollama Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ
    """
    try:
        env_vars = await system_analyzer.get_environment_variables()
        
        return {
            "environment_variables": env_vars,
            "optimization_applied": True,
            "recommended_ollama_command": f"OLLAMA_HOST={env_vars['OLLAMA_HOST']} OLLAMA_ORIGINS={env_vars['OLLAMA_ORIGINS']} ollama serve",
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error getting environment variables: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ: {str(e)}"
        )

@app.post("/api/v1/optimization/trigger")
async def trigger_optimization():
    """
    ðŸ”„ ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    
    Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÑ‚ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚
    Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ» Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    """
    try:
        # Ð¡Ð±Ñ€Ð¾Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
        system_analyzer.optimized_config = None
        
        # Ð—Ð°Ð¿ÑƒÑÐº Ð½Ð¾Ð²Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        new_config = await system_analyzer.optimize_config()
        
        return {
            "message": "ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°",
            "new_config": {
                "model": new_config.model,
                "num_gpu": new_config.num_gpu,
                "num_thread": new_config.num_thread,
                "batch_size": new_config.batch_size,
                "context_length": new_config.context_length,
                "semaphore_limit": new_config.semaphore_limit
            },
            "optimization_timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error triggering optimization: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸: {str(e)}"
        )

@app.get("/api/v1/cache/stats")
async def get_cache_stats():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÐºÑÑˆÐ°"""
    try:
        return {
            "memory_cache_size": 0,
            "redis_cache_size": 0,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÐºÑÑˆÐ°")

@app.post("/api/v1/cache/clear")
async def clear_cache():
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÐºÑÑˆÐ°"""
    try:
        return {"success": True, "message": "ÐšÑÑˆ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½"}
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ ÐºÑÑˆÐ°")

@app.delete("/api/v1/cache/{pattern}")
async def clear_cache_pattern(pattern: str):
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÐºÑÑˆÐ° Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñƒ"""
    try:
        return {"success": True, "deleted_count": 0, "pattern": pattern}
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ ÐºÑÑˆÐ°")

# Endpoints Ð´Ð»Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
@app.post("/api/v1/auth/register", response_model=UserResponse)
async def register_user(user_data: UserRegistrationRequest, db: AsyncSession = Depends(get_db)):
    """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ email
        result = await db.execute(select(User).where(User.email == user_data.email))
        if result.scalar_one_or_none():
            raise HTTPException(
                status_code=400,
                detail="ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ email ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚"
            )
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        hashed_password = get_password_hash(user_data.password)
        db_user = User(
            email=user_data.email,
            username=user_data.username,
            hashed_password=hashed_password
        )
        
        db.add(db_user)
        await db.commit()
        await db.refresh(db_user)
        
        return UserResponse(
            id=db_user.id,
            email=db_user.email,
            username=db_user.username,
            is_active=db_user.is_active,
            created_at=db_user.created_at
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ")

@app.post("/api/v1/auth/login", response_model=Token)
async def login_user(user_data: UserLoginRequest, db: AsyncSession = Depends(get_db)):
    """Ð’Ñ…Ð¾Ð´ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
    try:
        # Ð˜Ñ‰ÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        result = await db.execute(select(User).where(User.email == user_data.email))
        user = result.scalar_one_or_none()
        
        if not user or not verify_password(user_data.password, user.hashed_password):
            raise HTTPException(
                status_code=401,
                detail="ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ email Ð¸Ð»Ð¸ Ð¿Ð°Ñ€Ð¾Ð»ÑŒ"
            )
        
        if not user.is_active:
            raise HTTPException(
                status_code=400,
                detail="ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½ÐµÐ°ÐºÑ‚Ð¸Ð²ÐµÐ½"
            )
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ð¾ÐºÐµÐ½ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°
        access_token = create_access_token(data={"sub": str(user.id)})
        
        return Token(access_token=access_token, token_type="bearer")
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ…Ð¾Ð´Ð°")

@app.get("/api/v1/auth/me", response_model=UserResponse)
async def get_current_user_info(current_user: User = Depends(get_current_user)):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ"""
    return UserResponse(
        id=current_user.id,
        email=current_user.email,
        username=current_user.username,
        is_active=current_user.is_active,
        created_at=current_user.created_at
    )

@app.post("/api/v1/auth/refresh", response_model=Token)
async def refresh_token(current_user: User = Depends(get_current_user)):
    """ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ‚Ð¾ÐºÐµÐ½Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°"""
    try:
        access_token = create_access_token(data={"sub": str(current_user.id)})
        return Token(access_token=access_token, token_type="bearer")
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ñ‚Ð¾ÐºÐµÐ½Ð°")

@app.post("/api/v1/auth/logout")
async def logout_user(current_user: User = Depends(get_current_user)):
    """Ð’Ñ‹Ñ…Ð¾Ð´ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ"""
    try:
        return {"message": "Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹ Ð²Ñ‹Ñ…Ð¾Ð´ Ð¸Ð· ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"}
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ñ…Ð¾Ð´Ð°")

# Endpoints Ð´Ð»Ñ SEO Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹
@app.post("/api/v1/seo/analyze", response_model=SEOAnalysisResult)
async def analyze_domain(
    request_data: DomainAnalysisRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð¾Ð¼ÐµÐ½Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
    try:
        # Ð—Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÐµÑ‚ Ð»Ð¾Ð³Ð¸ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°
        # ÐŸÐ¾ÐºÐ° Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ
        analysis_result = SEOAnalysisResult(
            domain=request_data.domain,
            analysis_date=datetime.utcnow(),
            score=75.5,
            recommendations=[
                {
                    "type": "internal_linking",
                    "priority": "high",
                    "description": "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÑÑ‚Ð°Ñ‚ÑŒÑÐ¼Ð¸"
                }
            ],
            metrics={
                "total_posts": 100,
                "internal_links": 50,
                "semantic_density": 0.8
            },
            status="completed"
        )
        
        return analysis_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°")

@app.post("/api/v1/seo/competitors")
async def analyze_competitors(
    request_data: CompetitorAnalysisRequest,
    current_user: User = Depends(get_current_user)
):
    """ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²"""
    try:
        result = {
            "domain": request_data.domain,
            "competitors": request_data.competitors,
            "analysis_date": datetime.utcnow().isoformat(),
            "metrics": {
                "traffic_comparison": {},
                "backlink_analysis": {},
                "keyword_overlap": {}
            }
        }
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²")

# Endpoints Ð´Ð»Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°
@app.get("/api/v1/history")
async def get_analysis_history(
    request: AnalysisHistoryRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð² Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
    try:
        history = [
            {
                "id": 1,
                "domain": "example.com",
                "analysis_date": datetime.utcnow().isoformat(),
                "status": "completed",
                "score": 85.0
            }
        ]
        
        return {
            "history": history,
            "total": len(history),
            "limit": request.limit,
            "offset": request.offset
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸")

@app.post("/api/v1/export")
async def export_data(
    request_data: ExportRequest,
    current_user: User = Depends(get_current_user)
):
    """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    try:
        export_result = {
            "format": request_data.format,
            "analysis_count": len(request_data.analysis_ids),
            "download_url": f"/api/v1/downloads/export_{datetime.utcnow().timestamp()}.{request_data.format}",
            "expires_at": (datetime.utcnow() + timedelta(hours=24)).isoformat()
        }
        
        return export_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…")

# Endpoints Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
@app.post("/api/v1/validate/domain")
async def validate_domain(domain: str):
    """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð´Ð¾Ð¼ÐµÐ½Ð°"""
    try:
        import re
        pattern = r'^[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?)*$'
        if re.match(pattern, domain):
            return {
                "valid": True,
                "domain": domain,
                "sanitized": domain.lower().strip()
            }
        else:
            return {
                "valid": False,
                "domain": domain,
                "error": "ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð¾Ð¼ÐµÐ½Ð°"
            }
    except ValueError as e:
        return {
            "valid": False,
            "domain": domain,
            "error": str(e)
        }

@app.post("/api/v1/validate/email")
async def validate_email(email: str):
    """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ email"""
    try:
        import re
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if re.match(pattern, email):
            return {
                "valid": True,
                "email": email,
                "sanitized": email.lower().strip()
            }
        else:
            return {
                "valid": False,
                "email": email,
                "error": "ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ email"
            }
    except Exception as e:
        return {
            "valid": False,
            "email": email,
            "error": str(e)
        }

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Pydantic"""
    return JSONResponse(
        status_code=422,
        content={"detail": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…", "errors": exc.errors()}
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº HTTP Ð¾ÑˆÐ¸Ð±Ð¾Ðº"""
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ÐžÐ±Ñ‰Ð¸Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹"""
    return JSONResponse(
        status_code=500,
        content={
            "error": "internal_server_error",
            "message": "Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°",
            "timestamp": datetime.utcnow().isoformat()
        }
    )

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ
@app.on_event("startup")
async def startup_event():
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð»Ð¾Ð³Ð¾Ð²
    os.makedirs("logs", exist_ok=True)
    
    print("ðŸš€ reLink SEO Platform v1.0.0 Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½!")

@app.get("/api/v1/rag/cache/stats")
async def get_rag_cache_stats():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ RAG ÐºÑÑˆÐ°"""
    try:
        stats = await cache_manager.get_rag_stats()
        return {
            "status": "success",
            "data": stats,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting RAG cache stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/rag/cache/clear")
async def clear_rag_cache():
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° RAG ÐºÑÑˆÐ°"""
    try:
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð²ÑÐµ Ñ‚Ð¸Ð¿Ñ‹ RAG ÐºÑÑˆÐ°
        await cache_manager.rag_cache.clear_expired()
        return {
            "status": "success",
            "message": "RAG cache cleared",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Error clearing RAG cache: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/rag/monitoring/metrics")
async def get_rag_monitoring_metrics():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ RAG Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
    try:
        from .monitoring import rag_monitor
        metrics = rag_monitor.get_rag_metrics()
        return {
            "status": "success",
            "data": metrics,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting RAG monitoring metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/rag/monitoring/health")
async def get_rag_health():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹."""
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ ChromaDB
        chroma_client = chromadb.Client()
        collections = chroma_client.list_collections()
        
        return {
            "status": "healthy",
            "chromadb_available": True,
            "collections_count": len(collections),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"RAG health check failed: {e}")
        return {
            "status": "unhealthy",
            "chromadb_available": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# ðŸŽ¨ DIAGRAM GENERATION ENDPOINTS

class DiagramGenerationRequestModel(BaseModel):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹."""
    diagram_type: str
    title: str
    description: str
    components: List[Dict[str, Any]]
    relationships: List[Dict[str, Any]]
    style: Optional[Dict[str, Any]] = None
    width: int = 800
    height: int = 600
    interactive: bool = True
    include_legend: bool = True

class DiagramGenerationResponseModel(BaseModel):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹."""
    diagram_id: int
    svg_content: str
    quality_score: float
    generation_time: float
    model_used: str
    confidence_score: float
    validation_result: Dict[str, Any]

@app.post("/api/diagrams/generate", response_model=DiagramGenerationResponseModel)
async def generate_diagram(
    request: DiagramGenerationRequestModel,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ SVG Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹."""
    try:
        diagram_service = DiagramService()
        
        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐµÑ€Ð²Ð¸ÑÐ°
        diagram_request = DiagramGenerationRequest(
            diagram_type=request.diagram_type,
            title=request.title,
            description=request.description,
            components=request.components,
            relationships=request.relationships,
            style_config=request.style,
            user_id=current_user.id
        )
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñƒ
        result = await diagram_service.generate_diagram(diagram_request, db)
        
        return DiagramGenerationResponseModel(
            diagram_id=result.diagram_id,
            svg_content=result.svg_content,
            quality_score=result.quality_score,
            generation_time=result.generation_time,
            model_used=result.model_used,
            confidence_score=result.confidence_score,
            validation_result=result.validation_result
        )
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {str(e)}"
        )

@app.get("/api/diagrams/templates")
async def get_diagram_templates():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð² Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼."""
    try:
        diagram_service = DiagramService()
        templates = await diagram_service.get_available_templates()
        return {"templates": templates}
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²: {str(e)}"
        )

@app.get("/api/diagrams/{diagram_id}")
async def get_diagram(
    diagram_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ð¿Ð¾ ID."""
    try:
        from .models import Diagram
        result = await db.execute(
            select(Diagram).where(
                Diagram.id == diagram_id,
                Diagram.user_id == current_user.id
            )
        )
        diagram = result.scalar_one_or_none()
        
        if not diagram:
            raise HTTPException(status_code=404, detail="Ð”Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
        
        return {
            "id": diagram.id,
            "title": diagram.title,
            "description": diagram.description,
            "svg_content": diagram.svg_content,
            "quality_score": diagram.quality_score,
            "created_at": diagram.created_at.isoformat(),
            "diagram_type": diagram.diagram_type
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {str(e)}"
        )

@app.get("/api/diagrams")
async def get_user_diagrams(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    limit: int = 10,
    offset: int = 0
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ."""
    try:
        from .models import Diagram
        result = await db.execute(
            select(Diagram)
            .where(Diagram.user_id == current_user.id)
            .order_by(Diagram.created_at.desc())
            .limit(limit)
            .offset(offset)
        )
        diagrams = result.scalars().all()
        
        return {
            "diagrams": [
                {
                    "id": d.id,
                    "title": d.title,
                    "description": d.description,
                    "diagram_type": d.diagram_type,
                    "quality_score": d.quality_score,
                    "created_at": d.created_at.isoformat()
                }
                for d in diagrams
            ],
            "total": len(diagrams)
        }
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼: {str(e)}"
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

