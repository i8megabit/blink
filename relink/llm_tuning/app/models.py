"""
üß† –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LLM Tuning –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–æ–¥–µ–ª–µ–π, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏, RAG –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ç—é–Ω–∏–Ω–≥–∞
"""

from sqlalchemy import Column, Integer, String, Float, Boolean, DateTime, Text, JSON, ForeignKey, Index
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from datetime import datetime
from typing import Optional, Dict, Any, List
from pydantic import BaseModel, Field
from enum import Enum

Base = declarative_base()


class ModelStatus(str, Enum):
    """–°—Ç–∞—Ç—É—Å—ã –º–æ–¥–µ–ª–µ–π"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    LOADING = "loading"
    ERROR = "error"
    TUNING = "tuning"


class RouteStrategy(str, Enum):
    """–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏"""
    SMART = "smart"
    ROUND_ROBIN = "round_robin"
    LOAD_BASED = "load_based"
    QUALITY_BASED = "quality_based"
    CONTEXT_AWARE = "context_aware"


class TuningStatus(str, Enum):
    """–°—Ç–∞—Ç—É—Å—ã —Ç—é–Ω–∏–Ω–≥–∞"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


# SQLAlchemy –º–æ–¥–µ–ª–∏
class LLMModel(Base):
    """–ú–æ–¥–µ–ª—å LLM –≤ —Å–∏—Å—Ç–µ–º–µ"""
    __tablename__ = "llm_models"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(255), unique=True, index=True, nullable=False)
    provider = Column(String(50), nullable=False)  # ollama, openai, anthropic
    model_id = Column(String(255), nullable=False)  # qwen2.5:7b-turbo
    status = Column(String(20), default=ModelStatus.INACTIVE.value)
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    temperature = Column(Float, default=0.7)
    max_tokens = Column(Integer, default=4096)
    context_length = Column(Integer, default=4096)
    batch_size = Column(Integer, default=512)
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    avg_response_time = Column(Float, default=0.0)
    avg_quality_score = Column(Float, default=0.0)
    total_requests = Column(Integer, default=0)
    error_rate = Column(Float, default=0.0)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    description = Column(Text, nullable=True)
    tags = Column(JSON, default=list)
    config = Column(JSON, default=dict)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    last_used = Column(DateTime(timezone=True), nullable=True)
    
    # –°–≤—è–∑–∏
    routes = relationship("ModelRoute", back_populates="model")
    tuning_sessions = relationship("TuningSession", back_populates="model")
    performance_metrics = relationship("PerformanceMetric", back_populates="model")
    
    __table_args__ = (
        Index('idx_model_provider_status', 'provider', 'status'),
        Index('idx_model_performance', 'avg_response_time', 'avg_quality_score'),
    )


class ModelRoute(Base):
    """–ú–∞—Ä—à—Ä—É—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π"""
    __tablename__ = "model_routes"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(255), unique=True, index=True, nullable=False)
    model_id = Column(Integer, ForeignKey("llm_models.id"), nullable=False)
    strategy = Column(String(50), default=RouteStrategy.SMART.value)
    
    # –£—Å–ª–æ–≤–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
    conditions = Column(JSON, default=dict)  # {"context_type": "seo", "complexity": "high"}
    priority = Column(Integer, default=1)
    weight = Column(Float, default=1.0)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_requests = Column(Integer, default=0)
    success_rate = Column(Float, default=0.0)
    avg_response_time = Column(Float, default=0.0)
    
    # –°—Ç–∞—Ç—É—Å
    is_active = Column(Boolean, default=True)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    # –°–≤—è–∑–∏
    model = relationship("LLMModel", back_populates="routes")
    
    __table_args__ = (
        Index('idx_route_strategy_active', 'strategy', 'is_active'),
        Index('idx_route_priority', 'priority', 'weight'),
    )


class TuningSession(Base):
    """–°–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π"""
    __tablename__ = "tuning_sessions"
    
    id = Column(Integer, primary_key=True, index=True)
    model_id = Column(Integer, ForeignKey("llm_models.id"), nullable=False)
    name = Column(String(255), nullable=False)
    status = Column(String(20), default=TuningStatus.PENDING.value)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—é–Ω–∏–Ω–≥–∞
    strategy = Column(String(50), nullable=False)  # adaptive, aggregate, hybrid
    learning_rate = Column(Float, default=0.001)
    batch_size = Column(Integer, default=32)
    epochs = Column(Integer, default=3)
    
    # –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞
    training_data = Column(JSON, default=list)
    validation_data = Column(JSON, default=list)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    initial_quality = Column(Float, nullable=True)
    final_quality = Column(Float, nullable=True)
    improvement = Column(Float, nullable=True)
    
    # –õ–æ–≥–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏
    logs = Column(JSON, default=list)
    metrics = Column(JSON, default=dict)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    started_at = Column(DateTime(timezone=True), nullable=True)
    completed_at = Column(DateTime(timezone=True), nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    # –°–≤—è–∑–∏
    model = relationship("LLMModel", back_populates="tuning_sessions")
    
    __table_args__ = (
        Index('idx_tuning_status', 'status'),
        Index('idx_tuning_model', 'model_id', 'status'),
    )


class PerformanceMetric(Base):
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    __tablename__ = "performance_metrics"
    
    id = Column(Integer, primary_key=True, index=True)
    model_id = Column(Integer, ForeignKey("llm_models.id"), nullable=False)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    response_time = Column(Float, nullable=False)
    quality_score = Column(Float, nullable=True)
    token_count = Column(Integer, nullable=True)
    error_occurred = Column(Boolean, default=False)
    error_message = Column(Text, nullable=True)
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç
    request_type = Column(String(50), nullable=True)  # rag, direct, tuning
    context_length = Column(Integer, nullable=True)
    user_id = Column(String(255), nullable=True)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    timestamp = Column(DateTime(timezone=True), server_default=func.now())
    
    # –°–≤—è–∑–∏
    model = relationship("LLMModel", back_populates="performance_metrics")
    
    __table_args__ = (
        Index('idx_metric_timestamp', 'timestamp'),
        Index('idx_metric_model_time', 'model_id', 'timestamp'),
    )


class RAGDocument(Base):
    """–î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã"""
    __tablename__ = "rag_documents"
    
    id = Column(Integer, primary_key=True, index=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)
    source = Column(String(500), nullable=True)
    
    # –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    embedding = Column(JSON, nullable=True)  # –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    chunk_id = Column(String(255), nullable=True)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    document_type = Column(String(50), nullable=True)  # seo, technical, content
    tags = Column(JSON, default=list)
    metadata = Column(JSON, default=dict)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    usage_count = Column(Integer, default=0)
    last_used = Column(DateTime(timezone=True), nullable=True)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    __table_args__ = (
        Index('idx_document_type', 'document_type'),
        Index('idx_document_usage', 'usage_count'),
    )


class APICall(Base):
    """–õ–æ–≥–∏ API –≤—ã–∑–æ–≤–æ–≤"""
    __tablename__ = "api_calls"
    
    id = Column(Integer, primary_key=True, index=True)
    
    # –ó–∞–ø—Ä–æ—Å
    endpoint = Column(String(255), nullable=False)
    method = Column(String(10), nullable=False)
    request_data = Column(JSON, nullable=True)
    
    # –û—Ç–≤–µ—Ç
    response_status = Column(Integer, nullable=True)
    response_data = Column(JSON, nullable=True)
    response_time = Column(Float, nullable=False)
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç
    user_id = Column(String(255), nullable=True)
    ip_address = Column(String(45), nullable=True)
    user_agent = Column(Text, nullable=True)
    
    # –û—à–∏–±–∫–∏
    error_occurred = Column(Boolean, default=False)
    error_message = Column(Text, nullable=True)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    timestamp = Column(DateTime(timezone=True), server_default=func.now())
    
    __table_args__ = (
        Index('idx_api_timestamp', 'timestamp'),
        Index('idx_api_endpoint', 'endpoint'),
        Index('idx_api_user', 'user_id'),
    )


# Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è API
class LLMModelCreate(BaseModel):
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ LLM"""
    name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    provider: str = Field(..., description="–ü—Ä–æ–≤–∞–π–¥–µ—Ä (ollama, openai, anthropic)")
    model_id: str = Field(..., description="ID –º–æ–¥–µ–ª–∏ —É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞")
    temperature: float = Field(default=0.7, description="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    max_tokens: int = Field(default=4096, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤")
    context_length: int = Field(default=4096, description="–î–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
    description: Optional[str] = Field(None, description="–û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    tags: List[str] = Field(default=list, description="–¢–µ–≥–∏ –º–æ–¥–µ–ª–∏")
    config: Dict[str, Any] = Field(default=dict, description="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")


class LLMModelUpdate(BaseModel):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ LLM"""
    temperature: Optional[float] = None
    max_tokens: Optional[int] = None
    context_length: Optional[int] = None
    status: Optional[ModelStatus] = None
    description: Optional[str] = None
    tags: Optional[List[str]] = None
    config: Optional[Dict[str, Any]] = None


class LLMModelResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –º–æ–¥–µ–ª—å—é LLM"""
    id: int
    name: str
    provider: str
    model_id: str
    status: str
    temperature: float
    max_tokens: int
    context_length: int
    avg_response_time: float
    avg_quality_score: float
    total_requests: int
    error_rate: float
    description: Optional[str]
    tags: List[str]
    config: Dict[str, Any]
    created_at: datetime
    updated_at: Optional[datetime]
    last_used: Optional[datetime]
    
    class Config:
        from_attributes = True


class RouteCreate(BaseModel):
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞"""
    name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞")
    model_id: int = Field(..., description="ID –º–æ–¥–µ–ª–∏")
    strategy: RouteStrategy = Field(default=RouteStrategy.SMART, description="–°—Ç—Ä–∞—Ç–µ–≥–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏")
    conditions: Dict[str, Any] = Field(default=dict, description="–£—Å–ª–æ–≤–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏")
    priority: int = Field(default=1, description="–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç")
    weight: float = Field(default=1.0, description="–í–µ—Å –º–∞—Ä—à—Ä—É—Ç–∞")


class RouteResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –º–∞—Ä—à—Ä—É—Ç–æ–º"""
    id: int
    name: str
    model_id: int
    strategy: str
    conditions: Dict[str, Any]
    priority: int
    weight: float
    total_requests: int
    success_rate: float
    avg_response_time: float
    is_active: bool
    created_at: datetime
    updated_at: Optional[datetime]
    
    class Config:
        from_attributes = True


class TuningSessionCreate(BaseModel):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
    model_id: int = Field(..., description="ID –º–æ–¥–µ–ª–∏")
    name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏")
    strategy: str = Field(..., description="–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ç—é–Ω–∏–Ω–≥–∞")
    learning_rate: float = Field(default=0.001, description="–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è")
    batch_size: int = Field(default=32, description="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞")
    epochs: int = Field(default=3, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö")
    training_data: List[Dict[str, Any]] = Field(default=list, description="–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    validation_data: List[Dict[str, Any]] = Field(default=list, description="–î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")


class TuningSessionResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å —Å–µ—Å—Å–∏–µ–π —Ç—é–Ω–∏–Ω–≥–∞"""
    id: int
    model_id: int
    name: str
    status: str
    strategy: str
    learning_rate: float
    batch_size: int
    epochs: int
    initial_quality: Optional[float]
    final_quality: Optional[float]
    improvement: Optional[float]
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    created_at: datetime
    
    class Config:
        from_attributes = True


class RAGQuery(BaseModel):
    """RAG –∑–∞–ø—Ä–æ—Å"""
    query: str = Field(..., description="–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    context_type: Optional[str] = Field(None, description="–¢–∏–ø –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
    top_k: int = Field(default=5, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    similarity_threshold: float = Field(default=0.7, description="–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏")
    use_hybrid_search: bool = Field(default=True, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫")


class RAGResponse(BaseModel):
    """RAG –æ—Ç–≤–µ—Ç"""
    answer: str = Field(..., description="–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å")
    sources: List[Dict[str, Any]] = Field(default=list, description="–ò—Å—Ç–æ—á–Ω–∏–∫–∏")
    confidence: float = Field(..., description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ")
    response_time: float = Field(..., description="–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞")
    tokens_used: int = Field(..., description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤")


class RouteRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é"""
    query: str = Field(..., description="–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    context: Optional[Dict[str, Any]] = Field(None, description="–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞")
    user_id: Optional[str] = Field(None, description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    priority: Optional[str] = Field(None, description="–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (high, normal, low)")
    model_preference: Optional[str] = Field(None, description="–ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å")


class RouteResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä–∞"""
    model_id: int = Field(..., description="ID –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
    model_name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    route_id: int = Field(..., description="ID –º–∞—Ä—à—Ä—É—Ç–∞")
    strategy: str = Field(..., description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è")
    confidence: float = Field(..., description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –≤—ã–±–æ—Ä–µ")
    reasoning: str = Field(..., description="–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∞")


class PerformanceMetrics(BaseModel):
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    model_id: int
    response_time: float
    quality_score: Optional[float] = None
    token_count: Optional[int] = None
    error_occurred: bool = False
    error_message: Optional[str] = None
    request_type: Optional[str] = None
    context_length: Optional[int] = None
    user_id: Optional[str] = None 