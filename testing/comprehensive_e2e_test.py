#!/usr/bin/env python3
"""
üéØ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π E2E —Ç–µ—Å—Ç –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏ reLink
relink ‚Üí router ‚Üí chromadb ‚Üí ollama ‚Üí llm

–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–º–µ–Ω–∞ dagorod.ru
–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
"""

import os
import sys
import time
import json
import requests
import asyncio
import aiohttp
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import logging
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('e2e_test_results.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class TestResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞"""
    test_name: str
    status: str  # success, error, warning
    score: float  # 0-100
    details: Dict[str, Any]
    duration: float
    timestamp: datetime

@dataclass
class SEORecommendation:
    """SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"""
    type: str  # technical, content, structure, performance
    priority: str  # high, medium, low
    description: str
    impact_score: float  # 0-100
    implementation_difficulty: str  # easy, medium, hard
    estimated_improvement: str  # –æ–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ

class ComprehensiveE2ETest:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π E2E —Ç–µ—Å—Ç –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã reLink"""
    
    def __init__(self, domain: str = "dagorod.ru"):
        self.domain = domain
        self.base_urls = {
            'relink': 'http://localhost:8003',
            'router': 'http://localhost:8001', 
            'chromadb': 'http://localhost:8006',
            'ollama': 'http://localhost:11434',
            'llm_tuning': 'http://localhost:8005'
        }
        self.results: List[TestResult] = []
        self.indexing_data: Dict[str, Any] = {}
        self.seo_recommendations: List[SEORecommendation] = []
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
        self.seo_benchmarks = {
            'internal_linking_score': {
                'excellent': 85,
                'good': 70,
                'average': 50,
                'poor': 30
            },
            'content_quality_score': {
                'excellent': 90,
                'good': 75,
                'average': 60,
                'poor': 40
            },
            'technical_seo_score': {
                'excellent': 95,
                'good': 80,
                'average': 65,
                'poor': 45
            }
        }
        
        # –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö SEO —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        self.seo_examples = {
            'internal_linking': {
                'good_example': 'https://moz.com/blog/internal-linking-for-seo',
                'best_practices': [
                    '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∞–Ω–∫–æ—Ä–æ–≤',
                    '–õ–æ–≥–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Å—ã–ª–æ–∫',
                    '–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ PageRank'
                ]
            },
            'content_optimization': {
                'good_example': 'https://ahrefs.com/blog/content-marketing-strategy/',
                'best_practices': [
                    '–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤',
                    '–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ',
                    '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞'
                ]
            },
            'technical_seo': {
                'good_example': 'https://backlinko.com/technical-seo-guide',
                'best_practices': [
                    '–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏',
                    '–ú–æ–±–∏–ª—å–Ω–∞—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å',
                    '–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ HTTPS'
                ]
            }
        }
        
    async def run_full_test_suite(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ —Ç–µ—Å—Ç–æ–≤"""
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ E2E —Ç–µ—Å—Ç–∞ –¥–ª—è –¥–æ–º–µ–Ω–∞: {self.domain}")
        
        start_time = time.time()
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
        await self.test_service_availability()
        
        # 2. –¢–µ—Å—Ç –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–º–µ–Ω–∞
        await self.test_domain_indexing()
        
        # 3. –¢–µ—Å—Ç —Ä–∞–±–æ—Ç—ã —Å ChromaDB
        await self.test_chromadb_integration()
        
        # 4. –¢–µ—Å—Ç LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        await self.test_llm_integration()
        
        # 5. –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        await self.test_seo_recommendations()
        
        # 6. –¢–µ—Å—Ç —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        await self.test_deep_analysis()
        
        # 7. –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        await self.test_performance()
        
        total_duration = time.time() - start_time
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        final_report = self.generate_final_report(total_duration)
        
        logger.info(f"‚úÖ E2E —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_duration:.2f} —Å–µ–∫—É–Ω–¥")
        return final_report
    
    async def test_service_availability(self) -> None:
        """–¢–µ—Å—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤...")
        
        for service_name, url in self.base_urls.items():
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"{url}/health", timeout=10) as response:
                        if response.status == 200:
                            self.results.append(TestResult(
                                test_name=f"service_availability_{service_name}",
                                status="success",
                                score=100.0,
                                details={"url": url, "status_code": response.status},
                                duration=0.1,
                                timestamp=datetime.now()
                            ))
                            logger.info(f"‚úÖ {service_name}: –¥–æ—Å—Ç—É–ø–µ–Ω")
                        else:
                            self.results.append(TestResult(
                                test_name=f"service_availability_{service_name}",
                                status="error",
                                score=0.0,
                                details={"url": url, "status_code": response.status},
                                duration=0.1,
                                timestamp=datetime.now()
                            ))
                            logger.error(f"‚ùå {service_name}: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥ {response.status})")
            except Exception as e:
                self.results.append(TestResult(
                    test_name=f"service_availability_{service_name}",
                    status="error",
                    score=0.0,
                    details={"url": url, "error": str(e)},
                    duration=0.1,
                    timestamp=datetime.now()
                ))
                logger.error(f"‚ùå {service_name}: –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è - {e}")
    
    async def test_domain_indexing(self) -> None:
        """–¢–µ—Å—Ç –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–º–µ–Ω–∞"""
        logger.info(f"üåê –¢–µ—Å—Ç –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–º–µ–Ω–∞ {self.domain}...")
        
        start_time = time.time()
        
        try:
            # –ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ reLink API
            indexing_payload = {
                "domain": self.domain,
                "max_pages": 50,
                "depth": 3,
                "include_assets": True,
                "crawl_delay": 1
            }
            
            async with aiohttp.ClientSession() as session:
                # –ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è
                async with session.post(
                    f"{self.base_urls['relink']}/api/index-domain",
                    json=indexing_payload,
                    timeout=300
                ) as response:
                    if response.status == 200:
                        indexing_result = await response.json()
                        self.indexing_data = indexing_result
                        
                        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è
                        pages_indexed = indexing_result.get('pages_indexed', 0)
                        links_found = indexing_result.get('links_found', 0)
                        errors = indexing_result.get('errors', [])
                        
                        score = min(100.0, (pages_indexed / 10) * 100)  # –ë–∞–∑–æ–≤—ã–π score
                        if errors:
                            score *= 0.8  # –®—Ç—Ä–∞—Ñ –∑–∞ –æ—à–∏–±–∫–∏
                        
                        self.results.append(TestResult(
                            test_name="domain_indexing",
                            status="success" if pages_indexed > 0 else "error",
                            score=score,
                            details={
                                "pages_indexed": pages_indexed,
                                "links_found": links_found,
                                "errors": errors,
                                "domain": self.domain
                            },
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
                        logger.info(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {pages_indexed} —Å—Ç—Ä–∞–Ω–∏—Ü, {links_found} —Å—Å—ã–ª–æ–∫")
                    else:
                        self.results.append(TestResult(
                            test_name="domain_indexing",
                            status="error",
                            score=0.0,
                            details={"status_code": response.status},
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è: –∫–æ–¥ {response.status}")
                        
        except Exception as e:
            self.results.append(TestResult(
                test_name="domain_indexing",
                status="error",
                score=0.0,
                details={"error": str(e)},
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    
    async def test_chromadb_integration(self) -> None:
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å ChromaDB"""
        logger.info("üóÑÔ∏è –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å ChromaDB...")
        
        start_time = time.time()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ ChromaDB
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_urls['chromadb']}/api/v2/heartbeat") as response:
                    if response.status == 200:
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ
                        async with session.get(f"{self.base_urls['chromadb']}/api/v2/collections") as collections_response:
                            if collections_response.status == 200:
                                collections = await collections_response.json()
                                
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –Ω–∞—à–µ–≥–æ –¥–æ–º–µ–Ω–∞
                                domain_collection = None
                                for collection in collections.get('collections', []):
                                    if self.domain in collection.get('name', ''):
                                        domain_collection = collection
                                        break
                                
                                if domain_collection:
                                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                                    collection_id = domain_collection['id']
                                    async with session.get(
                                        f"{self.base_urls['chromadb']}/api/v2/collections/{collection_id}/count"
                                    ) as count_response:
                                        if count_response.status == 200:
                                            count_data = await count_response.json()
                                            doc_count = count_data.get('count', 0)
                                            
                                            score = min(100.0, (doc_count / 10) * 100)
                                            
                                            self.results.append(TestResult(
                                                test_name="chromadb_integration",
                                                status="success",
                                                score=score,
                                                details={
                                                    "collection_found": True,
                                                    "documents_count": doc_count,
                                                    "collection_name": domain_collection['name']
                                                },
                                                duration=time.time() - start_time,
                                                timestamp=datetime.now()
                                            ))
                                            
                                            logger.info(f"‚úÖ ChromaDB: –Ω–∞–π–¥–µ–Ω–æ {doc_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                                        else:
                                            self.results.append(TestResult(
                                                test_name="chromadb_integration",
                                                status="warning",
                                                score=50.0,
                                                details={"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"},
                                                duration=time.time() - start_time,
                                                timestamp=datetime.now()
                                            ))
                                else:
                                    self.results.append(TestResult(
                                        test_name="chromadb_integration",
                                        status="error",
                                        score=0.0,
                                        details={"error": f"–ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –¥–æ–º–µ–Ω–∞ {self.domain} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"},
                                        duration=time.time() - start_time,
                                        timestamp=datetime.now()
                                    ))
                                    logger.error(f"‚ùå –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –¥–æ–º–µ–Ω–∞ {self.domain} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                            else:
                                self.results.append(TestResult(
                                    test_name="chromadb_integration",
                                    status="error",
                                    score=0.0,
                                    details={"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π"},
                                    duration=time.time() - start_time,
                                    timestamp=datetime.now()
                                ))
                    else:
                        self.results.append(TestResult(
                            test_name="chromadb_integration",
                            status="error",
                            score=0.0,
                            details={"error": "ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"},
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
        except Exception as e:
            self.results.append(TestResult(
                test_name="chromadb_integration",
                status="error",
                score=0.0,
                details={"error": str(e)},
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å ChromaDB: {e}")
    
    async def test_llm_integration(self) -> None:
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å LLM"""
        logger.info("üß† –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å LLM...")
        
        start_time = time.time()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_urls['ollama']}/api/tags") as response:
                    if response.status == 200:
                        models = await response.json()
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω—É–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                        available_models = [model['name'] for model in models.get('models', [])]
                        required_models = ['llama3.1:8b', 'qwen2.5:7b']  # –ü—Ä–∏–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π
                        
                        found_models = [model for model in required_models if any(model in available_model for available_model in available_models)]
                        
                        score = (len(found_models) / len(required_models)) * 100
                        
                        self.results.append(TestResult(
                            test_name="llm_integration",
                            status="success" if found_models else "warning",
                            score=score,
                            details={
                                "available_models": available_models,
                                "found_models": found_models,
                                "required_models": required_models
                            },
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
                        logger.info(f"‚úÖ LLM: –Ω–∞–π–¥–µ–Ω–æ {len(found_models)} –∏–∑ {len(required_models)} –º–æ–¥–µ–ª–µ–π")
                    else:
                        self.results.append(TestResult(
                            test_name="llm_integration",
                            status="error",
                            score=0.0,
                            details={"error": "Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"},
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
        except Exception as e:
            self.results.append(TestResult(
                test_name="llm_integration",
                status="error",
                score=0.0,
                details={"error": str(e)},
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å LLM: {e}")
    
    async def test_seo_recommendations(self) -> None:
        """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        logger.info("üìä –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        
        start_time = time.time()
        
        try:
            # –ó–∞–ø—Ä–æ—Å SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —á–µ—Ä–µ–∑ LLM API
            seo_payload = {
                "domain": self.domain,
                "analysis_type": "comprehensive",
                "include_technical": True,
                "include_content": True,
                "include_structure": True,
                "include_performance": True
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_urls['llm_tuning']}/api/seo-analysis",
                    json=seo_payload,
                    timeout=120
                ) as response:
                    if response.status == 200:
                        seo_result = await response.json()
                        
                        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                        recommendations = seo_result.get('recommendations', [])
                        self.seo_recommendations = []
                        
                        for rec in recommendations:
                            self.seo_recommendations.append(SEORecommendation(
                                type=rec.get('type', 'unknown'),
                                priority=rec.get('priority', 'medium'),
                                description=rec.get('description', ''),
                                impact_score=rec.get('impact_score', 0.0),
                                implementation_difficulty=rec.get('difficulty', 'medium'),
                                estimated_improvement=rec.get('improvement', 'unknown')
                            ))
                        
                        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                        total_recommendations = len(self.seo_recommendations)
                        high_priority_count = len([r for r in self.seo_recommendations if r.priority == 'high'])
                        avg_impact_score = sum(r.impact_score for r in self.seo_recommendations) / max(total_recommendations, 1)
                        
                        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ score
                        score = min(100.0, (
                            (total_recommendations / 10) * 30 +  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                            (high_priority_count / max(total_recommendations, 1)) * 40 +  # –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
                            (avg_impact_score / 100) * 30  # –°—Ä–µ–¥–Ω–∏–π impact score
                        ))
                        
                        self.results.append(TestResult(
                            test_name="seo_recommendations",
                            status="success" if total_recommendations > 0 else "warning",
                            score=score,
                            details={
                                "total_recommendations": total_recommendations,
                                "high_priority_count": high_priority_count,
                                "avg_impact_score": avg_impact_score,
                                "recommendations_by_type": self._group_recommendations_by_type()
                            },
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
                        logger.info(f"‚úÖ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {total_recommendations} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, {high_priority_count} –≤—ã—Å–æ–∫–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞")
                    else:
                        self.results.append(TestResult(
                            test_name="seo_recommendations",
                            status="error",
                            score=0.0,
                            details={"status_code": response.status},
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: –∫–æ–¥ {response.status}")
                        
        except Exception as e:
            self.results.append(TestResult(
                test_name="seo_recommendations",
                status="error",
                score=0.0,
                details={"error": str(e)},
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
    
    async def test_deep_analysis(self) -> None:
        """–¢–µ—Å—Ç —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        logger.info("üîç –¢–µ—Å—Ç —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        
        start_time = time.time()
        
        try:
            # –ó–∞–ø—Ä–æ—Å —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
            deep_analysis_payload = {
                "domain": self.domain,
                "analysis_type": "deep",
                "target_pages": ["/", "/about", "/services"],  # –ü—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü
                "analysis_depth": "comprehensive",
                "include_competitor_analysis": True,
                "include_trend_analysis": True
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_urls['llm_tuning']}/api/deep-analysis",
                    json=deep_analysis_payload,
                    timeout=180
                ) as response:
                    if response.status == 200:
                        analysis_result = await response.json()
                        
                        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        pages_analyzed = len(analysis_result.get('page_analyses', []))
                        insights_found = len(analysis_result.get('insights', []))
                        competitor_data = analysis_result.get('competitor_analysis', {})
                        
                        score = min(100.0, (
                            (pages_analyzed / 3) * 40 +  # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü
                            (insights_found / 10) * 40 +  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Å–∞–π—Ç–æ–≤
                            (len(competitor_data) / 5) * 20  # –î–∞–Ω–Ω—ã–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
                        ))
                        
                        self.results.append(TestResult(
                            test_name="deep_analysis",
                            status="success" if pages_analyzed > 0 else "warning",
                            score=score,
                            details={
                                "pages_analyzed": pages_analyzed,
                                "insights_found": insights_found,
                                "competitor_data_points": len(competitor_data),
                                "analysis_depth": "comprehensive"
                            },
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
                        logger.info(f"‚úÖ –£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {pages_analyzed} —Å—Ç—Ä–∞–Ω–∏—Ü, {insights_found} –∏–Ω—Å–∞–π—Ç–æ–≤")
                    else:
                        self.results.append(TestResult(
                            test_name="deep_analysis",
                            status="error",
                            score=0.0,
                            details={"status_code": response.status},
                            duration=time.time() - start_time,
                            timestamp=datetime.now()
                        ))
                        
        except Exception as e:
            self.results.append(TestResult(
                test_name="deep_analysis",
                status="error",
                score=0.0,
                details={"error": str(e)},
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    async def test_performance(self) -> None:
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
        logger.info("‚ö° –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        start_time = time.time()
        
        try:
            # –¢–µ—Å—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞ API
            performance_metrics = {}
            
            async with aiohttp.ClientSession() as session:
                # –¢–µ—Å—Ç ChromaDB
                chroma_start = time.time()
                async with session.get(f"{self.base_urls['chromadb']}/api/v2/heartbeat") as response:
                    chroma_time = time.time() - chroma_start
                    performance_metrics['chromadb_response_time'] = chroma_time
                
                # –¢–µ—Å—Ç LLM
                llm_start = time.time()
                async with session.get(f"{self.base_urls['ollama']}/api/tags") as response:
                    llm_time = time.time() - llm_start
                    performance_metrics['llm_response_time'] = llm_time
                
                # –¢–µ—Å—Ç Router
                router_start = time.time()
                async with session.get(f"{self.base_urls['router']}/health") as response:
                    router_time = time.time() - router_start
                    performance_metrics['router_response_time'] = router_time
            
            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            avg_response_time = sum(performance_metrics.values()) / len(performance_metrics)
            
            # Score –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞ (—á–µ–º –±—ã—Å—Ç—Ä–µ–µ, —Ç–µ–º –ª—É—á—à–µ)
            if avg_response_time < 0.5:
                score = 100.0
            elif avg_response_time < 1.0:
                score = 80.0
            elif avg_response_time < 2.0:
                score = 60.0
            else:
                score = max(0.0, 100.0 - (avg_response_time - 2.0) * 20)
            
            self.results.append(TestResult(
                test_name="performance",
                status="success" if avg_response_time < 2.0 else "warning",
                score=score,
                details=performance_metrics,
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            
            logger.info(f"‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ {avg_response_time:.3f}—Å")
            
        except Exception as e:
            self.results.append(TestResult(
                test_name="performance",
                status="error",
                score=0.0,
                details={"error": str(e)},
                duration=time.time() - start_time,
                timestamp=datetime.now()
            ))
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
    
    def _group_recommendations_by_type(self) -> Dict[str, int]:
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ç–∏–ø—É"""
        grouped = {}
        for rec in self.seo_recommendations:
            grouped[rec.type] = grouped.get(rec.type, 0) + 1
        return grouped
    
    def generate_final_report(self, total_duration: float) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        
        # –†–∞—Å—á–µ—Ç –æ–±—â–∏—Ö –º–µ—Ç—Ä–∏–∫
        total_tests = len(self.results)
        successful_tests = len([r for r in self.results if r.status == "success"])
        error_tests = len([r for r in self.results if r.status == "error"])
        warning_tests = len([r for r in self.results if r.status == "warning"])
        
        avg_score = sum(r.score for r in self.results) / max(total_tests, 1)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
        if error_tests == 0 and warning_tests == 0:
            overall_status = "excellent"
        elif error_tests == 0:
            overall_status = "good"
        elif error_tests < total_tests / 2:
            overall_status = "fair"
        else:
            overall_status = "poor"
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_analysis = {}
        for result in self.results:
            category = result.test_name.split('_')[0]
            if category not in category_analysis:
                category_analysis[category] = {
                    'tests': [],
                    'avg_score': 0.0,
                    'status': 'unknown'
                }
            category_analysis[category]['tests'].append(result)
        
        # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–∏—Ö scores –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, data in category_analysis.items():
            if data['tests']:
                data['avg_score'] = sum(t.score for t in data['tests']) / len(data['tests'])
                if data['avg_score'] >= 80:
                    data['status'] = 'excellent'
                elif data['avg_score'] >= 60:
                    data['status'] = 'good'
                elif data['avg_score'] >= 40:
                    data['status'] = 'fair'
                else:
                    data['status'] = 'poor'
        
        # –ê–Ω–∞–ª–∏–∑ SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        seo_analysis = {
            'total_recommendations': len(self.seo_recommendations),
            'by_priority': {
                'high': len([r for r in self.seo_recommendations if r.priority == 'high']),
                'medium': len([r for r in self.seo_recommendations if r.priority == 'medium']),
                'low': len([r for r in self.seo_recommendations if r.priority == 'low'])
            },
            'by_type': self._group_recommendations_by_type(),
            'avg_impact_score': sum(r.impact_score for r in self.seo_recommendations) / max(len(self.seo_recommendations), 1)
        }
        
        report = {
            'test_info': {
                'domain': self.domain,
                'timestamp': datetime.now().isoformat(),
                'total_duration': total_duration,
                'overall_status': overall_status,
                'overall_score': avg_score
            },
            'test_summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'error_tests': error_tests,
                'warning_tests': warning_tests,
                'success_rate': (successful_tests / total_tests) * 100 if total_tests > 0 else 0
            },
            'category_analysis': category_analysis,
            'seo_analysis': seo_analysis,
            'detailed_results': [
                {
                    'test_name': r.test_name,
                    'status': r.status,
                    'score': r.score,
                    'duration': r.duration,
                    'details': r.details
                }
                for r in self.results
            ],
            'recommendations': [
                {
                    'type': r.type,
                    'priority': r.priority,
                    'description': r.description,
                    'impact_score': r.impact_score,
                    'implementation_difficulty': r.implementation_difficulty,
                    'estimated_improvement': r.estimated_improvement
                }
                for r in self.seo_recommendations
            ]
        }
        
        return report

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    tester = ComprehensiveE2ETest("dagorod.ru")
    
    try:
        report = await tester.run_full_test_suite()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_file = f"e2e_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print("\n" + "="*80)
        print("üéØ –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ E2E –¢–ï–°–¢–ê")
        print("="*80)
        print(f"–î–æ–º–µ–Ω: {report['test_info']['domain']}")
        print(f"–û–±—â–∏–π —Å—Ç–∞—Ç—É—Å: {report['test_info']['overall_status'].upper()}")
        print(f"–û–±—â–∏–π score: {report['test_info']['overall_score']:.1f}/100")
        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {report['test_info']['total_duration']:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"–£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {report['test_summary']['successful_tests']}/{report['test_summary']['total_tests']}")
        print(f"SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {report['seo_analysis']['total_recommendations']}")
        print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")
        print("="*80)
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        print("\nüìä –ê–ù–ê–õ–ò–ó –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        for category, data in report['category_analysis'].items():
            print(f"  {category.upper()}: {data['status'].upper()} ({data['avg_score']:.1f}/100)")
        
        # –¢–æ–ø SEO-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        if report['recommendations']:
            print(f"\nüîù –¢–û–ü SEO-–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            high_priority = [r for r in report['recommendations'] if r['priority'] == 'high']
            for i, rec in enumerate(high_priority[:5], 1):
                print(f"  {i}. [{rec['type'].upper()}] {rec['description'][:100]}...")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 