"""FastAPI-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº reLink."""

from __future__ import annotations

import asyncio
import json
import os
import re
import logging
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Tuple

import chromadb
import httpx
import nltk
import numpy as np
import ollama
from bs4 import BeautifulSoup
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Request, Response, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from pydantic import BaseModel, ValidationError
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import (
    DateTime, Float, ForeignKey, Index, Integer, JSON, String, Text,
    func, select, update, delete
)
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship, selectinload

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('app.log')
    ]
)

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÑƒÐ»Ð¸
from .config import settings, get_settings
from .exceptions import (
    RelinkBaseException, ErrorHandler, ErrorResponse,
    ValidationException, AuthenticationException, AuthorizationException,
    NotFoundException, DatabaseException, OllamaException,
    raise_not_found, raise_validation_error, raise_authentication_error,
    raise_authorization_error, raise_database_error, raise_ollama_error
)
from .monitoring import (
    logger, metrics_collector, performance_monitor, 
    get_metrics, get_health_status, monitor_operation,
    MonitoringMiddleware
)
from .cache import (
    cache_manager, cache_result, invalidate_cache,
    SEOCache, UserCache
)
from .validation import (
    UserRegistrationModel, UserLoginModel, DomainAnalysisModel,
    SEORecommendationModel, ExportModel, PaginationModel,
    validate_request, validate_response, validate_and_clean_data
)
from .auth import (
    get_current_user, create_access_token, get_password_hash, verify_password,
    User, UserCreate, UserResponse, Token, TokenData,
    UserRegistrationRequest, UserLoginRequest
)
from .database import get_db, engine
from .models import Base, User, Domain, WordPressPost, AnalysisHistory, Diagram, DiagramEmbedding
from .models import (
    TestRequest, TestResponse, TestSuiteRequest, TestSuiteResponse, TestExecutionResponse,
    TestType, TestStatus, TestPriority, TestEnvironment
)
from .llm_router import system_analyzer, llm_router
from .diagram_service import DiagramService, DiagramGenerationRequest
from .testing_service import testing_service, router as testing_router
from .api.auth import router as auth_router

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° NLTK Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Ð ÑƒÑÑÐºÐ¸Ðµ ÑÑ‚Ð¾Ð¿-ÑÐ»Ð¾Ð²Ð°
RUSSIAN_STOP_WORDS = set(stopwords.words('russian'))

# ðŸ”’ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ Ð¡Ð•ÐœÐÐ¤ÐžÐ  Ð”Ð›Ð¯ ÐžÐ“Ð ÐÐÐ˜Ð§Ð•ÐÐ˜Ð¯ ÐÐÐ“Ð Ð£Ð—ÐšÐ˜ ÐÐ OLLAMA
OLLAMA_SEMAPHORE = asyncio.Semaphore(1)

@dataclass
class SemanticEntity:
    """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° LLM."""
    entity_type: str
    value: str
    confidence: float
    context: str

@dataclass
class ThematicCluster:
    """Ð¢ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€ ÑÑ‚Ð°Ñ‚ÐµÐ¹."""
    cluster_id: str
    theme: str
    keywords: List[str]
    articles_count: int
    semantic_density: float

@dataclass
class AIThought:
    """Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¼Ñ‹ÑÐ»ÑŒ Ð˜Ð˜ Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¾Ð¹."""
    thought_id: str
    stage: str  # analyzing, connecting, evaluating, optimizing
    content: str
    confidence: float
    semantic_weight: float
    related_concepts: List[str]
    reasoning_chain: List[str]
    timestamp: datetime
    
@dataclass
class SemanticConnection:
    """Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸ÑÐ¼Ð¸."""
    source_concept: str
    target_concept: str
    connection_type: str  # semantic, causal, hierarchical, temporal
    strength: float
    evidence: List[str]
    context_keywords: Set[str]

class WebSocketManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ WebSocket ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°."""

    def __init__(self) -> None:
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str) -> None:
        """ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°."""
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½: {client_id}")

    def disconnect(self, client_id: str) -> None:
        """ÐžÑ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°."""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            logger.info(f"WebSocket Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½: {client_id}")

    async def send_progress(self, client_id: str, message: dict) -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð¼Ñƒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json(message)
                logger.debug(f"ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ {client_id}: {message}")
            except Exception as e:
                logger.error(f"Error sending progress to {client_id}: {e}")

    async def send_error(self, client_id: str, error: str, details: str = "") -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾ÑˆÐ¸Ð±ÐºÐ¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ."""
        await self.send_progress(client_id, {
            "type": "error",
            "message": error,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })

    async def send_step(self, client_id: str, step: str, current: int, total: int, details: str = "") -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ ÑˆÐ°Ð³Ðµ."""
        await self.send_progress(client_id, {
            "type": "progress",
            "step": step,
            "current": current,
            "total": total,
            "percentage": round((current / total) * 100) if total > 0 else 0,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })

    async def send_ollama_info(self, client_id: str, info: dict) -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ollama."""
        await self.send_progress(client_id, {
            "type": "ollama",
            "info": info,
            "timestamp": datetime.now().isoformat()
        })

    async def send_ai_thinking(self, client_id: str, thought: str, thinking_stage: str = "analyzing", emoji: str = "ðŸ¤”") -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° 'Ð¼Ñ‹ÑÐ»ÐµÐ¹' Ð˜Ð˜ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json({
                    "type": "ai_thinking",
                    "thought": thought,
                    "thinking_stage": thinking_stage,
                    "emoji": emoji,
                    "timestamp": datetime.now().isoformat()
                })
                logger.debug(f"ÐœÑ‹ÑÐ»ÑŒ Ð˜Ð˜ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð° {client_id}: {thought[:50]}...")
            except Exception as e:
                logger.error(f"Error sending AI thinking to {client_id}: {e}")
    
    async def send_enhanced_ai_thinking(self, client_id: str, ai_thought: AIThought) -> None:
        """ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ñ‹ÑÐ»ÐµÐ¹ Ð˜Ð˜ Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¾Ð¹."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json({
                    "type": "enhanced_ai_thinking",
                    "thought_id": ai_thought.thought_id,
                    "stage": ai_thought.stage,
                    "content": ai_thought.content,
                    "confidence": ai_thought.confidence,
                    "semantic_weight": ai_thought.semantic_weight,
                    "related_concepts": ai_thought.related_concepts,
                    "reasoning_chain": ai_thought.reasoning_chain,
                    "timestamp": ai_thought.timestamp.isoformat()
                })
                logger.debug(f"Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð°Ñ Ð¼Ñ‹ÑÐ»ÑŒ Ð˜Ð˜ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð° {client_id}: {ai_thought.content[:50]}...")
            except Exception as e:
                logger.error(f"Error sending enhanced AI thinking to {client_id}: {e}")

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ WebSocket
websocket_manager = WebSocketManager()

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ FastAPI Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
app = FastAPI(
    title=settings.api.title,
    description=settings.api.description,
    version=settings.api.version,
    debug=settings.api.debug,
    docs_url=settings.api.docs_url,
    redoc_url=settings.api.redoc_url
)

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.api.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ middleware Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
app.add_middleware(MonitoringMiddleware)

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
def initialize_rag_system() -> None:
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ñ ChromaDB."""
    try:
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° ChromaDB
        chroma_client = chromadb.Client()
        
        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
        collection = chroma_client.create_collection(
            name="relink_documents",
            metadata={"description": "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ reLink"}
        )
        
        logger.info("RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ñ ChromaDB")
        return collection
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: {e}")
        return None

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð´Ð»Ñ RAG ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸
rag_collection = initialize_rag_system()

class AdvancedRAGManager:
    """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹."""
    
    def __init__(self) -> None:
        self.collection = rag_collection
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=RUSSIAN_STOP_WORDS,
            ngram_range=(1, 2)
        )
    
    async def create_semantic_knowledge_base(self, domain, posts, client_id=None):
        # ÐŸÑ€Ð¾ÐºÑÐ¸Ñ€ÑƒÐµÐ¼ Ð²Ñ‹Ð·Ð¾Ð² Ðº Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñƒ Ð¼Ñ‹ÑÐ»ÐµÐ¹
        return await generate_ai_thoughts_for_domain(domain, posts, client_id)

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ RAG
rag_manager = AdvancedRAGManager()

# Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
class RecommendRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ ÑÑÑ‹Ð»Ð¾Ðº."""
    text: str

class WPRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° WordPress-ÑÐ°Ð¹Ñ‚Ð°."""
    domain: str
    client_id: Optional[str] = None
    comprehensive: Optional[bool] = False

class BenchmarkRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°."""
    name: str
    description: Optional[str] = None
    benchmark_type: str = "seo_advanced"
    models: List[str] = []
    iterations: int = 3
    client_id: Optional[str] = None

class ModelConfigRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸."""
    llm_model: str
    display_name: Optional[str] = None
    description: Optional[str] = None
    default_parameters: Optional[dict] = None
    seo_optimized_params: Optional[dict] = None
    benchmark_params: Optional[dict] = None

class SEOAnalysisResult(BaseModel):
    """Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ SEO Ð°Ð½Ð°Ð»Ð¸Ð·Ð°."""
    domain: str
    analysis_date: datetime
    score: float
    recommendations: List[dict]
    metrics: dict
    status: str

class DomainAnalysisRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°."""
    domain: str
    comprehensive: Optional[bool] = False

class CompetitorAnalysisRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²."""
    domain: str
    competitors: List[str]

class AnalysisHistoryRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²."""
    limit: int = 10
    offset: int = 0

class ExportRequest(BaseModel):
    """Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…."""
    format: str  # json, csv, pdf
    analysis_ids: List[int]

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ollama
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5:7b-instruct-turbo")

# ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²
OPTIMAL_CONTEXT_SIZE = 3072
OPTIMAL_PREDICTION_SIZE = 800
OPTIMAL_TEMPERATURE = 0.3
OPTIMAL_TOP_P = 0.85
OPTIMAL_TOP_K = 50
OPTIMAL_REPEAT_PENALTY = 1.08

# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¼Ñ‹ÑÐ»ÐµÐ¹ Ð˜Ð˜
async def generate_ai_thoughts_for_domain(domain: str, posts: List[dict], client_id: str = None) -> List[AIThought]:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¼Ñ‹ÑÐ»ÐµÐ¹ Ð˜Ð˜ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°."""
    thoughts = []
    
    if client_id:
        await websocket_manager.send_ai_thinking(
            client_id, 
            f"ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð¾Ð¼ÐµÐ½Ð° {domain}...", 
            "analyzing", 
            "ðŸ”"
        )
    
    # ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
    content_thought = AIThought(
        thought_id=f"content_analysis_{domain}",
        stage="analyzing",
        content=f"ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ {len(posts)} ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð½Ð° Ð´Ð¾Ð¼ÐµÐ½Ðµ {domain}",
        confidence=0.8,
        semantic_weight=0.7,
        related_concepts=["ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚", "Ð°Ð½Ð°Ð»Ð¸Ð·", "ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ°"],
        reasoning_chain=["Ð¿Ð¾Ð´ÑÑ‡ÐµÑ‚ ÑÑ‚Ð°Ñ‚ÐµÐ¹", "Ð¾Ñ†ÐµÐ½ÐºÐ° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°"],
        timestamp=datetime.now(timezone.utc)
    )
    thoughts.append(content_thought)
    
    if client_id:
        await websocket_manager.send_enhanced_ai_thinking(client_id, content_thought)
    
    # ÐŸÐ¾Ð¸ÑÐº ÑÐ²ÑÐ·ÐµÐ¹
    connection_thought = AIThought(
        thought_id=f"connection_search_{domain}",
        stage="connecting",
        content="Ð˜Ñ‰Ñƒ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ ÑÑ‚Ð°Ñ‚ÑŒÑÐ¼Ð¸",
        confidence=0.9,
        semantic_weight=0.8,
        related_concepts=["ÑÐ²ÑÐ·Ð¸", "ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ°", "Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸"],
        reasoning_chain=["Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼", "Ð¿Ð¾Ð¸ÑÐº Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ð¹"],
        timestamp=datetime.now(timezone.utc)
    )
    thoughts.append(connection_thought)
    
    if client_id:
        await websocket_manager.send_enhanced_ai_thinking(client_id, connection_thought)
    
    return thoughts

# API endpoints
@app.get("/")
async def root():
    """ÐšÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ endpoint."""
    return {"message": "reLink SEO Platform v4.1.1.022 Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½!"}

@app.get("/health")
async def health_check():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    return {"status": "healthy", "version": settings.api.version}

@app.get("/api/v1/health")
async def api_health():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ API."""
    return {"status": "healthy", "version": settings.api.version}

@app.get("/api/v1/version")
async def get_version():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÑ€ÑÐ¸Ð¸ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    try:
        version_file = Path("VERSION")
        if version_file.exists():
            with open(version_file, 'r', encoding='utf-8') as f:
                version = f.read().strip()
        else:
            version = settings.api.version
        
        return {
            "version": version,
            "buildDate": datetime.now().strftime('%Y-%m-%d'),
            "commitHash": os.getenv("GIT_COMMIT_HASH", ""),
            "environment": os.getenv("ENVIRONMENT", "development")
        }
    except Exception as e:
        return {
            "version": settings.api.version,
            "buildDate": datetime.now().strftime('%Y-%m-%d'),
            "error": str(e)
        }

@app.get("/api/v1/settings")
async def get_settings():
    """Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº Ð´Ð»Ñ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ð°."""
    return {
        "theme": "light",
        "language": "ru",
        "features": {
            "ai_recommendations": True,
            "advanced_benchmark": True,
            "notifications": True,
            "export": True
        },
        "version": settings.api.version
    }

@app.get("/api/v1/ollama_status")
async def get_ollama_status():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ollama."""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get("http://ollama:11434/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [model.get("name", "") for model in models]
                
                return {
                    "ready_for_work": len(model_names) > 0,
                    "server_available": True,
                    "model_loaded": len(model_names) > 0,
                    "message": f"Ð“Ð¾Ñ‚Ð¾Ð² Ðº Ñ€Ð°Ð±Ð¾Ñ‚Ðµ ({len(model_names)} Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹)" if model_names else "ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹",
                    "status": "available",
                    "connection": "connected",
                    "models_count": len(model_names),
                    "available_models": model_names,
                    "timestamp": datetime.now().isoformat(),
                    "last_check": datetime.now().isoformat()
                }
            else:
                return {
                    "ready_for_work": False,
                    "server_available": False,
                    "model_loaded": False,
                    "message": f"Ollama Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» ÑÐ¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐ¾Ð¼ {response.status_code}",
                    "status": "error",
                    "connection": "disconnected",
                    "models_count": 0,
                    "available_models": [],
                    "timestamp": datetime.now().isoformat(),
                    "last_check": datetime.now().isoformat()
                }
    except Exception as e:
        return {
            "ready_for_work": False,
            "server_available": False,
            "model_loaded": False,
            "message": f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ: {str(e)}",
            "status": "unavailable",
            "connection": "disconnected",
            "models_count": 0,
            "available_models": [],
            "timestamp": datetime.now().isoformat(),
            "last_check": datetime.now().isoformat()
        }

@app.get("/api/v1/domains")
async def get_domains():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²."""
    try:
        async with engine.begin() as conn:
            result = await conn.execute(select(Domain))
            domains = result.scalars().all()
            return [
                {
                    "id": domain.id,
                    "name": domain.name,
                    "display_name": domain.display_name,
                    "description": domain.description,
                    "total_posts": domain.total_posts,
                    "total_analyses": domain.total_analyses,
                    "last_analysis_at": domain.last_analysis_at.isoformat() if domain.last_analysis_at else None
                }
                for domain in domains
            ]
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/v1/analysis_history")
async def get_analysis_history():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²."""
    try:
        async with engine.begin() as conn:
            result = await conn.execute(select(AnalysisHistory).order_by(AnalysisHistory.created_at.desc()))
            histories = result.scalars().all()
            return [
                {
                    "id": history.id,
                    "domain_id": history.domain_id,
                    "posts_analyzed": history.posts_analyzed,
                    "connections_found": history.connections_found,
                    "recommendations_generated": history.recommendations_generated,
                    "created_at": history.created_at.isoformat(),
                    "completed_at": history.completed_at.isoformat() if history.completed_at else None
                }
                for history in histories
            ]
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/v1/benchmarks")
async def get_benchmarks():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð²."""
    try:
        # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð´Ð»Ñ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¾Ð²
        return [
            {
                "id": 1,
                "name": "SEO Basic Benchmark",
                "description": "Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ SEO Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€Ðº",
                "benchmark_type": "seo_basic",
                "status": "completed",
                "overall_score": 85.5,
                "created_at": datetime.now().isoformat()
            }
        ]
    except Exception as e:
        return {"error": str(e)}

@app.get("/metrics")
async def get_metrics():
    """Endpoint Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Prometheus"""
    return await get_metrics()

@app.get("/api/v1/monitoring/health")
async def get_monitoring_health():
    """Endpoint Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼"""
    return await get_health_status()

@app.get("/api/v1/monitoring/stats")
async def get_monitoring_stats():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
    try:
        return {
            "uptime": "99.9%",
            "response_time": "150ms",
            "error_rate": "0.1%",
            "active_connections": 10,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸")

@app.get("/api/v1/optimization/report")
async def get_optimization_report():
    """
    ðŸ§  ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾Ð± Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ñ… Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº
    - ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
    - Ð˜ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    - Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ LLM
    """
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾Ñ‚ SystemAnalyzer
        report = await system_analyzer.get_optimization_report()
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
        enhanced_report = {
            **report,
            "optimization_status": {
                "llm_recommendations_applied": True,
                "adaptive_optimization_active": True,
                "performance_monitoring": True,
                "knowledge_base_entries": len(system_analyzer.knowledge_base),
                "last_optimization": datetime.now().isoformat()
            },
            "system_insights": {
                "apple_silicon_detected": report["system_specs"]["apple_silicon"],
                "gpu_acceleration_available": report["system_specs"]["gpu_available"],
                "memory_optimization": "high" if report["system_specs"]["memory_gb"] >= 16 else "medium",
                "cpu_utilization_optimal": report["system_specs"]["cpu_count"] >= 6
            },
            "performance_metrics": {
                "avg_response_time": report["performance_history"]["recent_avg_response_time"],
                "success_rate": report["performance_history"]["recent_success_rate"],
                "total_requests_processed": report["performance_history"]["total_records"],
                "optimization_effectiveness": "excellent" if report["performance_history"]["recent_avg_response_time"] < 2.0 else "good"
            },
            "llm_insights": {
                "used_model": report["optimized_config"]["model"],
                "temperature_optimized": report["optimized_config"]["temperature"],
                "context_length_optimized": report["optimized_config"]["context_length"],
                "batch_size_optimized": report["optimized_config"]["batch_size"]
            }
        }
        
        return enhanced_report
        
    except Exception as e:
        logger.error(f"Error getting optimization report: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾Ð± Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸: {str(e)}"
        )

@app.get("/api/v1/optimization/environment")
async def get_optimization_environment():
    """
    ðŸ”§ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ollama
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
    Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ollama Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒÑŽ
    """
    try:
        env_vars = await system_analyzer.get_environment_variables()
        
        return {
            "environment_variables": env_vars,
            "optimization_applied": True,
            "recommended_ollama_command": f"OLLAMA_HOST={env_vars['OLLAMA_HOST']} OLLAMA_ORIGINS={env_vars['OLLAMA_ORIGINS']} ollama serve",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error getting environment variables: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ: {str(e)}"
        )

@app.post("/api/v1/optimization/trigger")
async def trigger_optimization():
    """
    ðŸ”„ ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    
    Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÑ‚ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚
    Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ» Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    """
    try:
        # Ð¡Ð±Ñ€Ð¾Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
        system_analyzer.optimized_config = None
        
        # Ð—Ð°Ð¿ÑƒÑÐº Ð½Ð¾Ð²Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        new_config = await system_analyzer.optimize_config()
        
        return {
            "message": "ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°",
            "new_config": {
                "used_model": new_config.model,
                "num_gpu": new_config.num_gpu,
                "num_thread": new_config.num_thread,
                "batch_size": new_config.batch_size,
                "context_length": new_config.context_length,
                "semaphore_limit": new_config.semaphore_limit
            },
            "optimization_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error triggering optimization: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸: {str(e)}"
        )

@app.get("/api/v1/cache/stats")
async def get_cache_stats():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÐºÑÑˆÐ°"""
    try:
        return {
            "memory_cache_size": 0,
            "redis_cache_size": 0,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÐºÑÑˆÐ°")

@app.post("/api/v1/cache/clear")
async def clear_cache():
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÐºÑÑˆÐ°"""
    try:
        return {"success": True, "message": "ÐšÑÑˆ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½"}
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ ÐºÑÑˆÐ°")

@app.delete("/api/v1/cache/{pattern}")
async def clear_cache_pattern(pattern: str):
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÐºÑÑˆÐ° Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñƒ"""
    try:
        return {"success": True, "deleted_count": 0, "pattern": pattern}
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ ÐºÑÑˆÐ°")

# Endpoints Ð´Ð»Ñ SEO Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹
@app.post("/api/v1/seo/analyze", response_model=SEOAnalysisResult)
async def analyze_domain(
    request_data: DomainAnalysisRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð¾Ð¼ÐµÐ½Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
    try:
        # Ð—Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÐµÑ‚ Ð»Ð¾Ð³Ð¸ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°
        # ÐŸÐ¾ÐºÐ° Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ
        analysis_result = SEOAnalysisResult(
            domain=request_data.domain,
            analysis_date=datetime.now(timezone.utc),
            score=75.5,
            recommendations=[
                {
                    "type": "internal_linking",
                    "priority": "high",
                    "description": "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÑÑ‚Ð°Ñ‚ÑŒÑÐ¼Ð¸"
                }
            ],
            metrics={
                "total_posts": 100,
                "internal_links": 50,
                "semantic_density": 0.8
            },
            status="completed"
        )
        
        return analysis_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¾Ð¼ÐµÐ½Ð°")

@app.post("/api/v1/seo/competitors")
async def analyze_competitors(
    request_data: CompetitorAnalysisRequest,
    current_user: User = Depends(get_current_user)
):
    """ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²"""
    try:
        result = {
            "domain": request_data.domain,
            "competitors": request_data.competitors,
            "analysis_date": datetime.now().isoformat(),
            "metrics": {
                "traffic_comparison": {},
                "backlink_analysis": {},
                "keyword_overlap": {}
            }
        }
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²")

# Endpoints Ð´Ð»Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°
@app.get("/api/v1/history")
async def get_analysis_history(
    request: AnalysisHistoryRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð² Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
    try:
        history = [
            {
                "id": 1,
                "domain": "example.com",
                "analysis_date": datetime.now().isoformat(),
                "status": "completed",
                "score": 85.0
            }
        ]
        
        return {
            "history": history,
            "total": len(history),
            "limit": request.limit,
            "offset": request.offset
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸")

@app.post("/api/v1/export")
async def export_data(
    request_data: ExportRequest,
    current_user: User = Depends(get_current_user)
):
    """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    try:
        export_result = {
            "format": request_data.format,
            "analysis_count": len(request_data.analysis_ids),
            "download_url": f"/api/v1/downloads/export_{datetime.now().timestamp()}.{request_data.format}",
            "expires_at": (datetime.now() + timedelta(hours=24)).isoformat()
        }
        
        return export_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail="ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…")

# Endpoints Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
@app.post("/api/v1/validate/domain")
async def validate_domain(domain: str):
    """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð´Ð¾Ð¼ÐµÐ½Ð°"""
    try:
        import re
        pattern = r'^[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?(\.[a-zA-Z0-9]([a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?)*$'
        if re.match(pattern, domain):
            return {
                "valid": True,
                "domain": domain,
                "sanitized": domain.lower().strip()
            }
        else:
            return {
                "valid": False,
                "domain": domain,
                "error": "ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð¾Ð¼ÐµÐ½Ð°"
            }
    except ValueError as e:
        return {
            "valid": False,
            "domain": domain,
            "error": str(e)
        }

@app.post("/api/v1/validate/email")
async def validate_email(email: str):
    """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ email"""
    try:
        import re
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if re.match(pattern, email):
            return {
                "valid": True,
                "email": email,
                "sanitized": email.lower().strip()
            }
        else:
            return {
                "valid": False,
                "email": email,
                "error": "ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ email"
            }
    except Exception as e:
        return {
            "valid": False,
            "email": email,
            "error": str(e)
        }

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Pydantic"""
    return JSONResponse(
        status_code=422,
        content={"detail": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…", "errors": exc.errors()}
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº HTTP Ð¾ÑˆÐ¸Ð±Ð¾Ðº"""
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail}
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ÐžÐ±Ñ‰Ð¸Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹"""
    return JSONResponse(
        status_code=500,
        content={
            "error": "internal_server_error",
            "message": "Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°",
            "timestamp": datetime.now().isoformat()
        }
    )

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ
@app.on_event("startup")
async def startup_event():
    """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð»Ð¾Ð³Ð¾Ð²
    os.makedirs("logs", exist_ok=True)
    
    print("ðŸš€ reLink SEO Platform v1.0.0 Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½!")

@app.get("/api/v1/rag/cache/stats")
async def get_rag_cache_stats():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ RAG ÐºÑÑˆÐ°"""
    try:
        stats = await cache_manager.get_rag_stats()
        return {
            "status": "success",
            "data": stats,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting RAG cache stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/rag/cache/clear")
async def clear_rag_cache():
    """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° RAG ÐºÑÑˆÐ°"""
    try:
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð²ÑÐµ Ñ‚Ð¸Ð¿Ñ‹ RAG ÐºÑÑˆÐ°
        await cache_manager.rag_cache.clear_expired()
        return {
            "status": "success",
            "message": "RAG cache cleared",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error clearing RAG cache: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/rag/monitoring/metrics")
async def get_rag_monitoring_metrics():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ RAG Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
    try:
        from .monitoring import rag_monitor
        metrics = rag_monitor.get_rag_metrics()
        return {
            "status": "success",
            "data": metrics,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting RAG monitoring metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/rag/monitoring/health")
async def get_rag_health():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹."""
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ ChromaDB
        chroma_client = chromadb.Client()
        collections = chroma_client.list_collections()
        
        return {
            "status": "healthy",
            "chromadb_available": True,
            "collections_count": len(collections),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"RAG health check failed: {e}")
        return {
            "status": "unhealthy",
            "chromadb_available": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# ðŸŽ¨ DIAGRAM GENERATION ENDPOINTS

class DiagramGenerationRequestModel(BaseModel):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹."""
    diagram_type: str
    title: str
    description: str
    components: List[Dict[str, Any]]
    relationships: List[Dict[str, Any]]
    style: Optional[Dict[str, Any]] = None
    width: int = 800
    height: int = 600
    interactive: bool = True
    include_legend: bool = True

class DiagramGenerationResponseModel(BaseModel):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹."""
    diagram_id: int
    svg_content: str
    quality_score: float
    generation_time: float
    used_model: str
    confidence_score: float
    validation_result: Dict[str, Any]

@app.post("/api/diagrams/generate", response_model=DiagramGenerationResponseModel)
async def generate_diagram(
    request: DiagramGenerationRequestModel,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ SVG Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹."""
    try:
        diagram_service = DiagramService()
        
        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐµÑ€Ð²Ð¸ÑÐ°
        diagram_request = DiagramGenerationRequest(
            diagram_type=request.diagram_type,
            title=request.title,
            description=request.description,
            components=request.components,
            relationships=request.relationships,
            style_config=request.style,
            user_id=current_user.id
        )
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñƒ
        result = await diagram_service.generate_diagram(diagram_request, db)
        
        return DiagramGenerationResponseModel(
            diagram_id=result.diagram_id,
            svg_content=result.svg_content,
            quality_score=result.quality_score,
            generation_time=result.generation_time,
            used_model=result.used_model,
            confidence_score=result.confidence_score,
            validation_result=result.validation_result
        )
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {str(e)}"
        )

@app.get("/api/diagrams/templates")
async def get_diagram_templates():
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð² Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼."""
    try:
        diagram_service = DiagramService()
        templates = await diagram_service.get_available_templates()
        return {"templates": templates}
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð²: {str(e)}"
        )

@app.get("/api/diagrams/{diagram_id}")
async def get_diagram(
    diagram_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ð¿Ð¾ ID."""
    try:
        from .models import Diagram
        result = await db.execute(
            select(Diagram).where(
                Diagram.id == diagram_id,
                Diagram.user_id == current_user.id
            )
        )
        diagram = result.scalar_one_or_none()
        
        if not diagram:
            raise HTTPException(status_code=404, detail="Ð”Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
        
        return {
            "id": diagram.id,
            "title": diagram.title,
            "description": diagram.description,
            "svg_content": diagram.svg_content,
            "quality_score": diagram.quality_score,
            "created_at": diagram.created_at.isoformat(),
            "diagram_type": diagram.diagram_type
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹: {str(e)}"
        )

@app.get("/api/diagrams")
async def get_user_diagrams(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    limit: int = 10,
    offset: int = 0
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ."""
    try:
        from .models import Diagram
        result = await db.execute(
            select(Diagram)
            .where(Diagram.user_id == current_user.id)
            .order_by(Diagram.created_at.desc())
            .limit(limit)
            .offset(offset)
        )
        diagrams = result.scalars().all()
        
        return {
            "diagrams": [
                {
                    "id": d.id,
                    "title": d.title,
                    "description": d.description,
                    "diagram_type": d.diagram_type,
                    "quality_score": d.quality_score,
                    "created_at": d.created_at.isoformat()
                }
                for d in diagrams
            ],
            "total": len(diagrams)
        }
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼: {str(e)}"
        )

# ============================================================================
# API Ð­ÐÐ”ÐŸÐžÐ˜ÐÐ¢Ð« Ð”Ð›Ð¯ Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð¯
# ============================================================================

@app.post("/api/v1/tests/", response_model=TestResponse)
async def create_test(
    test_request: TestRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð°"""
    return await testing_service.create_test(test_request, current_user.id, db)

@app.get("/api/v1/tests/", response_model=List[TestResponse])
async def get_tests(
    test_type: Optional[TestType] = None,
    status: Optional[TestStatus] = None,
    priority: Optional[TestPriority] = None,
    environment: Optional[TestEnvironment] = None,
    name_contains: Optional[str] = None,
    description_contains: Optional[str] = None,
    tags: Optional[List[str]] = None,
    limit: int = 50,
    offset: int = 0,
    sort_by: str = "created_at",
    sort_order: str = "desc",
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ñ‚ÐµÑÑ‚Ð¾Ð² Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹"""
    filters = TestFilter(
        test_type=test_type,
        status=status,
        priority=priority,
        environment=environment,
        name_contains=name_contains,
        description_contains=description_contains,
        tags=tags,
        limit=limit,
        offset=offset,
        sort_by=sort_by,
        sort_order=sort_order
    )
    return await testing_service.get_tests(filters, offset, limit, db)

@app.get("/api/v1/tests/{test_id}", response_model=TestResponse)
async def get_test(
    test_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÑÑ‚Ð° Ð¿Ð¾ ID"""
    test = await testing_service.get_test(test_id, db)
    if not test:
        raise_not_found("Ð¢ÐµÑÑ‚ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
    return test

@app.post("/api/v1/tests/{test_id}/execute", response_model=TestExecutionResponse)
async def execute_test(
    test_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ñ‚ÐµÑÑ‚Ð°"""
    return await testing_service.execute_test(test_id, current_user.id, db)

@app.get("/api/v1/test-executions/", response_model=List[TestExecutionResponse])
async def get_test_executions(
    test_id: Optional[str] = None,
    status: Optional[TestStatus] = None,
    limit: int = 50,
    offset: int = 0,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¹ Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    return await testing_service.get_executions(offset, limit, test_id, status, db)

@app.post("/api/v1/test-executions/{execution_id}/cancel")
async def cancel_test_execution(
    execution_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐžÑ‚Ð¼ÐµÐ½Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ñ‚ÐµÑÑ‚Ð°"""
    success = await testing_service.cancel_execution(execution_id, db)
    if not success:
        raise HTTPException(status_code=404, detail="Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
    return {"message": "Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð¼ÐµÐ½ÐµÐ½Ð¾"}

@app.post("/api/v1/test-suites/", response_model=TestSuiteResponse)
async def create_test_suite(
    suite_request: TestSuiteRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½Ð°Ð±Ð¾Ñ€Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    return await testing_service.create_test_suite(suite_request, current_user.id, db)

@app.post("/api/v1/test-suites/{suite_id}/execute", response_model=List[TestExecutionResponse])
async def execute_test_suite(
    suite_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð½Ð°Ð±Ð¾Ñ€Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    return await testing_service.execute_test_suite(suite_id, current_user.id, db)

@app.get("/api/v1/testing/metrics")
async def get_testing_metrics(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
    return await testing_service.get_test_metrics(db=db)

@app.get("/api/v1/testing/health")
async def get_testing_health():
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
    return {
        "status": "healthy",
        "running_executions": len(testing_service.running_executions),
        "timestamp": datetime.now().isoformat()
    }

app.include_router(testing_router, prefix="/api/v1/testing")
app.include_router(auth_router, prefix="/api/v1")

@app.post("/api/v1/wordpress/index")
async def index_wordpress_site(
    request: WPRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ WordPress ÑÐ°Ð¹Ñ‚Ð°."""
    try:
        domain = request.domain.strip().lower()
        if not domain.startswith(('http://', 'https://')):
            domain = f"https://{domain}"
        
        logger.info(f"ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸ÑŽ WordPress ÑÐ°Ð¹Ñ‚Ð°: {domain}")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ ÑƒÐ¶Ðµ Ð´Ð¾Ð¼ÐµÐ½ Ð² Ð±Ð°Ð·Ðµ
        existing_domain = await db.execute(
            select(Domain).where(Domain.name == domain)
        )
        domain_obj = existing_domain.scalar_one_or_none()
        
        if not domain_obj:
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹ Ð´Ð¾Ð¼ÐµÐ½
            domain_obj = Domain(
                name=domain,
                display_name=domain.replace('https://', '').replace('http://', ''),
                description=f"WordPress ÑÐ°Ð¹Ñ‚ {domain}",
                owner_id=current_user.id
            )
            db.add(domain_obj)
            await db.commit()
            await db.refresh(domain_obj)
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ WordPress ÑÐ°Ð¹Ñ‚
        posts = await parse_wordpress_site(domain, request.client_id)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ð¾ÑÑ‚Ñ‹ Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        saved_posts = []
        for post_data in posts:
            post = WordPressPost(
                domain_id=domain_obj.id,
                wp_post_id=post_data.get('id', 0),
                title=post_data.get('title', ''),
                content=post_data.get('content', ''),
                excerpt=post_data.get('excerpt', ''),
                link=post_data.get('link', ''),
                published_at=post_data.get('date', datetime.now(timezone.utc))
            )
            db.add(post)
            saved_posts.append(post)
        
        await db.commit()
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð´Ð¾Ð¼ÐµÐ½Ð°
        domain_obj.total_posts = len(saved_posts)
        domain_obj.last_analysis_at = datetime.now(timezone.utc)
        await db.commit()
        
        return {
            "status": "success",
            "message": f"Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°. ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(saved_posts)} ÑÑ‚Ð°Ñ‚ÐµÐ¹.",
            "domain": domain,
            "posts_count": len(saved_posts),
            "domain_id": domain_obj.id
        }
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ WordPress ÑÐ°Ð¹Ñ‚Ð°: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸: {str(e)}")

@app.post("/api/v1/wordpress/reindex")
async def reindex_wordpress_site(
    request: WPRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Ð ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ WordPress ÑÐ°Ð¹Ñ‚Ð°."""
    try:
        domain = request.domain.strip().lower()
        if not domain.startswith(('http://', 'https://')):
            domain = f"https://{domain}"
        
        logger.info(f"ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ñ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸ÑŽ WordPress ÑÐ°Ð¹Ñ‚Ð°: {domain}")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð´Ð¾Ð¼ÐµÐ½ Ð² Ð±Ð°Ð·Ðµ
        existing_domain = await db.execute(
            select(Domain).where(Domain.name == domain)
        )
        domain_obj = existing_domain.scalar_one_or_none()
        
        if not domain_obj:
            raise HTTPException(status_code=404, detail="Ð”Ð¾Ð¼ÐµÐ½ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸ÑŽ.")
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð¿Ð¾ÑÑ‚Ñ‹
        await db.execute(
            delete(WordPressPost).where(WordPressPost.domain_id == domain_obj.id)
        )
        await db.commit()
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ WordPress ÑÐ°Ð¹Ñ‚ Ð·Ð°Ð½Ð¾Ð²Ð¾
        posts = await parse_wordpress_site(domain, request.client_id)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ðµ Ð¿Ð¾ÑÑ‚Ñ‹ Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        saved_posts = []
        for post_data in posts:
            post = WordPressPost(
                domain_id=domain_obj.id,
                wp_post_id=post_data.get('id', 0),
                title=post_data.get('title', ''),
                content=post_data.get('content', ''),
                excerpt=post_data.get('excerpt', ''),
                link=post_data.get('link', ''),
                published_at=post_data.get('date', datetime.now(timezone.utc))
            )
            db.add(post)
            saved_posts.append(post)
        
        await db.commit()
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð´Ð¾Ð¼ÐµÐ½Ð°
        domain_obj.total_posts = len(saved_posts)
        domain_obj.last_analysis_at = datetime.now(timezone.utc)
        await db.commit()
        
        return {
            "status": "success",
            "message": f"Ð ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°. ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ {len(saved_posts)} ÑÑ‚Ð°Ñ‚ÐµÐ¹.",
            "domain": domain,
            "posts_count": len(saved_posts),
            "domain_id": domain_obj.id,
            "reindexed_at": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ WordPress ÑÐ°Ð¹Ñ‚Ð°: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸: {str(e)}")

async def parse_wordpress_site(domain: str, client_id: str = None) -> List[dict]:
    """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ WordPress ÑÐ°Ð¹Ñ‚Ð° Ñ‡ÐµÑ€ÐµÐ· REST API Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚ÐµÐ¹."""
    posts = []
    
    try:
        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ URL Ð´Ð»Ñ WordPress REST API
        api_url = f"{domain.rstrip('/')}/wp-json/wp/v2/posts"
        
        if client_id:
            await websocket_manager.send_step(client_id, "ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº WordPress API", 0, 1)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ Ñ‡ÐµÑ€ÐµÐ· WordPress REST API
        async with httpx.AsyncClient(timeout=30.0) as client:
            # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ 100 ÑÑ‚Ð°Ñ‚ÐµÐ¹
            response = await client.get(f"{api_url}?per_page=100")
            
            if response.status_code != 200:
                # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÐ½ÑŒÑˆÐµ ÑÑ‚Ð°Ñ‚ÐµÐ¹
                response = await client.get(f"{api_url}?per_page=50")
                
                if response.status_code != 200:
                    # Ð•ÑÐ»Ð¸ Ð¸ ÑÑ‚Ð¾ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ 10 ÑÑ‚Ð°Ñ‚ÐµÐ¹
                    response = await client.get(f"{api_url}?per_page=10")
                    
                    if response.status_code != 200:
                        raise Exception(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº WordPress API: {response.status_code}")
            
            wp_posts = response.json()
            
            if client_id:
                await websocket_manager.send_step(client_id, f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(wp_posts)} ÑÑ‚Ð°Ñ‚ÐµÐ¹", 1, len(wp_posts))
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´ÑƒÑŽ ÑÑ‚Ð°Ñ‚ÑŒÑŽ
            for i, wp_post in enumerate(wp_posts):
                try:
                    if client_id:
                        await websocket_manager.send_step(client_id, f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÑ‚Ð°Ñ‚ÑŒÐ¸ {i+1}", i+1, len(wp_posts))
                    
                    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· WordPress API Ð¾Ñ‚Ð²ÐµÑ‚Ð°
                    post_id = wp_post.get('id', 0)
                    title = wp_post.get('title', {}).get('rendered', '')
                    content = wp_post.get('content', {}).get('rendered', '')
                    excerpt = wp_post.get('excerpt', {}).get('rendered', '')
                    link = wp_post.get('link', '')
                    
                    # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð´Ð°Ñ‚Ñƒ
                    date = datetime.now(timezone.utc)
                    date_str = wp_post.get('date', '')
                    if date_str:
                        try:
                            date = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                        except:
                            pass
                    
                    # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ HTML Ñ‚ÐµÐ³Ð¸ Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
                    if content:
                        soup = BeautifulSoup(content, 'html.parser')
                        content = soup.get_text().strip()
                    
                    if excerpt:
                        soup = BeautifulSoup(excerpt, 'html.parser')
                        excerpt = soup.get_text().strip()
                    
                    if title and content:
                        posts.append({
                            'id': post_id,
                            'title': title,
                            'content': content,
                            'excerpt': excerpt,
                            'link': link,
                            'date': date
                        })
                    
                    # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¼ÐµÐ¶Ð´Ñƒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ ÑÑ‚Ð°Ñ‚ÐµÐ¹
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ {i+1}: {e}")
                    continue
            
            if client_id:
                await websocket_manager.send_step(client_id, "Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°", len(wp_posts), len(wp_posts))
        
        return posts
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ðµ WordPress ÑÐ°Ð¹Ñ‚Ð°: {e}")
        if client_id:
            await websocket_manager.send_error(client_id, "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°", str(e))
        raise

@app.post("/api/v1/seo/recommendations")
async def get_seo_recommendations(
    request_data: DomainAnalysisRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ SEO Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¸Ð½Ð´ÐµÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…."""
    try:
        domain = request_data.domain.strip().lower()
        if not domain.startswith(('http://', 'https://')):
            domain = f"https://{domain}"
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        domain_obj = await db.execute(
            select(Domain).where(Domain.name == domain)
        )
        domain_obj = domain_obj.scalar_one_or_none()
        
        if not domain_obj:
            raise HTTPException(status_code=404, detail="Ð”Ð¾Ð¼ÐµÐ½ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸ÑŽ.")
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÑÐµ Ð¿Ð¾ÑÑ‚Ñ‹ Ð´Ð¾Ð¼ÐµÐ½Ð°
        posts = await db.execute(
            select(WordPressPost).where(WordPressPost.domain_id == domain_obj.id)
        )
        posts = posts.scalars().all()
        
        if not posts:
            raise HTTPException(status_code=404, detail="Ð¡Ñ‚Ð°Ñ‚ÑŒÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸ÑŽ.")
        
        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð¸ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
        recommendations = await generate_seo_recommendations(posts, domain, request_data.client_id)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð°Ð½Ð°Ð»Ð¸Ð· Ð² Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
        analysis = AnalysisHistory(
            domain_id=domain_obj.id,
            user_id=current_user.id,
            posts_analyzed=len(posts),
            connections_found=len([r for r in recommendations if r.get('type') == 'internal_linking']),
            recommendations_generated=len(recommendations),
            recommendations=recommendations,
            thematic_analysis={
                "total_posts": len(posts),
                "avg_content_length": sum(len(p.content) for p in posts) / len(posts),
                "topics_found": len(set(p.content_type for p in posts if p.content_type))
            },
            semantic_metrics={
                "content_quality_avg": sum(p.content_quality_score for p in posts) / len(posts),
                "semantic_richness_avg": sum(p.semantic_richness for p in posts) / len(posts)
            },
            llm_model_used=OLLAMA_MODEL,
            processing_time_seconds=0.0
        )
        db.add(analysis)
        await db.commit()
        
        return {
            "status": "success",
            "domain": domain,
            "posts_analyzed": len(posts),
            "recommendations": recommendations,
            "analysis_id": analysis.id,
            "generated_at": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ SEO Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹: {str(e)}")

async def generate_seo_recommendations(posts: List[WordPressPost], domain: str, client_id: str = None) -> List[dict]:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ SEO Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿Ð¾ÑÑ‚Ð¾Ð²."""
    recommendations = []
    
    try:
        if client_id:
            await websocket_manager.send_ai_thinking(client_id, "ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ SEO Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹...", "analyzing", "ðŸ”")
        
        # ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº
        internal_linking_recs = await analyze_internal_linking(posts, client_id)
        recommendations.extend(internal_linking_recs)
        
        # ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
        content_recs = await analyze_content_quality(posts, client_id)
        recommendations.extend(content_recs)
        
        # ÐÐ½Ð°Ð»Ð¸Ð· ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ¸
        semantic_recs = await analyze_semantic_optimization(posts, client_id)
        recommendations.extend(semantic_recs)
        
        # ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹
        structure_recs = await analyze_content_structure(posts, client_id)
        recommendations.extend(structure_recs)
        
        if client_id:
            await websocket_manager.send_ai_thinking(client_id, f"Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ {len(recommendations)} Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹", "optimizing", "âœ…")
        
        return recommendations
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹: {e}")
        if client_id:
            await websocket_manager.send_error(client_id, "ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹", str(e))
        raise

async def analyze_internal_linking(posts: List[WordPressPost], client_id: str = None) -> List[dict]:
    """ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº."""
    recommendations = []
    
    # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· - Ð¸Ñ‰ÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ Ð±ÐµÐ· Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº
    posts_without_links = []
    for post in posts:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ðµ ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ð° Ð´Ñ€ÑƒÐ³Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸
        content_lower = post.content.lower()
        has_internal_links = any(
            other_post.title.lower() in content_lower 
            for other_post in posts 
            if other_post.id != post.id
        )
        
        if not has_internal_links:
            posts_without_links.append(post)
    
    if posts_without_links:
        recommendations.append({
            "type": "internal_linking",
            "priority": "high",
            "title": "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸",
            "description": f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(posts_without_links)} ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ð±ÐµÐ· Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº",
            "details": [
                {
                    "post_title": post.title,
                    "post_url": post.link,
                    "suggested_links": [
                        other_post.title 
                        for other_post in posts[:3] 
                        if other_post.id != post.id
                    ]
                }
                for post in posts_without_links[:5]  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 5
            ]
        })
    
    return recommendations

async def analyze_content_quality(posts: List[WordPressPost], client_id: str = None) -> List[dict]:
    """ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°."""
    recommendations = []
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð»Ð¸Ð½Ñ‹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
    short_posts = [post for post in posts if len(post.content) < 1000]
    if short_posts:
        recommendations.append({
            "type": "content_quality",
            "priority": "medium",
            "title": "Ð Ð°ÑÑˆÐ¸Ñ€Ð¸Ñ‚ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸",
            "description": f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(short_posts)} ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ñ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¼ Ð¾Ð±ÑŠÐµÐ¼Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°",
            "details": [
                {
                    "post_title": post.title,
                    "post_url": post.link,
                    "current_length": len(post.content),
                    "recommended_length": "1500+ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²"
                }
                for post in short_posts[:3]
            ]
        })
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²
    posts_without_h1 = [post for post in posts if not post.title or len(post.title) < 10]
    if posts_without_h1:
        recommendations.append({
            "type": "content_quality",
            "priority": "medium",
            "title": "Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÑÑ‚Ð°Ñ‚ÐµÐ¹",
            "description": f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(posts_without_h1)} ÑÑ‚Ð°Ñ‚ÐµÐ¹ Ñ Ð½ÐµÐ¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ð¼Ð¸",
            "details": [
                {
                    "post_title": post.title,
                    "post_url": post.link,
                    "current_length": len(post.title),
                    "recommendation": "Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ 50-60 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²"
                }
                for post in posts_without_h1[:3]
            ]
        })
    
    return recommendations

async def analyze_semantic_optimization(posts: List[WordPressPost], client_id: str = None) -> List[dict]:
    """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸."""
    recommendations = []
    
    # ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÑÐ»Ð¾Ð²
    all_content = " ".join([post.content for post in posts])
    words = word_tokenize(all_content.lower())
    words = [word for word in words if word.isalpha() and word not in RUSSIAN_STOP_WORDS]
    
    # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ ÑÐ»Ð¾Ð²
    word_freq = defaultdict(int)
    for word in words:
        word_freq[word] += 1
    
    # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð°ÑÑ‚Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    
    recommendations.append({
        "type": "semantic_optimization",
        "priority": "medium",
        "title": "ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°",
        "description": "ÐÐ½Ð°Ð»Ð¸Ð· ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ ÑÐ´Ñ€Ð° ÑÐ°Ð¹Ñ‚Ð°",
        "details": {
            "top_keywords": [{"word": word, "frequency": freq} for word, freq in top_words],
            "recommendation": "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð² Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ñ… Ð¸ Ð¼ÐµÑ‚Ð°-Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑÑ…"
        }
    })
    
    return recommendations

async def analyze_content_structure(posts: List[WordPressPost], client_id: str = None) -> List[dict]:
    """ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°."""
    recommendations = []
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð³Ñ€ÑƒÐ¿Ð¿
    content_types = defaultdict(int)
    for post in posts:
        if post.content_type:
            content_types[post.content_type] += 1
    
    if len(content_types) < 3:
        recommendations.append({
            "type": "content_structure",
            "priority": "low",
            "title": "Ð Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ñ‚ÑŒ Ñ‚Ð¸Ð¿Ñ‹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°",
            "description": "Ð¡Ð°Ð¹Ñ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¸Ð¿Ð¾Ð² ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°",
            "details": {
                "current_types": dict(content_types),
                "recommendation": "Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°: Ð³Ð°Ð¹Ð´Ñ‹, Ð¾Ð±Ð·Ð¾Ñ€Ñ‹, Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸, Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ"
            }
        })
    
    return recommendations

@app.get("/api/v1/insights/{domain_id}")
async def get_domain_insights(
    domain_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¿Ð¾ Ð´Ð¾Ð¼ÐµÐ½Ñƒ."""
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½
        domain = await db.execute(
            select(Domain).where(Domain.id == domain_id)
        )
        domain = domain.scalar_one_or_none()
        
        if not domain:
            raise HTTPException(status_code=404, detail="Ð”Ð¾Ð¼ÐµÐ½ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾ÑÑ‚Ñ‹ Ð´Ð¾Ð¼ÐµÐ½Ð°
        posts = await db.execute(
            select(WordPressPost).where(WordPressPost.domain_id == domain_id)
        )
        posts = posts.scalars().all()
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²
        analyses = await db.execute(
            select(AnalysisHistory)
            .where(AnalysisHistory.domain_id == domain_id)
            .order_by(AnalysisHistory.created_at.desc())
            .limit(5)
        )
        analyses = analyses.scalars().all()
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹
        insights = await generate_domain_insights(posts, analyses)
        
        return {
            "status": "success",
            "domain": {
                "id": domain.id,
                "name": domain.name,
                "display_name": domain.display_name,
                "total_posts": domain.total_posts,
                "last_analysis": domain.last_analysis_at.isoformat() if domain.last_analysis_at else None
            },
            "insights": insights,
            "recent_analyses": [
                {
                    "id": analysis.id,
                    "created_at": analysis.created_at.isoformat(),
                    "posts_analyzed": analysis.posts_analyzed,
                    "recommendations_count": analysis.recommendations_generated
                }
                for analysis in analyses
            ]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð²: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð²: {str(e)}")

@app.get("/api/v1/analytics/{domain_id}")
async def get_domain_analytics(
    domain_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ð¿Ð¾ Ð´Ð¾Ð¼ÐµÐ½Ñƒ."""
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾Ð¼ÐµÐ½
        domain = await db.execute(
            select(Domain).where(Domain.id == domain_id)
        )
        domain = domain.scalar_one_or_none()
        
        if not domain:
            raise HTTPException(status_code=404, detail="Ð”Ð¾Ð¼ÐµÐ½ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½")
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾ÑÑ‚Ñ‹ Ð´Ð¾Ð¼ÐµÐ½Ð°
        posts = await db.execute(
            select(WordPressPost).where(WordPressPost.domain_id == domain_id)
        )
        posts = posts.scalars().all()
        
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÑƒ
        analytics = await generate_domain_analytics(posts)
        
        return {
            "status": "success",
            "domain": {
                "id": domain.id,
                "name": domain.name,
                "display_name": domain.display_name
            },
            "analytics": analytics,
            "generated_at": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸: {str(e)}")

async def generate_domain_insights(posts: List[WordPressPost], analyses: List[AnalysisHistory]) -> dict:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¿Ð¾ Ð´Ð¾Ð¼ÐµÐ½Ñƒ."""
    insights = {
        "content_insights": {},
        "performance_insights": {},
        "seo_insights": {},
        "trends": {}
    }
    
    if not posts:
        return insights
    
    # Ð˜Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¿Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ñƒ
    total_content_length = sum(len(post.content) for post in posts)
    avg_content_length = total_content_length / len(posts)
    
    insights["content_insights"] = {
        "total_posts": len(posts),
        "total_content_length": total_content_length,
        "average_content_length": round(avg_content_length, 2),
        "content_distribution": {
            "short_posts": len([p for p in posts if len(p.content) < 1000]),
            "medium_posts": len([p for p in posts if 1000 <= len(p.content) < 3000]),
            "long_posts": len([p for p in posts if len(p.content) >= 3000])
        },
        "top_performing_content": [
            {
                "title": post.title,
                "url": post.link,
                "length": len(post.content),
                "quality_score": post.content_quality_score
            }
            for post in sorted(posts, key=lambda p: p.content_quality_score, reverse=True)[:5]
        ]
    }
    
    # Ð˜Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¿Ð¾ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    if analyses:
        latest_analysis = analyses[0]
        insights["performance_insights"] = {
            "last_analysis_date": latest_analysis.created_at.isoformat(),
            "total_recommendations": latest_analysis.recommendations_generated,
            "internal_links_found": latest_analysis.connections_found,
            "analysis_metrics": latest_analysis.semantic_metrics
        }
    
    # SEO Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹
    all_content = " ".join([post.content for post in posts])
    words = word_tokenize(all_content.lower())
    words = [word for word in words if word.isalpha() and word not in RUSSIAN_STOP_WORDS]
    
    word_freq = defaultdict(int)
    for word in words:
        word_freq[word] += 1
    
    top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:15]
    
    insights["seo_insights"] = {
        "top_keywords": [{"word": word, "frequency": freq} for word, freq in top_keywords],
        "keyword_density": len(set(words)) / len(words) if words else 0,
        "content_optimization_score": sum(post.content_quality_score for post in posts) / len(posts)
    }
    
    # Ð¢Ñ€ÐµÐ½Ð´Ñ‹
    if len(analyses) > 1:
        insights["trends"] = {
            "analysis_frequency": "regular" if len(analyses) >= 3 else "occasional",
            "improvement_trend": "positive" if analyses[0].recommendations_generated < analyses[-1].recommendations_generated else "stable"
        }
    
    return insights

async def generate_domain_analytics(posts: List[WordPressPost]) -> dict:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ¸ Ð¿Ð¾ Ð´Ð¾Ð¼ÐµÐ½Ñƒ."""
    analytics = {
        "content_metrics": {},
        "semantic_analysis": {},
        "quality_metrics": {},
        "engagement_potential": {}
    }
    
    if not posts:
        return analytics
    
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
    content_lengths = [len(post.content) for post in posts]
    analytics["content_metrics"] = {
        "total_posts": len(posts),
        "total_words": sum(len(post.content.split()) for post in posts),
        "average_length": round(sum(content_lengths) / len(content_lengths), 2),
        "min_length": min(content_lengths),
        "max_length": max(content_lengths),
        "length_distribution": {
            "0-500": len([l for l in content_lengths if l < 500]),
            "500-1000": len([l for l in content_lengths if 500 <= l < 1000]),
            "1000-2000": len([l for l in content_lengths if 1000 <= l < 2000]),
            "2000+": len([l for l in content_lengths if l >= 2000])
        }
    }
    
    # Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
    all_content = " ".join([post.content for post in posts])
    words = word_tokenize(all_content.lower())
    words = [word for word in words if word.isalpha() and word not in RUSSIAN_STOP_WORDS]
    
    word_freq = defaultdict(int)
    for word in words:
        word_freq[word] += 1
    
    analytics["semantic_analysis"] = {
        "unique_words": len(set(words)),
        "total_words": len(words),
        "lexical_diversity": len(set(words)) / len(words) if words else 0,
        "top_keywords": [{"word": word, "frequency": freq} for word, freq in sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]]
    }
    
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
    quality_scores = [post.content_quality_score for post in posts]
    semantic_scores = [post.semantic_richness for post in posts]
    
    analytics["quality_metrics"] = {
        "average_content_quality": round(sum(quality_scores) / len(quality_scores), 3),
        "average_semantic_richness": round(sum(semantic_scores) / len(semantic_scores), 3),
        "quality_distribution": {
            "excellent": len([s for s in quality_scores if s >= 0.8]),
            "good": len([s for s in quality_scores if 0.6 <= s < 0.8]),
            "average": len([s for s in quality_scores if 0.4 <= s < 0.6]),
            "poor": len([s for s in quality_scores if s < 0.4])
        }
    }
    
    # ÐŸÐ¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð» Ð²Ð¾Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
    analytics["engagement_potential"] = {
        "linkability_score": round(sum(post.linkability_score for post in posts) / len(posts), 3),
        "content_types": {
            "guides": len([p for p in posts if p.content_type == "guide"]),
            "reviews": len([p for p in posts if p.content_type == "review"]),
            "news": len([p for p in posts if p.content_type == "news"]),
            "other": len([p for p in posts if not p.content_type])
        },
        "target_audience_diversity": len(set(p.target_audience for p in posts if p.target_audience))
    }
    
    return analytics

@app.post("/api/v1/test/setup")
async def setup_test_user():
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸."""
    try:
        from .auth import get_password_hash
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ ÑƒÐ¶Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ
        async with async_sessionmaker(engine)() as db:
            existing_user = await db.execute(
                select(User).where(User.username == "test_user")
            )
            existing_user = existing_user.scalar_one_or_none()
            
            if existing_user:
                return {
                    "status": "success",
                    "message": "Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚",
                    "user": {
                        "id": existing_user.id,
                        "username": existing_user.username,
                        "email": existing_user.email
                    }
                }
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
            test_user = User(
                username="test_user",
                email="test@example.com",
                full_name="Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ",
                hashed_password=get_password_hash("test123"),
                is_active=True
            )
            db.add(test_user)
            await db.commit()
            await db.refresh(test_user)
            
            return {
                "status": "success",
                "message": "Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑÐ¾Ð·Ð´Ð°Ð½",
                "user": {
                    "id": test_user.id,
                    "username": test_user.username,
                    "email": test_user.email
                }
            }
            
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {str(e)}")

@app.post("/api/v1/test/login")
async def test_login():
    """Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð»Ð¾Ð³Ð¸Ð½ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ."""
    try:
        from .auth import create_access_token
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ð¾ÐºÐµÐ½ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        access_token = create_access_token(data={"sub": "test_user"})
        
        return {
            "status": "success",
            "access_token": access_token,
            "token_type": "bearer",
            "user": {
                "username": "test_user",
                "email": "test@example.com"
            }
        }
        
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð»Ð¾Ð³Ð¸Ð½Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {e}")
        raise HTTPException(status_code=500, detail=f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð»Ð¾Ð³Ð¸Ð½Ð°: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

