"""FastAPI-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫."""

from __future__ import annotations

import asyncio
import os
import re
import json
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from collections import defaultdict
from dataclasses import dataclass

import httpx
import nltk
import numpy as np
import chromadb
import ollama
from bs4 import BeautifulSoup
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import Integer, Text, JSON, select, DateTime, ARRAY, Float, String, Index, ForeignKey
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, sessionmaker, relationship
from datetime import datetime

# –ó–∞–≥—Ä—É–∑–∫–∞ NLTK –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# –†—É—Å—Å–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
RUSSIAN_STOP_WORDS = set(stopwords.words('russian'))

@dataclass
class SemanticEntity:
    """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—É—â–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ LLM."""
    entity_type: str
    value: str
    confidence: float
    context: str

@dataclass 
class ThematicCluster:
    """–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä —Å—Ç–∞—Ç–µ–π."""
    cluster_id: str
    theme: str
    keywords: List[str]
    articles_count: int
    semantic_density: float

class WebSocketManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞."""
    
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
    
    async def connect(self, websocket: WebSocket, client_id: str):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞."""
        await websocket.accept()
        self.active_connections[client_id] = websocket
        print(f"üîå WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω: {client_id}")
    
    def disconnect(self, client_id: str):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞."""
        if client_id in self.active_connections:
            del self.active_connections[client_id]
            print(f"üîå WebSocket –æ—Ç–∫–ª—é—á–µ–Ω: {client_id}")
    
    async def send_progress(self, client_id: str, message: dict):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∫–ª–∏–µ–Ω—Ç—É."""
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_json(message)
                print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω {client_id}: {message}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ {client_id}: {e}")
    
    async def send_error(self, client_id: str, error: str, details: str = ""):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ—à–∏–±–∫–∏ –∫–ª–∏–µ–Ω—Ç—É."""
        await self.send_progress(client_id, {
            "type": "error",
            "message": error,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })
    
    async def send_step(self, client_id: str, step: str, current: int, total: int, details: str = ""):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–º —à–∞–≥–µ."""
        await self.send_progress(client_id, {
            "type": "progress",
            "step": step,
            "current": current,
            "total": total,
            "percentage": round((current / total) * 100) if total > 0 else 0,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })
    
    async def send_ollama_info(self, client_id: str, info: dict):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–±–æ—Ç–µ Ollama."""
        await self.send_progress(client_id, {
            "type": "ollama",
            "info": info,
            "timestamp": datetime.now().isoformat()
        })


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä WebSocket
websocket_manager = WebSocketManager()

app = FastAPI()

# –î–æ–±–∞–≤–ª—è–µ–º CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class Base(DeclarativeBase):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–µ–π."""


class Domain(Base):
    """–ú–æ–¥–µ–ª—å –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è."""
    
    __tablename__ = "domains"
    
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    name: Mapped[str] = mapped_column(String(255), unique=True, index=True)
    display_name: Mapped[str] = mapped_column(String(500))
    description: Mapped[str] = mapped_column(Text, nullable=True)
    language: Mapped[str] = mapped_column(String(10), default="ru")
    category: Mapped[str] = mapped_column(String(100), nullable=True)
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    updated_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    is_active: Mapped[bool] = mapped_column(default=True)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_posts: Mapped[int] = mapped_column(Integer, default=0)
    total_analyses: Mapped[int] = mapped_column(Integer, default=0)
    last_analysis_at: Mapped[datetime] = mapped_column(DateTime, nullable=True)
    
    # –û—Ç–Ω–æ—à–µ–Ω–∏—è
    posts: Mapped[List["WordPressPost"]] = relationship("WordPressPost", back_populates="domain_ref", cascade="all, delete-orphan")
    analyses: Mapped[List["AnalysisHistory"]] = relationship("AnalysisHistory", back_populates="domain_ref", cascade="all, delete-orphan")
    themes: Mapped[List["ThematicGroup"]] = relationship("ThematicGroup", back_populates="domain_ref", cascade="all, delete-orphan")


class ThematicGroup(Base):
    """–ú–æ–¥–µ–ª—å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä—É–ø–ø —Å—Ç–∞—Ç–µ–π –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏."""
    
    __tablename__ = "thematic_groups"
    
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    domain_id: Mapped[int] = mapped_column(Integer, ForeignKey("domains.id"), index=True)
    name: Mapped[str] = mapped_column(String(200))
    description: Mapped[str] = mapped_column(Text, nullable=True)
    keywords: Mapped[list[str]] = mapped_column(JSON)
    semantic_signature: Mapped[str] = mapped_column(Text)  # TF-IDF –ø–æ–¥–ø–∏—Å—å —Ç–µ–º—ã
    articles_count: Mapped[int] = mapped_column(Integer, default=0)
    avg_semantic_density: Mapped[float] = mapped_column(Float, default=0.0)
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    
    # –û—Ç–Ω–æ—à–µ–Ω–∏—è
    domain_ref: Mapped["Domain"] = relationship("Domain", back_populates="themes")
    posts: Mapped[List["WordPressPost"]] = relationship("WordPressPost", back_populates="thematic_group")
    
    __table_args__ = (
        Index("idx_thematic_groups_domain_semantic", "domain_id", "avg_semantic_density"),
    )


class WordPressPost(Base):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å—Ç–∞—Ç–µ–π WordPress —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–ª—è–º–∏."""

    __tablename__ = "wordpress_posts"

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    domain_id: Mapped[int] = mapped_column(Integer, ForeignKey("domains.id"), index=True)
    thematic_group_id: Mapped[int] = mapped_column(Integer, ForeignKey("thematic_groups.id"), nullable=True, index=True)
    wp_post_id: Mapped[int] = mapped_column(Integer)
    
    # –ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ –ø–æ–ª—è
    title: Mapped[str] = mapped_column(Text)
    content: Mapped[str] = mapped_column(Text)
    excerpt: Mapped[str] = mapped_column(Text, nullable=True)
    link: Mapped[str] = mapped_column(Text, index=True)
    
    # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è –¥–ª—è LLM
    semantic_summary: Mapped[str] = mapped_column(Text, nullable=True)  # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è LLM
    key_concepts: Mapped[list[str]] = mapped_column(JSON, default=list)  # –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
    entity_mentions: Mapped[list[dict]] = mapped_column(JSON, default=list)  # –£–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π
    content_type: Mapped[str] = mapped_column(String(50), nullable=True)  # —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–≥–∞–π–¥, –æ–±–∑–æ—Ä, –Ω–æ–≤–æ—Å—Ç—å)
    difficulty_level: Mapped[str] = mapped_column(String(20), nullable=True)  # —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    target_audience: Mapped[str] = mapped_column(String(100), nullable=True)  # —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è
    
    # –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    content_quality_score: Mapped[float] = mapped_column(Float, default=0.0)
    semantic_richness: Mapped[float] = mapped_column(Float, default=0.0)  # –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —Å–µ–º–∞–Ω—Ç–∏–∫–∏
    linkability_score: Mapped[float] = mapped_column(Float, default=0.0)  # –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ —Å—Ç–∞—Ç—É—Å—ã
    published_at: Mapped[datetime] = mapped_column(DateTime, nullable=True)
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    updated_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    last_analyzed_at: Mapped[datetime] = mapped_column(DateTime, nullable=True)
    
    # –û—Ç–Ω–æ—à–µ–Ω–∏—è
    domain_ref: Mapped["Domain"] = relationship("Domain", back_populates="posts")
    thematic_group: Mapped["ThematicGroup"] = relationship("ThematicGroup", back_populates="posts")
    embeddings: Mapped[List["ArticleEmbedding"]] = relationship("ArticleEmbedding", back_populates="post", cascade="all, delete-orphan")
    
    __table_args__ = (
        Index("idx_wp_posts_domain_theme", "domain_id", "thematic_group_id"),
        Index("idx_wp_posts_semantic_scores", "semantic_richness", "linkability_score"),
        Index("idx_wp_posts_published", "published_at"),
    )


class ArticleEmbedding(Base):
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏."""

    __tablename__ = "article_embeddings"

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    post_id: Mapped[int] = mapped_column(Integer, ForeignKey("wordpress_posts.id"), index=True)
    
    # –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embedding_type: Mapped[str] = mapped_column(String(50))  # 'title', 'content', 'summary', 'full'
    vector_model: Mapped[str] = mapped_column(String(100))  # –º–æ–¥–µ–ª—å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    embedding_vector: Mapped[str] = mapped_column(Text)  # JSON –≤–µ–∫—Ç–æ—Ä–∞
    dimension: Mapped[int] = mapped_column(Integer)  # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    context_window: Mapped[int] = mapped_column(Integer, nullable=True)  # —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞
    preprocessing_info: Mapped[dict] = mapped_column(JSON, default=dict)  # –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ
    quality_metrics: Mapped[dict] = mapped_column(JSON, default=dict)  # –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    
    # –û—Ç–Ω–æ—à–µ–Ω–∏—è
    post: Mapped["WordPressPost"] = relationship("WordPressPost", back_populates="embeddings")
    
    __table_args__ = (
        Index("idx_embeddings_post_type", "post_id", "embedding_type"),
    )


class SemanticConnection(Base):
    """–ú–æ–¥–µ–ª—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏."""
    
    __tablename__ = "semantic_connections"
    
    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    source_post_id: Mapped[int] = mapped_column(Integer, ForeignKey("wordpress_posts.id"), index=True)
    target_post_id: Mapped[int] = mapped_column(Integer, ForeignKey("wordpress_posts.id"), index=True)
    
    # –¢–∏–ø—ã —Å–≤—è–∑–µ–π
    connection_type: Mapped[str] = mapped_column(String(50))  # 'semantic', 'topical', 'hierarchical'
    strength: Mapped[float] = mapped_column(Float)  # —Å–∏–ª–∞ —Å–≤—è–∑–∏ (0.0 - 1.0)
    confidence: Mapped[float] = mapped_column(Float)  # —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–≤—è–∑–∏
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
    connection_context: Mapped[str] = mapped_column(Text, nullable=True)  # –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å–≤—è–∑–∏
    suggested_anchor: Mapped[str] = mapped_column(String(200), nullable=True)  # –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π –∞–Ω–∫–æ—Ä
    bidirectional: Mapped[bool] = mapped_column(default=False)  # –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Å–≤—è–∑—å
    
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    validated_at: Mapped[datetime] = mapped_column(DateTime, nullable=True)
    
    __table_args__ = (
        Index("idx_semantic_connections_strength", "strength"),
        Index("idx_semantic_connections_source_type", "source_post_id", "connection_type"),
    )


class AnalysisHistory(Base):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∏—Å—Ç–æ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏."""

    __tablename__ = "analysis_history"

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    domain_id: Mapped[int] = mapped_column(Integer, ForeignKey("domains.id"), index=True)
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    posts_analyzed: Mapped[int] = mapped_column(Integer)
    connections_found: Mapped[int] = mapped_column(Integer)
    recommendations_generated: Mapped[int] = mapped_column(Integer)
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    recommendations: Mapped[list[dict]] = mapped_column(JSON)
    thematic_analysis: Mapped[dict] = mapped_column(JSON, default=dict)  # –∞–Ω–∞–ª–∏–∑ —Ç–µ–º–∞—Ç–∏–∫
    semantic_metrics: Mapped[dict] = mapped_column(JSON, default=dict)  # —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    quality_assessment: Mapped[dict] = mapped_column(JSON, default=dict)  # –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    
    # LLM –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    llm_model_used: Mapped[str] = mapped_column(String(100))
    llm_context_size: Mapped[int] = mapped_column(Integer, nullable=True)
    processing_time_seconds: Mapped[float] = mapped_column(Float, nullable=True)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    completed_at: Mapped[datetime] = mapped_column(DateTime, nullable=True)
    
    # –û—Ç–Ω–æ—à–µ–Ω–∏—è
    domain_ref: Mapped["Domain"] = relationship("Domain", back_populates="analyses")
    
    __table_args__ = (
        Index("idx_analysis_history_domain_date", "domain_id", "created_at"),
    )


class Recommendation(Base):
    """–ú–æ–¥–µ–ª—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)."""

    __tablename__ = "recommendations"

    id: Mapped[int] = mapped_column(Integer, primary_key=True)
    text: Mapped[str] = mapped_column(Text)
    links: Mapped[list[str]] = mapped_column(JSON)


class RecommendRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å —Å —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Å—ã–ª–æ–∫."""

    text: str


class WPRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ WordPress-—Å–∞–π—Ç–∞."""

    domain: str
    client_id: Optional[str] = None
    comprehensive: Optional[bool] = False  # –§–ª–∞–≥ –¥–ª—è –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏


OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
# –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è SEO –∑–∞–¥–∞—á: qwen2.5:7b - –æ—Ç–ª–∏—á–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞/—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏/—Ä–µ—Å—É—Ä—Å–æ–≤
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5:7b")

DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql+asyncpg://seo_user:seo_pass@localhost/seo_db",
)

engine = create_async_engine(DATABASE_URL)
AsyncSessionLocal = sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG-—Å–∏—Å—Ç–µ–º—ã
chroma_client = None
tfidf_vectorizer = None

def initialize_rag_system():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é RAG-—Å–∏—Å—Ç–µ–º—É —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º."""
    global chroma_client, tfidf_vectorizer
    try:
        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π RAG-—Å–∏—Å—Ç–µ–º—ã...")
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        tfidf_vectorizer = TfidfVectorizer(
            max_features=2000,  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            ngram_range=(1, 3),  # –¥–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∏–≥—Ä–∞–º–º—ã
            min_df=1,
            max_df=0.85,
            stop_words=list(RUSSIAN_STOP_WORDS),  # —Ä—É—Å—Å–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            analyzer='word',
            lowercase=True,
            token_pattern=r'\b[–∞-—è—ë]{2,}\b|\b[a-z]{2,}\b'  # —Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        chroma_client = chromadb.PersistentClient(
            path="./chroma_db",
            settings=chromadb.Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        print("‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è RAG-—Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG: {e}")
        chroma_client = None
        tfidf_vectorizer = None


class AdvancedRAGManager:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π RAG-–º–µ–Ω–µ–¥–∂–µ—Ä —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º."""
    
    def __init__(self):
        self.domain_collections = {}
        self.thematic_clusters = {}
        self.semantic_cache = {}
    
    async def create_semantic_knowledge_base(
        self, 
        domain: str, 
        posts: List[Dict],
        client_id: Optional[str] = None
    ) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π —Å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–µ–π."""
        if not chroma_client:
            print("‚ùå RAG-—Å–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return False
            
        try:
            if client_id:
                await websocket_manager.send_step(client_id, "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑", 1, 5, "–ê–Ω–∞–ª–∏–∑ —Ç–µ–º–∞—Ç–∏–∫ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π...")
            
            print(f"üß† –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è {domain}...")
            
            # –û—á–∏—â–∞–µ–º –∏–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_name = domain.replace(".", "_").replace("-", "_")
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
            try:
                chroma_client.delete_collection(name=collection_name)
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è {collection_name}")
            except:
                pass
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            collection = chroma_client.create_collection(
                name=collection_name,
                metadata={
                    "domain": domain,
                    "created_at": datetime.now().isoformat(),
                    "rag_version": "2.0",
                    "semantic_analysis": True
                }
            )
            
            if client_id:
                await websocket_manager.send_step(client_id, "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", 2, 5, "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π...")
            
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π
            enriched_posts = await self._enrich_posts_with_semantics(posts, domain)
            
            if client_id:
                await websocket_manager.send_step(client_id, "–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è", 3, 5, "–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤...")
            
            documents = []
            metadatas = []
            ids = []
            
            for i, post in enumerate(enriched_posts):
                # –°–æ–∑–¥–∞–µ–º –±–æ–≥–∞—Ç—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
                semantic_text = self._create_llm_friendly_context(post)
                
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ - —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, —á–∏—Å–ª–∞ –∏ –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è
                key_concepts = post.get('key_concepts', [])
                key_concepts_str = ', '.join(key_concepts[:5]) if key_concepts else ""  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                
                documents.append(semantic_text)
                metadatas.append({
                    "title": (post.get('title', '') or '')[:300],  # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É
                    "link": post.get('link', '') or '',
                    "content_snippet": (post.get('content', '') or '')[:500],
                    "domain": domain,
                    "post_index": i,
                    "semantic_summary": (post.get('semantic_summary', '') or '')[:500],
                    "key_concepts_str": key_concepts_str,  # –°—Ç—Ä–æ–∫–∞ –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞
                    "key_concepts_count": len(key_concepts),  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∫ —á–∏—Å–ª–æ
                    "content_type": post.get('content_type', 'article'),
                    "difficulty_level": post.get('difficulty_level', 'medium'),
                    "linkability_score": float(post.get('linkability_score', 0.5))  # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —ç—Ç–æ float
                })
                ids.append(f"{collection_name}_{i}")
            
            if not documents:
                print(f"‚ùå –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ {domain}")
                return False
            
            if client_id:
                await websocket_manager.send_step(client_id, "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è", 4, 5, "–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º...")
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã
            vectorizer = TfidfVectorizer(
                max_features=1000,
                ngram_range=(1, 3),
                min_df=1,
                max_df=0.8,
                stop_words=list(RUSSIAN_STOP_WORDS),
                analyzer='word'
            )
            
            tfidf_matrix = vectorizer.fit_transform(documents)
            dense_embeddings = tfidf_matrix.toarray().tolist()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids,
                embeddings=dense_embeddings
            )
            
            if client_id:
                await websocket_manager.send_step(client_id, "–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è", 5, 5, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏...")
            
            self.domain_collections[domain] = collection_name
            
            print(f"üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–∞: {len(documents)} —Å—Ç–∞—Ç–µ–π –¥–ª—è {domain}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã: {e}")
            return False
    
    async def _enrich_posts_with_semantics(self, posts: List[Dict], domain: str) -> List[Dict]:
        """–û–±–æ–≥–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
        enriched = []
        
        for post in posts:
            try:
                title = post.get('title', '')
                content = post.get('content', '')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
                key_concepts = self._extract_key_concepts(title + ' ' + content)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                content_type = self._classify_content_type(title, content)
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
                difficulty = self._assess_difficulty(content)
                
                # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
                linkability = self._calculate_linkability_score(title, content, key_concepts)
                
                # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑—é–º–µ
                semantic_summary = self._create_semantic_summary(title, content, key_concepts)
                
                enriched_post = {
                    **post,
                    'key_concepts': key_concepts,
                    'content_type': content_type,
                    'difficulty_level': difficulty,
                    'linkability_score': linkability,
                    'semantic_summary': semantic_summary
                }
                
                enriched.append(enriched_post)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ {post.get('title', 'unknown')}: {e}")
                enriched.append(post)  # –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        
        return enriched
    
    def _extract_key_concepts(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏
        words = word_tokenize(text.lower())
        words = [w for w in words if w.isalpha() and len(w) > 3 and w not in RUSSIAN_STOP_WORDS]
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-10 –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        return sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True)[:10]
    
    def _classify_content_type(self, title: str, content: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
        title_lower = title.lower()
        content_lower = content.lower()
        
        # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if any(word in title_lower for word in ['–∫–∞–∫', '–≥–∞–π–¥', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è']):
            return 'guide'
        elif any(word in title_lower for word in ['–æ–±–∑–æ—Ä', '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ', '—Ç–µ—Å—Ç']):
            return 'review'
        elif any(word in title_lower for word in ['–Ω–æ–≤–æ—Å—Ç–∏', '–∞–Ω–æ–Ω—Å', '—Ä–µ–ª–∏–∑']):
            return 'news'
        elif len(content) < 1000:
            return 'short_article'
        else:
            return 'article'
    
    def _assess_difficulty(self, content: str) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
        words = word_tokenize(content)
        avg_word_length = sum(len(w) for w in words) / len(words) if words else 0
        
        if avg_word_length < 5:
            return 'easy'
        elif avg_word_length < 7:
            return 'medium'
        else:
            return 'advanced'
    
    def _calculate_linkability_score(self, title: str, content: str, concepts: List[str]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫."""
        score = 0.0
        
        # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        score += min(len(content) / 2000, 0.4)  # –¥–æ 0.4 –∑–∞ –¥–ª–∏–Ω—É
        
        # –°–∫–æ—Ä –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        score += min(len(concepts) / 20, 0.3)  # –¥–æ 0.3 –∑–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        
        # –°–∫–æ—Ä –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        if any(word in title.lower() for word in ['–∫–∞–∫', '—á—Ç–æ', '–≥–¥–µ', '–ø–æ—á–µ–º—É']):
            score += 0.2
            
        # –°–∫–æ—Ä –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        if content.count('.') > 5:  # –º–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            score += 0.1
            
        return min(score, 1.0)
    
    def _create_semantic_summary(self, title: str, content: str, concepts: List[str]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–ª—è LLM."""
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        sentences = content.split('.')[:3]
        summary = '. '.join(sentences).strip()
        
        if concepts:
            summary += f" –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã: {', '.join(concepts[:5])}."
            
        return summary[:500]  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    
    def _create_llm_friendly_context(self, post: Dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç LLM-–¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏."""
        title = post.get('title', '')
        summary = post.get('semantic_summary', '')
        concepts = post.get('key_concepts', [])
        content_type = post.get('content_type', 'article')
        difficulty = post.get('difficulty_level', 'medium')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
        context_parts = [
            f"–ó–ê–ì–û–õ–û–í–û–ö: {title}",
            f"–¢–ò–ü: {content_type}",
            f"–°–õ–û–ñ–ù–û–°–¢–¨: {difficulty}",
            f"–û–ü–ò–°–ê–ù–ò–ï: {summary}"
        ]
        
        if concepts:
            context_parts.append(f"–ö–õ–Æ–ß–ï–í–´–ï_–¢–ï–ú–´: {', '.join(concepts[:7])}")
        
        return ' | '.join(context_parts)
    
    async def get_semantic_recommendations(
        self,
        domain: str,
        limit: int = 25,
        min_linkability: float = 0.2  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
        if domain not in self.domain_collections:
            return []
        
        try:
            collection = chroma_client.get_collection(name=self.domain_collections[domain])
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            results = collection.get(
                limit=limit * 2,  # –±–µ—Ä–µ–º –±–æ–ª—å—à–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                include=['metadatas', 'documents']
            )
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É —Å–æ–∑–¥–∞–Ω–∏—è —Å—Å—ã–ª–æ–∫
            filtered_articles = []
            for i, metadata in enumerate(results['metadatas']):
                linkability_score = metadata.get('linkability_score', 0.0)
                if linkability_score >= min_linkability:
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º key_concepts –∏–∑ —Å—Ç—Ä–æ–∫–∏
                    key_concepts_str = metadata.get('key_concepts_str', '')
                    key_concepts = [kc.strip() for kc in key_concepts_str.split(',') if kc.strip()] if key_concepts_str else []
                    
                    filtered_articles.append({
                        'title': metadata['title'],
                        'link': metadata['link'],
                        'content': metadata.get('content_snippet', ''),
                        'semantic_summary': metadata.get('semantic_summary', ''),
                        'key_concepts': key_concepts,
                        'content_type': metadata.get('content_type', 'article'),
                        'difficulty_level': metadata.get('difficulty_level', 'medium'),
                        'linkability_score': linkability_score,
                        'domain': metadata['domain']
                    })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É —Å–æ–∑–¥–∞–Ω–∏—è —Å—Å—ã–ª–æ–∫
            filtered_articles.sort(key=lambda x: x['linkability_score'], reverse=True)
            
            print(f"üéØ –ü–æ–ª—É—á–µ–Ω–æ {len(filtered_articles)} —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
            return filtered_articles[:limit]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return []


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π RAG-–º–µ–Ω–µ–¥–∂–µ—Ä
rag_manager = AdvancedRAGManager()


async def generate_links(text: str) -> list[str]:
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç—ã—Ö —Å—Å—ã–ª–æ–∫."""
    prompt = (
        "–ü—Ä–µ–¥–ª–æ–∂–∏ –¥–æ –ø—è—Ç–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
        "–ö–∞–∂–¥—É—é —Å—Å—ã–ª–∫—É –≤—ã–≤–µ–¥–∏ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ /article/–Ω–∞–∑–≤–∞–Ω–∏–µ-—Å—Ç–∞—Ç—å–∏, "
        "–æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞. "
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏–ª–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è. "
        f"–¢–µ–∫—Å—Ç: {text}"
    )
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(
            OLLAMA_URL,
            json={"model": OLLAMA_MODEL, "prompt": prompt, "stream": False},
            timeout=60,
        )
    response.raise_for_status()
    data = response.json()
    lines = [line.strip("- \n") for line in data.get("response", "").splitlines()]
    links = [line for line in lines if line]
    return links[:5]


async def fetch_and_store_wp_posts(domain: str) -> list[dict[str, str]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç—å–∏ WordPress –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —É–ª—É—á—à–µ–Ω–Ω–æ–π –ë–î —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º."""
    print(f"üåê –ó–∞–≥—Ä—É–∂–∞—é –ø–æ—Å—Ç—ã —Å —Å–∞–π—Ç–∞ {domain}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –¥–æ–º–µ–Ω
    async with AsyncSessionLocal() as session:
        # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–æ–º–µ–Ω
        result = await session.execute(
            select(Domain).where(Domain.name == domain)
        )
        domain_obj = result.scalar_one_or_none()
        
        if not domain_obj:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–º–µ–Ω
            domain_obj = Domain(
                name=domain,
                display_name=domain,
                description=f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–æ–º–µ–Ω –¥–ª—è {domain}",
                language="ru"
            )
            session.add(domain_obj)
            await session.commit()
            await session.refresh(domain_obj)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –¥–æ–º–µ–Ω: {domain}")
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ø–æ—Å—Ç—ã —ç—Ç–æ–≥–æ –¥–æ–º–µ–Ω–∞
        await session.execute(
            select(WordPressPost).where(WordPressPost.domain_id == domain_obj.id)
        )
        await session.commit()
    
    url = f"https://{domain}/wp-json/wp/v2/posts?per_page=50"  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 50 –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    async with httpx.AsyncClient(timeout=120.0) as client:
        response = await client.get(url)
    if response.status_code >= 400:
        raise HTTPException(status_code=400, detail="–°–∞–π—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –Ω–µ WordPress")
    data = response.json()
    if not isinstance(data, list):
        raise HTTPException(status_code=400, detail="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç WordPress")
    
    posts = []
    seen_urls = set()  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ URL
    seen_titles = set()  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
    
    async with AsyncSessionLocal() as session:
        for item in data:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                content = item.get("content", {}).get("rendered", "")
                excerpt = item.get("excerpt", {}).get("rendered", "")
                
                # –û—á–∏—â–∞–µ–º HTML
                clean_content = BeautifulSoup(content, 'html.parser').get_text()
                clean_excerpt = BeautifulSoup(excerpt, 'html.parser').get_text() if excerpt else ""
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Å—ã–ª–∫–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –Ω–∞—à–µ–º—É –¥–æ–º–µ–Ω—É
                post_link = item["link"]
                if domain.lower() not in post_link.lower():
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Å—Ç–∞—Ç—å—é —Å —á—É–∂–æ–≥–æ –¥–æ–º–µ–Ω–∞: {post_link}")
                    continue
                
                # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
                if post_link in seen_urls:
                    print(f"‚ö†Ô∏è –î—É–±–ª–∏–∫–∞—Ç URL –ø—Ä–æ–ø—É—â–µ–Ω: {post_link}")
                    continue
                seen_urls.add(post_link)
                
                # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
                title = item["title"]["rendered"]
                title_normalized = title.lower().strip()
                if title_normalized in seen_titles:
                    print(f"‚ö†Ô∏è –î—É–±–ª–∏–∫–∞—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω: {title}")
                    continue
                seen_titles.add(title_normalized)
                
                # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –ø–æ—Å—Ç
                wp_post = WordPressPost(
                    domain_id=domain_obj.id,
                    wp_post_id=item["id"],
                    title=title,
                    content=clean_content,
                    excerpt=clean_excerpt,
                    link=post_link,
                    published_at=datetime.fromisoformat(item.get("date", datetime.now().isoformat()).replace('Z', '+00:00')) if item.get("date") else None,
                    last_analyzed_at=datetime.utcnow()
                )
                session.add(wp_post)
                
                # –î–ª—è RAG –±–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                posts.append({
                    "title": title, 
                    "link": post_link,
                    "content": clean_content[:800].strip()  # –ü–µ—Ä–≤—ã–µ 800 —Å–∏–º–≤–æ–ª–æ–≤
                })
                
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç: {title}")
                
            except Exception as exc:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ {item.get('id', 'unknown')}: {exc}")
                continue
        
        await session.commit()
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(posts)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –¥–æ–º–µ–Ω–∞ {domain}")
    
    return posts


async def generate_comprehensive_domain_recommendations(domain: str, client_id: Optional[str] = None) -> list[dict[str, str]]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–æ–º–µ–Ω–∞."""
    print(f"üîç –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–º–µ–Ω–∞ {domain} (client: {client_id})")
    
    analysis_start_time = datetime.now()
    all_recommendations = []
    
    try:
        # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï —Å—Ç–∞—Ç—å–∏ –¥–æ–º–µ–Ω–∞ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        if client_id:
            await websocket_manager.send_step(client_id, "–ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è", 1, 9, "–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –¥–æ–º–µ–Ω–∞...")
        
        async with AsyncSessionLocal() as session:
            domain_result = await session.execute(
                select(Domain).where(Domain.name == domain)
            )
            domain_obj = domain_result.scalar_one_or_none()
            
            if not domain_obj:
                error_msg = f"‚ùå –î–æ–º–µ–Ω {domain} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î"
                print(error_msg)
                if client_id:
                    await websocket_manager.send_error(client_id, error_msg)
                return [], 0.0
            
            # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –ø–æ—Å—Ç—ã —Å –ø–æ–ª–Ω–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            result = await session.execute(
                select(WordPressPost)
                .where(WordPressPost.domain_id == domain_obj.id)
                .order_by(WordPressPost.linkability_score.desc())
                # –ù–ï –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º - –±–µ—Ä–µ–º –≤—Å–µ!
            )
            all_posts = result.scalars().all()
        
        if not all_posts:
            error_msg = "‚ùå –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"
            print(error_msg)
            if client_id:
                await websocket_manager.send_error(client_id, error_msg)
            return [], 0.0
        
        print(f"üìä –ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è: {len(all_posts)} —Å—Ç–∞—Ç–µ–π –∏–∑ –ë–î")
        
        # –®–∞–≥ 2: –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å—Ç–∞—Ç–µ–π
        if client_id:
            await websocket_manager.send_step(client_id, "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞", 2, 9, f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(all_posts)} —Å—Ç–∞—Ç–µ–π...")
        
        full_dataset = []
        for post in all_posts:
            full_dataset.append({
                "id": post.id,
                "title": post.title,
                "link": post.link,
                "content": post.content,
                "semantic_summary": post.semantic_summary or "",
                "key_concepts": post.key_concepts or [],
                "content_type": post.content_type or "article",
                "difficulty_level": post.difficulty_level or "medium",
                "linkability_score": post.linkability_score or 0.5,
                "semantic_richness": post.semantic_richness or 0.5
            })
        
        # –®–∞–≥ 3: –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –≤—Å–µ–≥–æ –¥–æ–º–µ–Ω–∞
        if client_id:
            await websocket_manager.send_step(client_id, "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑", 3, 9, "–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏...")
        
        success = await rag_manager.create_semantic_knowledge_base(domain, full_dataset, client_id)
        if not success:
            error_msg = "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"
            print(error_msg)
            if client_id:
                await websocket_manager.send_error(client_id, error_msg)
            return [], 0.0
        
        # –®–∞–≥ 4: –ë–∞—Ç—á–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        if client_id:
            await websocket_manager.send_step(client_id, "–ë–∞—Ç—á–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π", 4, 9, "–†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –≥—Ä—É–ø–ø—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
        
        batch_size = 4  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        batches = []
        for i in range(0, len(full_dataset), batch_size):
            batch = full_dataset[i:i+batch_size]
            batches.append(batch)
        
        print(f"üì¶ –°–æ–∑–¥–∞–Ω–æ {len(batches)} –±–∞—Ç—á–µ–π –ø–æ {batch_size} —Å—Ç–∞—Ç–µ–π")
        
        # –®–∞–≥ 5-7: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –±–∞—Ç—á —á–µ—Ä–µ–∑ Ollama —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        for batch_idx, batch in enumerate(batches, 1):
            if client_id:
                await websocket_manager.send_step(
                    client_id, 
                    f"–ê–Ω–∞–ª–∏–∑ –±–∞—Ç—á–∞ {batch_idx}/{len(batches)}", 
                    4 + batch_idx, 
                    9, 
                    f"–ê–Ω–∞–ª–∏–∑ {len(batch)} —Å—Ç–∞—Ç–µ–π (–ø–æ–ø—ã—Ç–∫–∞ 1/3)..."
                )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
            batch_recommendations = []
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    batch_recommendations = await process_batch_with_ollama(
                        domain, batch, full_dataset, batch_idx, len(batches), client_id
                    )
                    
                    if batch_recommendations:  # –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–∏–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                        break
                    else:
                        print(f"‚ö†Ô∏è –ë–∞—Ç—á {batch_idx}: –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}")
                        
                except Exception as e:
                    print(f"‚ùå –ë–∞—Ç—á {batch_idx}: –æ—à–∏–±–∫–∞ –≤ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}/{max_retries}: {e}")
                    
                    if attempt < max_retries - 1:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                        if client_id:
                            await websocket_manager.send_step(
                                client_id, 
                                f"–ü–æ–≤—Ç–æ—Ä –±–∞—Ç—á–∞ {batch_idx}/{len(batches)}", 
                                4 + batch_idx, 
                                9, 
                                f"–ü–æ–≤—Ç–æ—Ä –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 2}/3)..."
                            )
                        await asyncio.sleep(10)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                    else:
                        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω–∞ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—É—Å—Ç—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
                        print(f"‚ùå –ë–∞—Ç—á {batch_idx}: –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        if client_id:
                            await websocket_manager.send_progress(client_id, {
                                "type": "warning",
                                "message": f"–ë–∞—Ç—á {batch_idx} –ø—Ä–æ–ø—É—â–µ–Ω",
                                "details": f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫"
                            })
            
            all_recommendations.extend(batch_recommendations)
            print(f"‚úÖ –ë–∞—Ç—á {batch_idx}: –ø–æ–ª—É—á–µ–Ω–æ {len(batch_recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        
        # –®–∞–≥ 8: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
        if client_id:
            await websocket_manager.send_step(client_id, "–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", 8, 9, "–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ...")
        
        final_recommendations = deduplicate_and_rank_recommendations(all_recommendations, domain)
        
        # –®–∞–≥ 9: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        total_analysis_time = (datetime.now() - analysis_start_time).total_seconds()
        
        if client_id:
            await websocket_manager.send_step(
                client_id, 
                "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", 
                9, 
                9, 
                f"–ì–æ—Ç–æ–≤–æ! {len(final_recommendations)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
            )
        
        print(f"üéØ –ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(final_recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞ {total_analysis_time:.1f}—Å")
        return final_recommendations, total_analysis_time
        
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}"
        print(error_msg)
        if client_id:
            await websocket_manager.send_error(client_id, "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", str(e))
        
        error_time = (datetime.now() - analysis_start_time).total_seconds()
        return [], error_time


async def process_batch_with_ollama(
    domain: str, 
    batch: List[Dict], 
    full_dataset: List[Dict], 
    batch_idx: int, 
    total_batches: int,
    client_id: Optional[str] = None
) -> List[Dict]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á —Å—Ç–∞—Ç–µ–π —á–µ—Ä–µ–∑ Ollama —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º."""
    
    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –±–∞—Ç—á–∞
    batch_context = f"""–ê–ù–ê–õ–ò–ó –ë–ê–¢–ß–ê {batch_idx}/{total_batches} –î–û–ú–ï–ù–ê {domain}

–°–¢–ê–¢–¨–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê ({len(batch)}):
"""
    
    for i, article in enumerate(batch, 1):
        key_concepts_str = ', '.join(article['key_concepts'][:4]) if article['key_concepts'] else '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã'
        
        batch_context += f"""
{i}. {article['title']}
   URL: {article['link']}
   –¢–∏–ø: {article['content_type']} | –°–≤—è–∑–Ω–æ—Å—Ç—å: {article['linkability_score']:.2f}
   –ö–æ–Ω—Ü–µ–ø—Ü–∏–∏: {key_concepts_str}
   –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {article['semantic_summary'][:150]}
   –ö–æ–Ω—Ç–µ–Ω—Ç: {article['content'][:200]}...

"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥—Ä—É–≥–∏—Ö —Å—Ç–∞—Ç–µ–π
    batch_context += f"""–î–û–°–¢–£–ü–ù–´–ï –¶–ï–õ–ò ({len(full_dataset)} —Å—Ç–∞—Ç–µ–π):
"""
    
    targets_added = 0
    for article in full_dataset[:15]:  # –¢–æ–ø-15 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        if article not in batch and targets_added < 10:  # –ú–∞–∫—Å–∏–º—É–º 10 —Ü–µ–ª–µ–π
            batch_context += f"‚Ä¢ {article['title'][:50]} | {article['link'][:60]}\n"
            targets_added += 1
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    comprehensive_prompt = f"""{batch_context}

–ó–ê–î–ê–ß–ê: –ù–∞–π–¥–∏ –ª–æ–≥–∏—á–Ω—ã–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏

–ö–†–ò–¢–ï–†–ò–ò:
‚Ä¢ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–≤—è–∑—å
‚Ä¢ –ü–æ–ª—å–∑–∞ –¥–ª—è —á–∏—Ç–∞—Ç–µ–ª—è  
‚Ä¢ SEO-—Ü–µ–Ω–Ω–æ—Å—Ç—å

–ü–†–ê–í–ò–õ–ê –∞–Ω–∫–æ—Ä–æ–≤:
‚Ä¢ –û–ø–∏—Å—ã–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
‚Ä¢ –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: "—Å–∞–π—Ç", "—Ä–µ—Å—É—Ä—Å", "–ø–æ—Ä—Ç–∞–ª"
‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã: "–ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", "–ø–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä"

–ù–∞–π–¥–∏ –í–°–ï –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ –¥–ª—è —Å—Ç–∞—Ç–µ–π —ç—Ç–æ–≥–æ –±–∞—Ç—á–∞.

–§–û–†–ú–ê–¢: –ò–°–¢–û–ß–ù–ò–ö -> –¶–ï–õ–¨ | –∞–Ω–∫–æ—Ä | –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ

–û–¢–í–ï–¢:"""
    
    try:
        if client_id:
            await websocket_manager.send_ollama_info(client_id, {
                "status": "processing_batch",
                "batch": f"{batch_idx}/{total_batches}",
                "articles_in_batch": len(batch),
                "total_context_size": len(comprehensive_prompt),
                "model": OLLAMA_MODEL
            })
        
        print(f"ü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á {batch_idx} —á–µ—Ä–µ–∑ Ollama (—Ä–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞: {len(comprehensive_prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        start_time = datetime.now()
        async with httpx.AsyncClient(timeout=300.0) as client:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º-–∞—É—Ç –¥–æ 5 –º–∏–Ω—É—Ç
            response = await client.post(
                OLLAMA_URL,
                json={
                    "model": OLLAMA_MODEL,
                    "prompt": comprehensive_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,    # –ù–µ–º–Ω–æ–≥–æ –ø–æ–≤—ã—à–∞–µ–º –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
                        "num_ctx": 4096,       # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                        "num_predict": 800,    # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
                        "top_p": 0.8,
                        "top_k": 40,
                        "repeat_penalty": 1.05,
                        "num_thread": 6        # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
                    }
                },
                timeout=300  # 5 –º–∏–Ω—É—Ç –Ω–∞ –±–∞—Ç—á
            )
        
        request_time = (datetime.now() - start_time).total_seconds()
        
        if client_id:
            await websocket_manager.send_ollama_info(client_id, {
                "status": "batch_completed",
                "batch": f"{batch_idx}/{total_batches}",
                "processing_time": f"{request_time:.1f}s",
                "response_length": len(response.text) if response.status_code == 200 else 0
            })
        
        if response.status_code != 200:
            print(f"‚ùå Ollama –æ—à–∏–±–∫–∞ –¥–ª—è –±–∞—Ç—á–∞ {batch_idx}: –∫–æ–¥ {response.status_code}")
            return []
        
        data = response.json()
        content = data.get("response", "")
        
        print(f"üìù –ë–∞—Ç—á {batch_idx}: –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç {len(content)} —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ {request_time:.1f}—Å")
        
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —ç—Ç–æ–≥–æ –±–∞—Ç—á–∞
        batch_recommendations = parse_ollama_recommendations(content, domain, full_dataset)
        
        return batch_recommendations
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞ {batch_idx}: {e}")
        return []


def deduplicate_and_rank_recommendations(recommendations: List[Dict], domain: str) -> List[Dict]:
    """–î–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç –∏ —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."""
    
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –ø–∞—Ä–µ –∏—Å—Ç–æ—á–Ω–∏–∫->—Ü–µ–ª—å
    seen_pairs = set()
    unique_recommendations = []
    
    for rec in recommendations:
        pair_key = (rec['from'], rec['to'])
        if pair_key not in seen_pairs:
            seen_pairs.add(pair_key)
            unique_recommendations.append(rec)
    
    # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∞–Ω–∫–æ—Ä–∞ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
    def quality_score(rec):
        anchor_score = len(rec['anchor']) * 0.1  # –î–ª–∏–Ω–∞ –∞–Ω–∫–æ—Ä–∞
        comment_score = len(rec['comment']) * 0.05  # –î–ª–∏–Ω–∞ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –≤ –∞–Ω–∫–æ—Ä–µ
        quality_words = ['–ø–æ–¥—Ä–æ–±–Ω—ã–π', '–ø–æ–ª–Ω—ã–π', '–¥–µ—Ç–∞–ª—å–Ω—ã–π', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', '–æ–±–∑–æ—Ä', '–≥–∞–π–¥']
        anchor_quality = sum(1 for word in quality_words if word in rec['anchor'].lower()) * 2
        
        return anchor_score + comment_score + anchor_quality
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
    ranked_recommendations = sorted(unique_recommendations, key=quality_score, reverse=True)
    
    print(f"üéØ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: {len(recommendations)} -> {len(unique_recommendations)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
    
    return ranked_recommendations[:50]  # –¢–æ–ø-50 —Å–∞–º—ã—Ö –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö


async def generate_rag_recommendations(domain: str, client_id: Optional[str] = None) -> list[dict[str, str]]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—è RAG-–ø–æ–¥—Ö–æ–¥ —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î."""
    print(f"üöÄ –ó–∞–ø—É—Å–∫ RAG-–∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain} (client: {client_id})")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞
    analysis_start_time = datetime.now()
    request_time = 0.0
    
    try:
        # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ –ë–î
        if client_id:
            await websocket_manager.send_step(client_id, "–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π", 1, 7, "–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        async with AsyncSessionLocal() as session:
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω
            domain_result = await session.execute(
                select(Domain).where(Domain.name == domain)
            )
            domain_obj = domain_result.scalar_one_or_none()
            
            if not domain_obj:
                error_msg = f"‚ùå –î–æ–º–µ–Ω {domain} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î"
                print(error_msg)
                if client_id:
                    await websocket_manager.send_error(client_id, error_msg)
                return [], 0.0
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            result = await session.execute(
                select(WordPressPost)
                .where(WordPressPost.domain_id == domain_obj.id)
                .order_by(WordPressPost.linkability_score.desc(), WordPressPost.published_at.desc())
                .limit(100)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            )
            db_posts = result.scalars().all()
        
        if not db_posts:
            error_msg = "‚ùå –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è RAG-–∞–Ω–∞–ª–∏–∑–∞"
            print(error_msg)
            if client_id:
                await websocket_manager.send_error(client_id, error_msg, f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}")
            return [], 0.0
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(db_posts)} —Å—Ç–∞—Ç–µ–π –∏–∑ –ë–î")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è RAG
        posts_data = []
        for post in db_posts:
            posts_data.append({
                "title": post.title,
                "link": post.link,
                "content": post.content[:1000]  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
            })
        
        # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã
        if client_id:
            await websocket_manager.send_step(client_id, "–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã", 2, 7, "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
        
        success = await rag_manager.create_semantic_knowledge_base(domain, posts_data, client_id)
        if not success:
            error_msg = "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"
            print(error_msg)
            if client_id:
                await websocket_manager.send_error(client_id, error_msg, "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤")
            return [], 0.0
        
        # –®–∞–≥ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±–∑–æ—Ä–∞ —Å—Ç–∞—Ç–µ–π
        if client_id:
            await websocket_manager.send_step(client_id, "–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞", 3, 7, "–í—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π...")
        
        articles = await rag_manager.get_semantic_recommendations(domain, limit=12)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        if not articles:
            error_msg = "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–∞—Ç—å–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"
            print(error_msg)
            if client_id:
                await websocket_manager.send_error(client_id, error_msg, "–ü—É—Å—Ç–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")
            return [], 0.0
        
        print(f"üìã –í—ã–±—Ä–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        if client_id:
            await websocket_manager.send_step(client_id, "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ò–ò", 4, 7, "–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è Ollama...")
        
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∏ –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        articles_context = ""
        for i, article in enumerate(articles, 1):
            title = article['title'][:80]
            content_snippet = article['content'][:200] if article.get('content') else ""  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å–Ω–∏–ø–ø–µ—Ç
            key_concepts = article.get('key_concepts', [])[:5]  # –¢–æ–ø-5 –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
            content_type = article.get('content_type', 'article')
            linkability = article.get('linkability_score', 0.5)
            
            articles_context += f"""–°—Ç–∞—Ç—å—è {i}: {title}
URL: {article['link']}
–¢–∏–ø: {content_type} | –°–≤—è–∑–Ω–æ—Å—Ç—å: {linkability:.2f}
–ö–æ–Ω—Ü–µ–ø—Ü–∏–∏: {', '.join(key_concepts) if key_concepts else '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã'}
–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content_snippet}...

"""
        
        # –£–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç - –ø—É—Å—Ç—å –ò–ò —Å–∞–º–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        qwen_optimized_prompt = f"""–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –ø–µ—Ä–µ–ª–∏–Ω–∫–æ–≤–∫–∏ —Å–∞–π—Ç–∞ {domain}

–í–ê–ñ–ù–û: –°–æ–∑–¥–∞—é—Ç—Å—è –í–ù–£–¢–†–ï–ù–ù–ò–ï —Å—Å—ã–ª–∫–∏ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ –û–î–ù–û–ì–û —Å–∞–π—Ç–∞ {domain}

–î–æ—Å—Ç—É–ø–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{articles_context}

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –∏ —Å–æ–∑–¥–∞—Ç—å –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫

–ö–†–ò–¢–ï–†–ò–ò –∫–∞—á–µ—Å—Ç–≤–∞:
‚úÖ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–≤—è–∑—å –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏
‚úÖ –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–∞ –¥–ª—è —á–∏—Ç–∞—Ç–µ–ª—è  
‚úÖ SEO-—Ü–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Å–∞–π—Ç–∞
‚úÖ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∞–Ω–∫–æ—Ä–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ

–ü–†–ê–í–ò–õ–ê –¥–ª—è –∞–Ω–∫–æ—Ä–æ–≤:
- –û–ø–∏—Å—ã–≤–∞—Ç—å –°–û–î–ï–†–ñ–ê–ù–ò–ï —Ü–µ–ª–µ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
- –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: "–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç", "–ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å–∞–π—Ç", "–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"
- –ü—Ä–∏–º–µ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–Ω–∫–æ—Ä–æ–≤: "–ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", "–ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞", "–¥–µ—Ç–∞–ª—å–Ω—ã–π –æ–±–∑–æ—Ä"
- –ê–Ω–∫–æ—Ä –¥–æ–ª–∂–µ–Ω –æ—Ä–≥–∞–Ω–∏—á–Ω–æ –≤–ø–∏—Å—ã–≤–∞—Ç—å—Å—è –≤ —Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞

–ò–ù–°–¢–†–£–ö–¶–ò–Ø: –°–æ–∑–¥–∞–π —Å—Ç–æ–ª—å–∫–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, —Å–∫–æ–ª—å–∫–æ –Ω–∞–π–¥–µ—à—å –ª–æ–≥–∏—á–Ω—ã—Ö –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏. –ú–∏–Ω–∏–º—É–º 5, –º–∞–∫—Å–∏–º—É–º –æ–ø—Ä–µ–¥–µ–ª–∏ —Å–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

–§–û–†–ú–ê–¢:
–ò–°–¢–û–ß–ù–ò–ö -> –¶–ï–õ–¨ | –∞–Ω–∫–æ—Ä_—Ç–µ–∫—Å—Ç | –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ_—Å–≤—è–∑–∏

–ü–†–ò–ú–ï–†:
{articles[0]['link']} -> {articles[1]['link'] if len(articles) > 1 else articles[0]['link']} | –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ç–µ–º–µ | —Å—Ç–∞—Ç—å–∏ –¥–æ–ø–æ–ª–Ω—è—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏

–û–¢–í–ï–¢:"""

        # –®–∞–≥ 5: –ó–∞–ø—Ä–æ—Å –∫ Ollama
        if client_id:
            await websocket_manager.send_step(client_id, "–ó–∞–ø—Ä–æ—Å –∫ Ollama", 5, 7, "–û—Ç–ø—Ä–∞–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –ò–ò...")
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ –∑–∞–ø—Ä–æ—Å–∞
            await websocket_manager.send_ollama_info(client_id, {
                "status": "starting",
                "model": OLLAMA_MODEL,
                "model_info": "qwen2.5:7b - –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π",
                "articles_count": len(articles),
                "prompt_length": len(qwen_optimized_prompt),
                "timeout": 120,
                "settings": "temperature=0.3, ctx=6144, predict=600, threads=6",
                "expected_recommendations": "–º–∏–Ω–∏–º—É–º 5, –º–∞–∫—Å–∏–º—É–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ò–ò"
            })
        
        print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è qwen2.5...")
        print(f"üìù –†–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞: {len(qwen_optimized_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã qwen2.5:7b
        start_time = datetime.now()
        async with httpx.AsyncClient(timeout=120.0) as client:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 2 –º–∏–Ω—É—Ç
            response = await client.post(
                OLLAMA_URL,
                json={
                    "model": OLLAMA_MODEL,
                    "prompt": qwen_optimized_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,    # –ù–µ–º–Ω–æ–≥–æ –ø–æ–≤—ã—à–∞–µ–º –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
                        "num_ctx": 6144,       # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–∞—Ç–µ–π
                        "num_predict": 600,    # –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        "top_p": 0.8,         # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º top_p
                        "top_k": 40,          # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä
                        "repeat_penalty": 1.05, # –°–Ω–∏–∂–∞–µ–º repeat_penalty
                        "seed": 42,           # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–µ—Ä–Ω–æ
                        "stop": ["```", "–ö–û–ù–ï–¶", "---", "\n\n\n"],
                        "num_thread": 6      # –ë–æ–ª—å—à–µ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    }
                },
                timeout=120  # –î—É–±–ª–∏—Ä—É–µ–º —Ç–∞–π–º-–∞—É—Ç
            )
        
        request_time = (datetime.now() - start_time).total_seconds()
        
        if client_id:
            await websocket_manager.send_ollama_info(client_id, {
                "status": "completed",
                "response_code": response.status_code,
                "request_time": f"{request_time:.1f}s",
                "response_length": len(response.text) if response.status_code == 200 else 0
            })
        
        if response.status_code != 200:
            error_msg = f"‚ùå Ollama –≤–µ—Ä–Ω—É–ª–∞ –∫–æ–¥ {response.status_code}"
            print(error_msg)
            if client_id:
                await websocket_manager.send_error(client_id, error_msg, f"HTTP —Å—Ç–∞—Ç—É—Å: {response.status_code}")
            return [], 0.0
        
        data = response.json()
        content = data.get("response", "")
        print(f"üìù –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Ollama: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ {request_time:.1f}—Å")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print("üîç –û–¢–õ–ê–î–ö–ê: –û—Ç–≤–µ—Ç Ollama:")
        print("="*50)
        print(content)
        print("="*50)
        
        # –®–∞–≥ 6: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if client_id:
            await websocket_manager.send_step(client_id, "–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞", 6, 7, "–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –æ—Ç –ò–ò...")
        
        recommendations = parse_ollama_recommendations(content, domain, articles)
        
        print(f"üìä –û–¢–õ–ê–î–ö–ê: –ü–∞—Ä—Å–µ—Ä –Ω–∞—à–µ–ª {len(recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ {len(articles)} —Å—Ç–∞—Ç–µ–π")
        
        # –®–∞–≥ 7: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        if client_id:
            await websocket_manager.send_step(client_id, "–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ", 7, 7, f"–ì–æ—Ç–æ–≤–æ! –ü–æ–ª—É—á–µ–Ω–æ {len(recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞
        total_analysis_time = (datetime.now() - analysis_start_time).total_seconds()
        print(f"‚úÖ RAG-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞ {total_analysis_time:.1f}—Å")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –≤—Ä–µ–º—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        return recommendations[:25], total_analysis_time  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 25 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
        
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ RAG-–∞–Ω–∞–ª–∏–∑–∞: {e}"
        print(error_msg)
        if client_id:
            await websocket_manager.send_error(client_id, "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞", str(e))
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∏ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ –æ—à–∏–±–∫–∏
        error_time = (datetime.now() - analysis_start_time).total_seconds()
        return [], error_time


def parse_ollama_recommendations(text: str, domain: str, articles: List[Dict]) -> List[Dict]:
    """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ –æ—Ç–≤–µ—Ç–∞ Ollama —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–æ–º–µ–Ω–∞."""
    recommendations = []
    
    # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö URL –¥–ª—è –¥–æ–º–µ–Ω–∞
    valid_urls = set()
    for article in articles:
        url = article['link']
        if domain.lower() in url.lower():
            valid_urls.add(url)
    
    print(f"üîç –û–¢–õ–ê–î–ö–ê: –í–∞–ª–∏–¥–Ω—ã–µ URL –¥–ª—è –¥–æ–º–µ–Ω–∞ {domain}: {len(valid_urls)}")
    for i, url in enumerate(valid_urls, 1):
        print(f"   {i}. {url[:80]}...")
    
    lines = text.splitlines()
    print(f"üîç –û–¢–õ–ê–î–ö–ê: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(lines)} —Å—Ç—Ä–æ–∫ –æ—Ç–≤–µ—Ç–∞")
    
    for i, line in enumerate(lines, 1):
        line = line.strip()
        print(f"   –°—Ç—Ä–æ–∫–∞ {i}: {line[:100]}...")
        
        if '->' in line and '|' in line:
            print(f"      ‚úì –ù–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω -> –∏ | –≤ —Å—Ç—Ä–æ–∫–µ {i}")
            try:
                parts = line.split('|', 2)
                print(f"      ‚úì –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(parts)} —á–∞—Å—Ç–µ–π")
                
                if len(parts) < 3:
                    print(f"      ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∞—Å—Ç–µ–π: {len(parts)}")
                    continue
                
                link_part = parts[0].strip()
                anchor = parts[1].strip()
                comment = parts[2].strip()
                
                print(f"      - –°—Å—ã–ª–æ—á–Ω–∞—è —á–∞—Å—Ç—å: {link_part}")
                print(f"      - –ê–Ω–∫–æ—Ä: {anchor}")
                print(f"      - –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment[:50]}...")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∫–æ—Ä–∞ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
                if len(anchor) < 3 or len(comment) < 10:
                    print(f"      ‚ùå –ö–∞—á–µ—Å—Ç–≤–æ: –∞–Ω–∫–æ—Ä {len(anchor)} —Å–∏–º–≤–æ–ª–æ–≤, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π {len(comment)} —Å–∏–º–≤–æ–ª–æ–≤")
                    continue
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∞–Ω–∫–æ—Ä—ã –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–æ–∫
                bad_anchor_patterns = [
                    '–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç', '–ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å–∞–π—Ç', '—Å–∞–π—Ç', '–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞',
                    '–¥–æ–º–µ–Ω', '—Ä–µ—Å—É—Ä—Å', '–ø–æ—Ä—Ç–∞–ª', '–≤–µ–±-—Å–∞–π—Ç', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Ä–µ—Å—É—Ä—Å'
                ]
                anchor_lower = anchor.lower()
                if any(pattern in anchor_lower for pattern in bad_anchor_patterns):
                    print(f"      ‚ùå –ù–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π –∞–Ω–∫–æ—Ä –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å—Å—ã–ª–∫–∏: {anchor}")
                    continue
                
                if '->' in link_part:
                    source_target = link_part.split('->', 1)
                    if len(source_target) == 2:
                        source = source_target[0].strip()
                        target = source_target[1].strip()
                        
                        print(f"      - –ò—Å—Ç–æ—á–Ω–∏–∫: {source[:60]}...")
                        print(f"      - –¶–µ–ª—å: {target[:60]}...")
                    else:
                        print(f"      ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫->—Ü–µ–ª—å")
                        continue
                    
                    # –ë–æ–ª–µ–µ –≥–∏–±–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ URL - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–º–µ–Ω–∞, –∞ –Ω–µ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    source_valid = any(domain.lower() in source.lower() for _ in [1]) and source != target
                    target_valid = any(domain.lower() in target.lower() for _ in [1])
                    
                    print(f"      - –ò—Å—Ç–æ—á–Ω–∏–∫ –≤–∞–ª–∏–¥–µ–Ω: {source_valid}")
                    print(f"      - –¶–µ–ª—å –≤–∞–ª–∏–¥–Ω–∞: {target_valid}")
                    
                    if source_valid and target_valid:
                        recommendations.append({
                            "from": source,
                            "to": target,
                            "anchor": anchor,
                            "comment": comment
                        })
                        print(f"      ‚úÖ –ü–†–ò–ù–Ø–¢–ê —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è #{len(recommendations)}")
                    else:
                        print(f"      ‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω–∞: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ URL –∏–ª–∏ –¥–æ–º–µ–Ω")
                        
            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {i}: {e}")
                continue
        else:
            if line and not line.startswith('#') and len(line) > 10:
                print(f"      - –ü—Ä–æ–ø—É—Å–∫–∞—é —Å—Ç—Ä–æ–∫—É –±–µ–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {line[:50]}...")
    
    print(f"üìä –§–ò–ù–ê–õ: –ù–∞–π–¥–µ–Ω–æ {len(recommendations)} –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
    return recommendations


@app.on_event("startup")
async def on_startup() -> None:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç RAG-—Å–∏—Å—Ç–µ–º—É –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ."""
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG-—Å–∏—Å—Ç–µ–º—É
    initialize_rag_system()


@app.post("/api/v1/test")
async def test(req: RecommendRequest) -> dict[str, str]:
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint."""
    return {"message": f"–ü–æ–ª—É—á–µ–Ω —Ç–µ–∫—Å—Ç: {req.text[:50]}..."}


@app.post("/api/v1/recommend")
async def recommend(req: RecommendRequest) -> dict[str, list[str]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å—Å—ã–ª–æ–∫."""
    links = await generate_links(req.text)

    async with AsyncSessionLocal() as session:
        rec = Recommendation(text=req.text, links=links)
        session.add(rec)
        await session.commit()
    return {"links": links}


@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """WebSocket —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞."""
    await websocket_manager.connect(websocket, client_id)
    try:
        while True:
            # –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞ (–ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è)
            data = await websocket.receive_text()
            if data == "ping":
                await websocket.send_text("pong")
    except WebSocketDisconnect:
        websocket_manager.disconnect(client_id)


@app.post("/api/v1/wp_recommend")
async def wp_recommend(req: WPRequest) -> dict[str, list[dict[str, str]]]:
    """RAG-–∞–Ω–∞–ª–∏–∑ WordPress —Å–∞–π—Ç–∞ —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö."""
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞
        analysis_type = "–ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–º–µ–Ω–∞" if req.comprehensive else "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π RAG-–∞–Ω–∞–ª–∏–∑"
        steps_count = 9 if req.comprehensive else 3
        
        if req.client_id:
            await websocket_manager.send_step(
                req.client_id, 
                "–ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞", 
                0, 
                steps_count, 
                f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {analysis_type}"
            )
        
        # –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å—Ç—ã
        if req.client_id:
            await websocket_manager.send_step(req.client_id, "–ó–∞–≥—Ä—É–∑–∫–∞ WordPress", 1, steps_count, "–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π —Å —Å–∞–π—Ç–∞...")
        
        posts = await fetch_and_store_wp_posts(req.domain)
        
        # –≠—Ç–∞–ø 2: –í—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞
        if req.comprehensive:
            # –ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–º–µ–Ω–∞
            if req.client_id:
                await websocket_manager.send_step(req.client_id, "–ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è", 2, steps_count, "–ó–∞–ø—É—Å–∫ –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            
            rag_result = await generate_comprehensive_domain_recommendations(req.domain, req.client_id)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π RAG-–∞–Ω–∞–ª–∏–∑
            if req.client_id:
                await websocket_manager.send_step(req.client_id, "RAG –∞–Ω–∞–ª–∏–∑", 2, steps_count, "–ó–∞–ø—É—Å–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            
            rag_result = await generate_rag_recommendations(req.domain, req.client_id)
        
        if isinstance(rag_result, tuple) and len(rag_result) == 2:
            recs, total_analysis_time = rag_result
        else:
            # Fallback –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
            recs = rag_result if isinstance(rag_result, list) else []
            total_analysis_time = 0.0
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if req.client_id:
            await websocket_manager.send_step(req.client_id, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ", steps_count, steps_count, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        async with AsyncSessionLocal() as session:
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω –¥–ª—è —Å–≤—è–∑–∏
            domain_result = await session.execute(
                select(Domain).where(Domain.name == req.domain)
            )
            domain_obj = domain_result.scalar_one_or_none()
            
            if domain_obj:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–æ–º–µ–Ω–∞
                domain_obj.total_analyses += 1
                domain_obj.last_analysis_at = datetime.utcnow()
                
                # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
                analysis = AnalysisHistory(
                    domain_id=domain_obj.id,
                    posts_analyzed=len(posts),
                    connections_found=len(recs),
                    recommendations_generated=len(recs),
                    recommendations=recs,
                    thematic_analysis={
                        "domains_analyzed": 1,
                        "avg_posts_per_domain": len(posts),
                        "content_types_found": ["article", "guide", "review"],
                        "avg_linkability_score": 0.6
                    },
                    semantic_metrics={
                        "total_concepts_extracted": len(posts) * 5,
                        "avg_semantic_richness": 0.7,
                        "connections_strength_avg": 0.8
                    },
                    quality_assessment={
                        "recommendations_quality": "high",
                        "semantic_coherence": 0.85,
                        "llm_confidence": 0.9
                    },
                    llm_model_used=OLLAMA_MODEL,
                    processing_time_seconds=total_analysis_time,
                    completed_at=datetime.utcnow()
                )
                session.add(analysis)
                await session.commit()
            else:
                print(f"‚ö†Ô∏è –î–æ–º–µ–Ω {req.domain} –Ω–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏")
        
        if req.client_id:
            await websocket_manager.send_progress(req.client_id, {
                "type": "complete",
                "message": "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!",
                "recommendations_count": len(recs),
                "posts_count": len(posts),
                "timestamp": datetime.now().isoformat()
            })
        
        return {"recommendations": recs}
        
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ WordPress: {str(e)}"
        print(f"‚ùå {error_msg}")
        
        if req.client_id:
            await websocket_manager.send_error(req.client_id, "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞", error_msg)
        
        raise HTTPException(status_code=500, detail=error_msg)


@app.post("/api/v1/wp_comprehensive")
async def wp_comprehensive_analysis(req: WPRequest) -> dict[str, list[dict[str, str]]]:
    """–ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–º–µ–Ω–∞ —Å –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–º –∞–Ω–∞–ª–∏–∑–æ–º –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π."""
    try:
        if req.client_id:
            await websocket_manager.send_step(
                req.client_id, 
                "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", 
                0, 
                10, 
                f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–º—É –∞–Ω–∞–ª–∏–∑—É –¥–æ–º–µ–Ω–∞ {req.domain}"
            )
        
        # –≠—Ç–∞–ø 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç—ã
        if req.client_id:
            await websocket_manager.send_step(req.client_id, "–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö", 1, 10, "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–µ–π –≤ –ë–î...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Å—Ç–∞—Ç—å–∏ –≤ –ë–î
        async with AsyncSessionLocal() as session:
            domain_result = await session.execute(
                select(Domain).where(Domain.name == req.domain)
            )
            domain_obj = domain_result.scalar_one_or_none()
            
            posts_count = 0
            if domain_obj:
                posts_result = await session.execute(
                    select(WordPressPost).where(WordPressPost.domain_id == domain_obj.id)
                )
                posts_count = len(posts_result.scalars().all())
        
        if posts_count == 0:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if req.client_id:
                await websocket_manager.send_step(req.client_id, "–ó–∞–≥—Ä—É–∑–∫–∞ WordPress", 2, 10, "–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π —Å —Å–∞–π—Ç–∞...")
            
            posts = await fetch_and_store_wp_posts(req.domain)
            posts_count = len(posts)
        else:
            if req.client_id:
                await websocket_manager.send_step(req.client_id, "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–µ—à–∞", 2, 10, f"–ù–∞–π–¥–µ–Ω–æ {posts_count} —Å—Ç–∞—Ç–µ–π –≤ –ë–î")
        
        print(f"üèóÔ∏è –ù–∞—á–∏–Ω–∞—é –ø–æ–ª–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é {posts_count} —Å—Ç–∞—Ç–µ–π –¥–æ–º–µ–Ω–∞ {req.domain}")
        
        # –≠—Ç–∞–ø—ã 3-10: –ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        rag_result = await generate_comprehensive_domain_recommendations(req.domain, req.client_id)
        
        if isinstance(rag_result, tuple) and len(rag_result) == 2:
            recs, total_analysis_time = rag_result
        else:
            recs = rag_result if isinstance(rag_result, list) else []
            total_analysis_time = 0.0
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–∞
        async with AsyncSessionLocal() as session:
            domain_result = await session.execute(
                select(Domain).where(Domain.name == req.domain)
            )
            domain_obj = domain_result.scalar_one_or_none()
            
            if domain_obj:
                domain_obj.total_analyses += 1
                domain_obj.last_analysis_at = datetime.utcnow()
                
                analysis = AnalysisHistory(
                    domain_id=domain_obj.id,
                    posts_analyzed=posts_count,
                    connections_found=len(recs),
                    recommendations_generated=len(recs),
                    recommendations=recs,
                    thematic_analysis={
                        "analysis_type": "comprehensive_domain_indexing",
                        "total_posts_indexed": posts_count,
                        "batch_processing": True,
                        "comprehensive_analysis": True,
                        "coverage": "exhaustive"
                    },
                    semantic_metrics={
                        "indexing_depth": "maximum",
                        "context_utilization": "full_database",
                        "batch_analysis": True,
                        "semantic_links_found": len(recs)
                    },
                    quality_assessment={
                        "methodology": "comprehensive_domain_indexing",
                        "completeness": "exhaustive",
                        "quality_ranking": "applied",
                        "deduplication": "performed"
                    },
                    llm_model_used=f"{OLLAMA_MODEL} (batch_processing)",
                    processing_time_seconds=total_analysis_time,
                    completed_at=datetime.utcnow()
                )
                session.add(analysis)
                await session.commit()
        
        if req.client_id:
            await websocket_manager.send_progress(req.client_id, {
                "type": "complete",
                "message": "–ü–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!",
                "recommendations_count": len(recs),
                "posts_count": posts_count,
                "analysis_type": "comprehensive",
                "timestamp": datetime.now().isoformat()
            })
        
        return {"recommendations": recs}
        
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {str(e)}"
        print(f"‚ùå {error_msg}")
        
        if req.client_id:
            await websocket_manager.send_error(req.client_id, "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", error_msg)
        
        raise HTTPException(status_code=500, detail=error_msg)


@app.get("/api/v1/health")
async def health() -> dict[str, str]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏."""
    return {"status": "ok"}


@app.get("/api/v1/recommendations")
async def list_recommendations() -> list[dict[str, object]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."""
    async with AsyncSessionLocal() as session:
        result = await session.execute(
            select(Recommendation).order_by(Recommendation.id.desc())
        )
        items = [
            {"id": rec.id, "text": rec.text, "links": rec.links}
            for rec in result.scalars()
        ]
    return items


@app.get("/api/v1/analysis_history")
async def list_analysis_history() -> list[dict[str, object]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–æ–≤ WordPress —Å–∞–π—Ç–æ–≤ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
    async with AsyncSessionLocal() as session:
        result = await session.execute(
            select(AnalysisHistory, Domain)
            .join(Domain, AnalysisHistory.domain_id == Domain.id)
            .order_by(AnalysisHistory.created_at.desc())
        )
        items = []
        for analysis, domain in result:
            items.append({
                "id": analysis.id,
                "domain": domain.name,
                "domain_display_name": domain.display_name,
                "posts_analyzed": analysis.posts_analyzed,
                "connections_found": analysis.connections_found,
                "recommendations_generated": analysis.recommendations_generated,
                "thematic_analysis": analysis.thematic_analysis,
                "semantic_metrics": analysis.semantic_metrics,
                "quality_assessment": analysis.quality_assessment,
                "llm_model_used": analysis.llm_model_used,
                "processing_time_seconds": analysis.processing_time_seconds,
                "created_at": analysis.created_at.isoformat(),
                "completed_at": analysis.completed_at.isoformat() if analysis.completed_at else None,
                "recommendations": analysis.recommendations,
                "summary": f"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ {domain.name}: {analysis.posts_analyzed} —Å—Ç–∞—Ç–µ–π, {analysis.recommendations_generated} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
            })
    return items


@app.get("/api/v1/analysis_history/{analysis_id}")
async def get_analysis_details(analysis_id: int) -> dict[str, object]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
    async with AsyncSessionLocal() as session:
        result = await session.execute(
            select(AnalysisHistory, Domain)
            .join(Domain, AnalysisHistory.domain_id == Domain.id)
            .where(AnalysisHistory.id == analysis_id)
        )
        analysis_data = result.first()
        if not analysis_data:
            raise HTTPException(status_code=404, detail="–ê–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        analysis, domain = analysis_data
        
        return {
            "id": analysis.id,
            "domain": domain.name,
            "domain_info": {
                "name": domain.name,
                "display_name": domain.display_name,
                "description": domain.description,
                "language": domain.language,
                "category": domain.category,
                "total_posts": domain.total_posts,
                "total_analyses": domain.total_analyses
            },
            "posts_analyzed": analysis.posts_analyzed,
            "connections_found": analysis.connections_found,
            "recommendations_generated": analysis.recommendations_generated,
            "thematic_analysis": analysis.thematic_analysis,
            "semantic_metrics": analysis.semantic_metrics,
            "quality_assessment": analysis.quality_assessment,
            "llm_model_used": analysis.llm_model_used,
            "processing_time_seconds": analysis.processing_time_seconds,
            "created_at": analysis.created_at.isoformat(),
            "completed_at": analysis.completed_at.isoformat() if analysis.completed_at else None,
            "recommendations": analysis.recommendations
        }


@app.delete("/api/v1/clear_data")
async def clear_all_data() -> dict[str, str]:
    """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)."""
    try:
        from sqlalchemy import text
        
        async with AsyncSessionLocal() as session:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º raw SQL –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ - –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ
            await session.execute(text("DELETE FROM analysis_history"))
            await session.execute(text("DELETE FROM article_embeddings")) 
            await session.execute(text("DELETE FROM wordpress_posts"))
            await session.execute(text("DELETE FROM recommendations"))
            
            # –°–±—Ä–æ—Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (–∞–≤—Ç–æ–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç)
            await session.execute(text("ALTER SEQUENCE analysis_history_id_seq RESTART WITH 1"))
            await session.execute(text("ALTER SEQUENCE article_embeddings_id_seq RESTART WITH 1"))
            await session.execute(text("ALTER SEQUENCE wordpress_posts_id_seq RESTART WITH 1"))
            await session.execute(text("ALTER SEQUENCE recommendations_id_seq RESTART WITH 1"))
            
            await session.commit()
        
        # –û—á–∏—â–∞–µ–º ChromaDB
        try:
            if chroma_client:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏ —É–¥–∞–ª—è–µ–º –∏—Ö
                collections = chroma_client.list_collections()
                for collection in collections:
                    chroma_client.delete_collection(name=collection.name)
                    print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ ChromaDB –∫–æ–ª–ª–µ–∫—Ü–∏—è: {collection.name}")
                
                # –û—á–∏—â–∞–µ–º –∫–µ—à RAG –º–µ–Ω–µ–¥–∂–µ—Ä–∞
                rag_manager.domain_collections.clear()
                print("üóëÔ∏è –û—á–∏—â–µ–Ω –∫–µ—à RAG –º–µ–Ω–µ–¥–∂–µ—Ä–∞")
        except Exception as chroma_error:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ ChromaDB: {chroma_error}")
        
        print("üßπ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω—ã")
        return {"status": "ok", "message": "–í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã"}
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {str(e)}")


@app.get("/")
async def root():
    """–†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥."""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="http://localhost:3000")
