"""
–°–µ—Ä–≤–∏—Å–Ω—ã–π —Å–ª–æ–π –¥–ª—è LLM Tuning –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏ —Ç—é–Ω–∏–Ω–≥–∞
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

import httpx
import numpy as np
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete, and_, or_, func
from sqlalchemy.orm import selectinload

from .models import (
    LLMModel, ModelRoute, TuningSession, PerformanceMetrics,
    RAGDocument, APILog, ModelStatus, RouteStrategy, TuningStrategy
)
from .config import settings

logger = logging.getLogger(__name__)


class ModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è LLM –º–æ–¥–µ–ª—è–º–∏"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    async def list_models(self) -> List[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ Ollama
            response = await self.ollama_client.get("/api/tags")
            ollama_models = response.json().get("models", [])
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –ë–î
            stmt = select(LLMModel).options(selectinload(LLMModel.routes))
            result = await self.db.execute(stmt)
            db_models = result.scalars().all()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å—ã –º–æ–¥–µ–ª–µ–π
            for model in db_models:
                model.is_available = any(
                    m["name"] == model.name for m in ollama_models
                )
            
            await self.db.commit()
            return db_models
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            raise
    
    async def get_model(self, model_id: int) -> Optional[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ ID"""
        stmt = select(LLMModel).options(
            selectinload(LLMModel.routes),
            selectinload(LLMModel.metrics)
        ).where(LLMModel.id == model_id)
        
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def create_model(self, model_data: Dict[str, Any]) -> LLMModel:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        model = LLMModel(**model_data)
        self.db.add(model)
        await self.db.commit()
        await self.db.refresh(model)
        return model
    
    async def update_model(self, model_id: int, model_data: Dict[str, Any]) -> Optional[LLMModel]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        stmt = update(LLMModel).where(LLMModel.id == model_id).values(**model_data)
        await self.db.execute(stmt)
        await self.db.commit()
        
        return await self.get_model(model_id)
    
    async def delete_model(self, model_id: int) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        stmt = delete(LLMModel).where(LLMModel.id == model_id)
        result = await self.db.execute(stmt)
        await self.db.commit()
        return result.rowcount > 0
    
    async def get_model_info(self, model_name: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –∏–∑ Ollama"""
        try:
            response = await self.ollama_client.get(f"/api/show", params={"name": model_name})
            return response.json()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ {model_name}: {e}")
            return {}


class RouteManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self._route_cache: Dict[str, ModelRoute] = {}
        self._cache_updated = datetime.now()
    
    async def get_route(self, request_type: str, content: str = "") -> Optional[ModelRoute]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
        if datetime.now() - self._cache_updated > timedelta(minutes=5):
            await self._update_cache()
        
        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–∞—Ä—à—Ä—É—Ç
        for route in self._route_cache.values():
            if route.is_active and self._matches_route(route, request_type, content):
                return route
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Ä—à—Ä—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return self._get_default_route()
    
    def _matches_route(self, route: ModelRoute, request_type: str, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∑–∞–ø—Ä–æ—Å–∞ –º–∞—Ä—à—Ä—É—Ç—É"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        if route.request_types and request_type not in route.request_types:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if route.keywords and not any(
            keyword.lower() in content.lower() for keyword in route.keywords
        ):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        if route.complexity_threshold:
            complexity = self._calculate_complexity(content)
            if complexity < route.complexity_threshold:
                return False
        
        return True
    
    def _calculate_complexity(self, content: str) -> float:
        """–†–∞—Å—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if not content:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        words = content.split()
        sentences = content.split('.')
        avg_sentence_length = len(words) / len(sentences) if sentences else 0
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ —á–∏—Å–ª–∞
        special_chars = sum(1 for c in content if not c.isalnum() and not c.isspace())
        numbers = sum(1 for c in content if c.isdigit())
        
        complexity = (
            avg_sentence_length * 0.4 +
            (special_chars / len(content)) * 0.3 +
            (numbers / len(content)) * 0.3
        )
        
        return min(complexity, 1.0)
    
    def _get_default_route(self) -> Optional[ModelRoute]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        for route in self._route_cache.values():
            if route.is_default:
                return route
        return None
    
    async def _update_cache(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ –º–∞—Ä—à—Ä—É—Ç–æ–≤"""
        stmt = select(ModelRoute).options(selectinload(ModelRoute.model))
        result = await self.db.execute(stmt)
        routes = result.scalars().all()
        
        self._route_cache = {route.name: route for route in routes}
        self._cache_updated = datetime.now()
    
    async def create_route(self, route_data: Dict[str, Any]) -> ModelRoute:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –º–∞—Ä—à—Ä—É—Ç–∞"""
        route = ModelRoute(**route_data)
        self.db.add(route)
        await self.db.commit()
        await self.db.refresh(route)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
        await self._update_cache()
        return route
    
    async def update_route(self, route_id: int, route_data: Dict[str, Any]) -> Optional[ModelRoute]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞—Ä—à—Ä—É—Ç–∞"""
        stmt = update(ModelRoute).where(ModelRoute.id == route_id).values(**route_data)
        await self.db.execute(stmt)
        await self.db.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
        await self._update_cache()
        
        stmt = select(ModelRoute).where(ModelRoute.id == route_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()


class RAGService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RAG (Retrieval-Augmented Generation)"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
        self._vector_cache: Dict[str, List[float]] = {}
    
    async def add_document(self, document_data: Dict[str, Any]) -> RAGDocument:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ RAG —Å–∏—Å—Ç–µ–º—É"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            document = RAGDocument(**document_data)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            embeddings = await self._generate_embeddings(document.content)
            document.embeddings = json.dumps(embeddings)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            document.keywords = await self._extract_keywords(document.content)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            self.db.add(document)
            await self.db.commit()
            await self.db.refresh(document)
            
            # –ö—ç—à–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            self._vector_cache[f"doc_{document.id}"] = embeddings
            
            logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç {document.title} –¥–æ–±–∞–≤–ª–µ–Ω –≤ RAG —Å–∏—Å—Ç–µ–º—É")
            return document
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            raise
    
    async def search_documents(self, query: str, limit: int = 5) -> List[RAGDocument]:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embeddings = await self._generate_embeddings(query)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            stmt = select(RAGDocument).where(RAGDocument.is_active == True)
            result = await self.db.execute(stmt)
            documents = result.scalars().all()
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarities = []
            for doc in documents:
                if doc.embeddings:
                    doc_embeddings = json.loads(doc.embeddings)
                    similarity = self._cosine_similarity(query_embeddings, doc_embeddings)
                    similarities.append((similarity, doc))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            similarities.sort(key=lambda x: x[0], reverse=True)
            top_documents = [doc for _, doc in similarities[:limit]]
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(top_documents)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
            return top_documents
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return []
    
    async def generate_with_rag(
        self, 
        model_name: str, 
        query: str, 
        context_documents: List[RAGDocument] = None
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG"""
        try:
            # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏—â–µ–º –∏—Ö
            if not context_documents:
                context_documents = await self.search_documents(query, limit=3)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            context = self._build_context(context_documents)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            system_prompt = """–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 
            –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º —á–µ—Å—Ç–Ω–æ."""
            
            user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç:"""
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = await self._generate_response(model_name, user_prompt, system_prompt)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            response["context_documents"] = [
                {
                    "title": doc.title,
                    "source": doc.source,
                    "relevance_score": doc.relevance_score
                }
                for doc in context_documents
            ]
            
            return response
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å RAG: {e}")
            return {
                "error": str(e),
                "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."
            }
    
    async def _generate_embeddings(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            response = await self.ollama_client.post(
                "/api/embeddings",
                json={
                    "model": "nomic-embed-text",
                    "prompt": text
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("embedding", [])
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                return self._simple_embeddings(text)
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}")
            return self._simple_embeddings(text)
    
    def _simple_embeddings(self, text: str) -> List[float]:
        """–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è fallback"""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã —Å–∏–º–≤–æ–ª–æ–≤
        import string
        from collections import Counter
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
        text = text.lower()
        text = ''.join(c for c in text if c.isalnum() or c.isspace())
        
        # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É —Å–∏–º–≤–æ–ª–æ–≤
        char_freq = Counter(text)
        
        # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
        embedding = [0.0] * 128
        for i, (char, freq) in enumerate(char_freq.most_common(128)):
            if i < 128:
                embedding[i] = freq / len(text)
        
        return embedding
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        try:
            import numpy as np
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω–µ
            min_len = min(len(vec1), len(vec2))
            vec1 = vec1[:min_len]
            vec2 = vec2[:min_len]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return dot_product / (norm1 * norm2)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}")
            return 0.0
    
    async def _extract_keywords(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            import re
            from collections import Counter
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            stop_words = {
                '–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞',
                '—Ç–∞–∫', '–µ–≥–æ', '–Ω–æ', '–¥–∞', '—Ç—ã', '–∫', '—É', '–∂–µ', '–≤—ã', '–∑–∞', '–±—ã', '–ø–æ', '—Ç–æ–ª—å–∫–æ', '–µ–µ',
                '–º–Ω–µ', '–±—ã–ª–æ', '–≤–æ—Ç', '–æ—Ç', '–º–µ–Ω—è', '–µ—â–µ', '–Ω–µ—Ç', '–æ', '–∏–∑', '–µ–º—É', '—Ç–µ–ø–µ—Ä—å', '–∫–æ–≥–¥–∞',
                '–¥–∞–∂–µ', '–Ω—É', '–≤–¥—Ä—É–≥', '–ª–∏', '–µ—Å–ª–∏', '—É–∂–µ', '–∏–ª–∏', '–Ω–∏', '–±—ã—Ç—å', '–±—ã–ª', '–Ω–µ–≥–æ', '–¥–æ',
                '–≤–∞—Å', '–Ω–∏–±—É–¥—å', '–æ–ø—è—Ç—å', '—É–∂', '–≤–∞–º', '–≤–µ–¥—å', '—Ç–∞–º', '–ø–æ—Ç–æ–º', '—Å–µ–±—è', '–Ω–∏—á–µ–≥–æ', '–µ–π',
                '–º–æ–∂–µ—Ç', '–æ–Ω–∏', '—Ç—É—Ç', '–≥–¥–µ', '–µ—Å—Ç—å', '–Ω–∞–¥–æ', '–Ω–µ–π', '–¥–ª—è', '–º—ã', '—Ç–µ–±—è', '–∏—Ö', '—á–µ–º',
                '–±—ã–ª–∞', '—Å–∞–º', '—á—Ç–æ–±', '–±–µ–∑', '–±—É–¥—Ç–æ', '—á–µ–≥–æ', '—Ä–∞–∑', '—Ç–æ–∂–µ', '—Å–µ–±–µ', '–ø–æ–¥', '–±—É–¥–µ—Ç',
                '–∂', '—Ç–æ–≥–¥–∞', '–∫—Ç–æ', '—ç—Ç–æ—Ç', '—Ç–æ–≥–æ', '–ø–æ—Ç–æ–º—É', '—ç—Ç–æ–≥–æ', '–∫–∞–∫–æ–π', '—Å–æ–≤—Å–µ–º', '–Ω–∏–º', '–∑–¥–µ—Å—å',
                '—ç—Ç–æ–º', '–æ–¥–∏–Ω', '–ø–æ—á—Ç–∏', '–º–æ–π', '—Ç–µ–º', '—á—Ç–æ–±—ã', '–Ω–µ–µ', '—Å–µ–π—á–∞—Å', '–±—ã–ª–∏', '–∫—É–¥–∞', '–∑–∞—á–µ–º',
                '–≤—Å–µ—Ö', '–Ω–∏–∫–æ–≥–¥–∞', '–º–æ–∂–Ω–æ', '–ø—Ä–∏', '–Ω–∞–∫–æ–Ω–µ—Ü', '–¥–≤–∞', '–æ–±', '–¥—Ä—É–≥–æ–π', '—Ö–æ—Ç—å', '–ø–æ—Å–ª–µ',
                '–Ω–∞–¥', '–±–æ–ª—å—à–µ', '—Ç–æ—Ç', '—á–µ—Ä–µ–∑', '—ç—Ç–∏', '–Ω–∞—Å', '–ø—Ä–æ', '–≤—Å–µ–≥–æ', '–Ω–∏—Ö', '–∫–∞–∫–∞—è', '–º–Ω–æ–≥–æ',
                '—Ä–∞–∑–≤–µ', '—Ç—Ä–∏', '—ç—Ç—É', '–º–æ—è', '–≤–ø—Ä–æ—á–µ–º', '—Ö–æ—Ä–æ—à–æ', '—Å–≤–æ—é', '—ç—Ç–æ–π', '–ø–µ—Ä–µ–¥', '–∏–Ω–æ–≥–¥–∞',
                '–ª—É—á—à–µ', '—á—É—Ç—å', '—Ç–æ–º', '–Ω–µ–ª—å–∑—è', '—Ç–∞–∫–æ–π', '–∏–º', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–ø—Ä–∏—Ç–æ–º', '–±—É–¥–µ—Ç',
                '–æ—á–µ–Ω—å', '–Ω–∞—Å', '–≤–¥–≤–æ–µ–º', '–ø–æ–¥', '–æ–±–æ—Ä–æ—Ç', '—Ç–µ–ø–µ—Ä—å', '–¥–æ–ª–≥–æ', '–ª–∏', '–æ—á–µ–Ω—å', '–ª–∏–±–æ',
                '–≤–ø—Ä–æ—á–µ–º', '–≤—Å–µ', '—Ç–∞–∫–∏', '–±–æ–ª–µ–µ', '–≤—Å–µ–≥–¥–∞', '–º–µ–∂–¥—É'
            }
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
            text = text.lower()
            text = re.sub(r'[^\w\s]', '', text)
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
            words = text.split()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
            keywords = [
                word for word in words 
                if word not in stop_words and len(word) > 2
            ]
            
            # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-10
            word_freq = Counter(keywords)
            return [word for word, _ in word_freq.most_common(10)]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
            return []
    
    def _build_context(self, documents: List[RAGDocument]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if not documents:
            return ""
        
        context_parts = []
        for i, doc in enumerate(documents, 1):
            context_parts.append(f"–î–æ–∫—É–º–µ–Ω—Ç {i}: {doc.title}")
            context_parts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {doc.source}")
            context_parts.append(f"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {doc.content[:500]}...")
            context_parts.append("")
        
        return "\n".join(context_parts)
    
    async def _generate_response(
        self, 
        model_name: str, 
        prompt: str, 
        system_prompt: str = None
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏"""
        try:
            payload = {
                "model": model_name,
                "prompt": prompt,
                "stream": False
            }
            
            if system_prompt:
                payload["system"] = system_prompt
            
            response = await self.ollama_client.post(
                "/api/generate",
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "response": data.get("response", ""),
                    "model": model_name,
                    "tokens_used": data.get("eval_count", 0),
                    "prompt_eval_count": data.get("prompt_eval_count", 0),
                    "eval_count": data.get("eval_count", 0)
                }
            else:
                return {
                    "error": f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {response.text}",
                    "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."
                }
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                "error": str(e),
                "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."
            }
    
    async def update_document(self, doc_id: int, updates: Dict[str, Any]) -> Optional[RAGDocument]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            stmt = select(RAGDocument).where(RAGDocument.id == doc_id)
            result = await self.db.execute(stmt)
            document = result.scalar_one_or_none()
            
            if not document:
                return None
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
            for key, value in updates.items():
                if hasattr(document, key):
                    setattr(document, key, value)
            
            # –ï—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç, –æ–±–Ω–æ–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            if "content" in updates:
                embeddings = await self._generate_embeddings(document.content)
                document.embeddings = json.dumps(embeddings)
                document.keywords = await self._extract_keywords(document.content)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                self._vector_cache[f"doc_{document.id}"] = embeddings
            
            await self.db.commit()
            await self.db.refresh(document)
            
            return document
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return None
    
    async def delete_document(self, doc_id: int) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            stmt = select(RAGDocument).where(RAGDocument.id == doc_id)
            result = await self.db.execute(stmt)
            document = result.scalar_one_or_none()
            
            if not document:
                return False
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞
            cache_key = f"doc_{document.id}"
            if cache_key in self._vector_cache:
                del self._vector_cache[cache_key]
            
            # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–π
            document.is_active = False
            await self.db.commit()
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
    
    async def get_documents_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            total_stmt = select(func.count(RAGDocument.id))
            total_result = await self.db.execute(total_stmt)
            total_docs = total_result.scalar()
            
            # –ê–∫—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            active_stmt = select(func.count(RAGDocument.id)).where(RAGDocument.is_active == True)
            active_result = await self.db.execute(active_stmt)
            active_docs = active_result.scalar()
            
            # –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ç–∏–ø–∞–º
            type_stmt = select(
                RAGDocument.document_type,
                func.count(RAGDocument.id)
            ).group_by(RAGDocument.document_type)
            type_result = await self.db.execute(type_stmt)
            docs_by_type = dict(type_result.all())
            
            return {
                "total_documents": total_docs,
                "active_documents": active_docs,
                "documents_by_type": docs_by_type,
                "vector_cache_size": len(self._vector_cache)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return {}


class TuningService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    async def create_tuning_session(self, session_data: Dict[str, Any]) -> TuningSession:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
        session = TuningSession(**session_data)
        self.db.add(session)
        await self.db.commit()
        await self.db.refresh(session)
        return session
    
    async def get_tuning_session(self, session_id: int) -> Optional[TuningSession]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
        stmt = select(TuningSession).where(TuningSession.id == session_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def update_tuning_session(self, session_id: int, updates: Dict[str, Any]) -> Optional[TuningSession]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ç—é–Ω–∏–Ω–≥–∞"""
        stmt = update(TuningSession).where(TuningSession.id == session_id).values(**updates)
        await self.db.execute(stmt)
        await self.db.commit()
        
        return await self.get_tuning_session(session_id)
    
    async def start_tuning(self, session_id: int) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ç—é–Ω–∏–Ω–≥–∞"""
        session = await self.get_tuning_session(session_id)
        if not session:
            return False
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.TUNING,
                "started_at": datetime.now()
            })
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—é–Ω–∏–Ω–≥ –≤ —Ñ–æ–Ω–µ
            asyncio.create_task(self._run_tuning(session_id))
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Ç—é–Ω–∏–Ω–≥–∞: {e}")
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.FAILED,
                "error_message": str(e)
            })
            return False
    
    async def _run_tuning(self, session_id: int):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–∏"""
        session = await self.get_tuning_session(session_id)
        if not session:
            logger.error(f"–°–µ—Å—Å–∏—è —Ç—é–Ω–∏–Ω–≥–∞ {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        try:
            logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            model = await self._get_model_by_session(session_id)
            if not model:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                })
                return
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.TUNING,
                "started_at": datetime.now()
            })
            
            # –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (10%)
            logger.info("üìä –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞")
            await self.update_tuning_session(session_id, {"progress": 10})
            
            training_data = await self._prepare_training_data(session)
            if not training_data:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"
                })
                return
            
            # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ Modelfile (20%)
            logger.info("üìù –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ Modelfile")
            await self.update_tuning_session(session_id, {"progress": 20})
            
            modelfile = await self._create_modelfile(model, training_data, session)
            if not modelfile:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Modelfile"
                })
                return
            
            # –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (40%)
            logger.info("‚¨áÔ∏è –≠—Ç–∞–ø 3: –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
            await self.update_tuning_session(session_id, {"progress": 40})
            
            base_model_loaded = await self._ensure_base_model(model.base_model)
            if not base_model_loaded:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å"
                })
                return
            
            # –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (70%)
            logger.info("üîß –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            await self.update_tuning_session(session_id, {"progress": 70})
            
            tuned_model_name = f"{model.name}-tuned-{session_id}"
            model_created = await self._create_tuned_model(tuned_model_name, modelfile)
            if not model_created:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"
                })
                return
            
            # –≠—Ç–∞–ø 5: –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (90%)
            logger.info("‚úÖ –≠—Ç–∞–ø 5: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            await self.update_tuning_session(session_id, {"progress": 90})
            
            validation_result = await self._validate_tuned_model(tuned_model_name, session)
            if not validation_result["success"]:
                await self.update_tuning_session(session_id, {
                    "status": ModelStatus.FAILED,
                    "error_message": f"–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞: {validation_result['error']}"
                })
                return
            
            # –≠—Ç–∞–ø 6: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ (100%)
            logger.info("üéâ –≠—Ç–∞–ø 6: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ç—é–Ω–∏–Ω–≥–∞")
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.READY,
                "progress": 100,
                "completed_at": datetime.now(),
                "tuned_model_name": tuned_model_name,
                "validation_metrics": validation_result["metrics"]
            })
            
            logger.info(f"‚úÖ –¢—é–Ω–∏–Ω–≥ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ: {tuned_model_name}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ç—é–Ω–∏–Ω–≥–∞ —Å–µ—Å—Å–∏–∏ {session_id}: {e}")
            await self.update_tuning_session(session_id, {
                "status": ModelStatus.FAILED,
                "error_message": str(e)
            })
    
    async def _get_model_by_session(self, session_id: int) -> Optional[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ ID —Å–µ—Å—Å–∏–∏"""
        stmt = select(TuningSession).where(TuningSession.id == session_id)
        result = await self.db.execute(stmt)
        session = result.scalar_one_or_none()
        
        if not session:
            return None
        
        stmt = select(LLMModel).where(LLMModel.id == session.model_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def _prepare_training_data(self, session: TuningSession) -> Optional[List[Dict[str, str]]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞ –∏–∑ —Å–µ—Å—Å–∏–∏
            training_data = []
            
            # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞
            if session.training_data:
                training_data = json.loads(session.training_data)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
                training_data = [
                    {
                        "instruction": "–û–±—ä—è—Å–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è",
                        "input": "",
                        "output": "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - —ç—Ç–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º —É—á–∏—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."
                    },
                    {
                        "instruction": "–ù–∞–ø–∏—à–∏ –∫–æ–¥ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞",
                        "input": "–º–∞—Å—Å–∏–≤ [3, 1, 4, 1, 5]",
                        "output": "def sort_array(arr):\n    return sorted(arr)\n\n# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\narr = [3, 1, 4, 1, 5]\nsorted_arr = sort_array(arr)\nprint(sorted_arr)  # [1, 1, 3, 4, 5]"
                    }
                ]
            
            return training_data
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞: {e}")
            return None
    
    async def _create_modelfile(
        self, 
        model: LLMModel, 
        training_data: List[Dict[str, str]], 
        session: TuningSession
    ) -> Optional[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ Modelfile –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"""
        try:
            modelfile_lines = [
                f"FROM {model.base_model}",
                "",
                "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏",
                f"PARAMETER temperature {session.parameters.get('temperature', 0.7)}",
                f"PARAMETER top_p {session.parameters.get('top_p', 0.9)}",
                f"PARAMETER top_k {session.parameters.get('top_k', 40)}",
                f"PARAMETER repeat_penalty {session.parameters.get('repeat_penalty', 1.1)}",
                "",
                "# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç",
                f'SYSTEM """{session.system_prompt or "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."}"""',
                "",
                "# –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞"
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ç—é–Ω–∏–Ω–≥–∞
            for i, example in enumerate(training_data):
                instruction = example.get("instruction", "")
                input_text = example.get("input", "")
                output = example.get("output", "")
                
                if input_text:
                    prompt = f"{instruction}\n\n–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {input_text}"
                else:
                    prompt = instruction
                
                modelfile_lines.extend([
                    f"# –ü—Ä–∏–º–µ—Ä {i+1}",
                    f'PROMPT """{prompt}"""',
                    f'RESPONSE """{output}"""',
                    ""
                ])
            
            modelfile = "\n".join(modelfile_lines)
            logger.info(f"–°–æ–∑–¥–∞–Ω Modelfile –¥–ª—è –º–æ–¥–µ–ª–∏ {model.name}")
            return modelfile
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Modelfile: {e}")
            return None
    
    async def _ensure_base_model(self, base_model: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –º–æ–¥–µ–ª—å –≤ Ollama
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{settings.OLLAMA_BASE_URL}/api/tags")
                if response.status_code == 200:
                    models = response.json().get("models", [])
                    model_names = [model["name"] for model in models]
                    
                    if base_model in model_names:
                        logger.info(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å {base_model} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                        return True
            
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å
            logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å {base_model}")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{settings.OLLAMA_BASE_URL}/api/pull",
                    json={"name": base_model}
                )
                
                if response.status_code == 200:
                    logger.info(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å {base_model} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    return True
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ {base_model}")
                    return False
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    async def _create_tuned_model(self, model_name: str, modelfile: str) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{settings.OLLAMA_BASE_URL}/api/create",
                    json={
                        "name": model_name,
                        "modelfile": modelfile
                    }
                )
                
                if response.status_code == 200:
                    logger.info(f"–¢—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å {model_name} —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    return True
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {response.text}")
                    return False
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    async def _validate_tuned_model(self, model_name: str, session: TuningSession) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç—é–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            test_queries = [
                "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
                "–û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, —á—Ç–æ —Ç–∞–∫–æ–µ API",
                "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏"
            ]
            
            results = []
            total_tokens = 0
            total_time = 0
            
            async with httpx.AsyncClient() as client:
                for query in test_queries:
                    start_time = time.time()
                    
                    response = await client.post(
                        f"{settings.OLLAMA_BASE_URL}/api/generate",
                        json={
                            "model": model_name,
                            "prompt": query,
                            "stream": False
                        }
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        end_time = time.time()
                        
                        results.append({
                            "query": query,
                            "response": result.get("response", ""),
                            "tokens": result.get("eval_count", 0),
                            "time": end_time - start_time
                        })
                        
                        total_tokens += result.get("eval_count", 0)
                        total_time += end_time - start_time
                    else:
                        return {
                            "success": False,
                            "error": f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {response.text}"
                        }
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            avg_response_time = total_time / len(results) if results else 0
            avg_tokens = total_tokens / len(results) if results else 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–ª–∏–Ω—É)
            quality_score = sum(1 for r in results if len(r["response"]) > 10) / len(results)
            
            metrics = {
                "avg_response_time": avg_response_time,
                "avg_tokens": avg_tokens,
                "quality_score": quality_score,
                "test_queries_count": len(test_queries),
                "successful_responses": len(results)
            }
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—à–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            success = (
                avg_response_time < 5.0 and  # –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –º–µ–Ω–µ–µ 5 —Å–µ–∫—É–Ω–¥
                quality_score > 0.8 and      # –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –±–æ–ª–µ–µ 80%
                len(results) == len(test_queries)  # –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            )
            
            return {
                "success": success,
                "metrics": metrics,
                "error": None if success else "–ú–æ–¥–µ–ª—å –Ω–µ –ø—Ä–æ—à–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é"
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {
                "success": False,
                "error": str(e)
            }


class PerformanceMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
    
    async def record_metrics(self, metrics_data: Dict[str, Any]) -> PerformanceMetrics:
        """–ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        metrics = PerformanceMetrics(**metrics_data)
        self.db.add(metrics)
        await self.db.commit()
        await self.db.refresh(metrics)
        return metrics
    
    async def get_model_metrics(
        self, 
        model_id: int, 
        start_time: datetime = None, 
        end_time: datetime = None
    ) -> List[PerformanceMetrics]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        stmt = select(PerformanceMetrics).where(PerformanceMetrics.model_id == model_id)
        
        if start_time:
            stmt = stmt.where(PerformanceMetrics.timestamp >= start_time)
        if end_time:
            stmt = stmt.where(PerformanceMetrics.timestamp <= end_time)
        
        stmt = stmt.order_by(PerformanceMetrics.timestamp.desc())
        
        result = await self.db.execute(stmt)
        return result.scalars().all()
    
    async def get_performance_summary(self, model_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        metrics = await self.get_model_metrics(model_id, start_time, end_time)
        
        if not metrics:
            return {}
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        response_times = [m.response_time for m in metrics if m.response_time]
        token_counts = [m.tokens_generated for m in metrics if m.tokens_generated]
        success_rates = [m.success_rate for m in metrics if m.success_rate]
        
        return {
            "total_requests": len(metrics),
            "avg_response_time": np.mean(response_times) if response_times else 0,
            "avg_tokens_generated": np.mean(token_counts) if token_counts else 0,
            "avg_success_rate": np.mean(success_rates) if success_rates else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0,
        }
    
    async def log_api_call(self, log_data: Dict[str, Any]) -> APILog:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ API –≤—ã–∑–æ–≤–∞"""
        log = APILog(**log_data)
        self.db.add(log)
        await self.db.commit()
        await self.db.refresh(log)
        return log


class OptimizationService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.ollama_client = httpx.AsyncClient(
            base_url=settings.OLLAMA_BASE_URL,
            timeout=settings.OLLAMA_TIMEOUT
        )
    
    async def optimize_model(self, model_id: int, optimization_params: Dict[str, Any]) -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        model = await self._get_model(model_id)
        if not model:
            return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            performance = await self._analyze_performance(model_id)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            optimal_params = await self._calculate_optimal_params(performance, optimization_params)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            result = await self._apply_optimization(model.name, optimal_params)
            
            return {
                "model_id": model_id,
                "optimization_applied": True,
                "new_params": optimal_params,
                "performance_improvement": result.get("improvement", 0)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {"error": str(e)}
    
    async def _get_model(self, model_id: int) -> Optional[LLMModel]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        stmt = select(LLMModel).where(LLMModel.id == model_id)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def _analyze_performance(self, model_id: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)
        
        stmt = select(PerformanceMetrics).where(
            and_(
                PerformanceMetrics.model_id == model_id,
                PerformanceMetrics.timestamp >= start_time,
                PerformanceMetrics.timestamp <= end_time
            )
        )
        
        result = await self.db.execute(stmt)
        metrics = result.scalars().all()
        
        if not metrics:
            return {}
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        response_times = [m.response_time for m in metrics if m.response_time]
        token_counts = [m.tokens_generated for m in metrics if m.tokens_generated]
        
        return {
            "avg_response_time": np.mean(response_times) if response_times else 0,
            "avg_tokens": np.mean(token_counts) if token_counts else 0,
            "total_requests": len(metrics),
            "success_rate": sum(1 for m in metrics if m.success_rate > 0.8) / len(metrics)
        }
    
    async def _calculate_optimal_params(
        self, 
        performance: Dict[str, Any], 
        optimization_params: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        target_response_time = optimization_params.get("target_response_time", 1.0)
        target_quality = optimization_params.get("target_quality", 0.8)
        
        current_response_time = performance.get("avg_response_time", 0)
        current_quality = performance.get("success_rate", 0)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        temperature_adjustment = 0.1 if current_quality < target_quality else -0.05
        top_p_adjustment = 0.05 if current_quality < target_quality else -0.02
        
        return {
            "temperature": max(0.1, min(1.0, 0.7 + temperature_adjustment)),
            "top_p": max(0.1, min(1.0, 0.9 + top_p_adjustment)),
            "num_predict": optimization_params.get("num_predict", 1000),
            "repeat_penalty": optimization_params.get("repeat_penalty", 1.1)
        }
    
    async def _apply_optimization(self, model_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫ –º–æ–¥–µ–ª–∏"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫ –º–æ–¥–µ–ª–∏
        # –ü–æ–∫–∞ —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∏–º—É–ª—è—Ü–∏—é
        
        return {
            "improvement": 0.15,  # 15% —É–ª—É—á—à–µ–Ω–∏–µ
            "applied_params": params
        }


class LLMTuningService:
    """–ì–ª–∞–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π LLM Tuning"""
    
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        self.model_manager = ModelManager(db_session)
        self.route_manager = RouteManager(db_session)
        self.rag_service = RAGService(db_session)
        self.tuning_service = TuningService(db_session)
        self.performance_monitor = PerformanceMonitor(db_session)
        self.optimization_service = OptimizationService(db_session)
    
    async def process_request(
        self, 
        request_type: str, 
        content: str, 
        use_rag: bool = False,
        optimization_level: str = "balanced"
    ) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π"""
        start_time = time.time()
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç
            route = await self.route_manager.get_route(request_type, content)
            if not route:
                return {"error": "–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–∞—Ä—à—Ä—É—Ç"}
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model = await self.model_manager.get_model(route.model_id)
            if not model:
                return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
            if use_rag:
                result = await self.rag_service.generate_with_rag(model.name, content)
            else:
                result = await self._generate_response(model.name, content, route.parameters)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            response_time = time.time() - start_time
            await self.performance_monitor.record_metrics({
                "model_id": model.id,
                "route_id": route.id,
                "request_type": request_type,
                "response_time": response_time,
                "tokens_generated": result.get("tokens_generated", 0),
                "success_rate": 1.0 if "response" in result else 0.0,
                "timestamp": datetime.now()
            })
            
            # –õ–æ–≥–∏—Ä—É–µ–º API –≤—ã–∑–æ–≤
            await self.performance_monitor.log_api_call({
                "model_id": model.id,
                "route_id": route.id,
                "request_type": request_type,
                "request_content": content[:1000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                "response_time": response_time,
                "status_code": 200,
                "timestamp": datetime.now()
            })
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return {"error": str(e)}
    
    async def _generate_response(
        self, 
        model_name: str, 
        content: str, 
        parameters: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏"""
        if not parameters:
            parameters = {
                "temperature": 0.7,
                "top_p": 0.9,
                "num_predict": 1000
            }
        
        response = await self.rag_service.ollama_client.post(
            f"/api/generate",
            json={
                "model": model_name,
                "prompt": content,
                "stream": False,
                "options": parameters
            }
        )
        
        return response.json()
    
    async def get_system_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            models = await self.model_manager.list_models()
            active_routes = len([r for r in self.route_manager._route_cache.values() if r.is_active])
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            total_requests = 0
            avg_response_time = 0
            
            if models:
                for model in models:
                    summary = await self.performance_monitor.get_performance_summary(model.id)
                    total_requests += summary.get("total_requests", 0)
                    avg_response_time += summary.get("avg_response_time", 0)
                
                avg_response_time /= len(models)
            
            return {
                "status": "healthy",
                "models_count": len(models),
                "active_routes": active_routes,
                "total_requests_24h": total_requests,
                "avg_response_time": avg_response_time,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            } 